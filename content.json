{"pages":[],"posts":[{"title":"BinzBlog小程序已开源","text":"BinzBlog界面设计来自iview-weapp和ColorUI组件 评论系统 Wxcomment是一个微信小程序的评论插件，结合BaaS提供商LeanCloud，无需其他另外的个人或者云服务器，就可以免费使用。解决了需要个人去注册域名、备案、购买云服务器的繁杂问题。 文章详情页面是Toxml是一个可将HTML、Markdown转为微信小程序WXML(WeiXin Markup Language)的渲染库。用于解决在微信小程序中Markdown、HTML不能直接渲染的问题。 v2.0.2——2019/01/171.聊天室图片点击可以预览2.文章搜索加入提示3.加入赞赏和意见反馈 4.加入自动更新 v2.0.1——2019/01/16全新2.0版本UI改版 v1.9——2019/01/141.加入聊天室在线列表显示2.加入聊天室发送图片功能 3.加入聊天室历史聊天记录 v1.8——2019/01/131.文章列表网络延迟优化2.加入聊天室重连机制 3.修复聊天室切出后台断开bug v1.7——2019/01/121.聊天室界面改版2.修复聊天室bug v1.6——2019/01/111.用户授权优化2.加入用户个人中心3.加入用户浏览历史 4.更改首页 v1.5——2019/01/101.连续提交了3个版本2.文章列表优化 3.文章评论系统 v1.2——2019/01/09开启聊天室功能 v1.1——2019/01/08只是学习过程中的一个寄托，一个港湾，一个承载学习过程的地方。 Demo关注下公众号 联系作者 GitHub地址 ：https://github.com/gaobinzhan/BinzBlog-weapp","link":"/2019/10/27/binzblog%E5%B0%8F%E7%A8%8B%E5%BA%8F%E5%B7%B2%E5%BC%80%E6%BA%90.html"},{"title":"docker-compose搭建redis-sentinel","text":"​ 对于上篇文章redis持久化rdb及aof中，redis服务器重启时的数据恢复，在新版本中是不符合我画的那个流程图的。 ​ redis启动的时候会去判断是否开启aof，如果开启了，不存在aof文件的话，会去判断是否存在rdb，但在新的版本中，如果开启aof，不存在aof文件的时候，redis会主动创建aof文件并且加载aof，这就会导致数据丢失。解决方案如下： 关闭aof 启动redis去加载rdb文件 动态开启aof最终达到数据一致性 ​ 当主机master宕机以后，需要人工解决切换，比如使用slaveof no one。实际上主从复制并没有实现高可用。 高可用侧重备份机器，利用集群中系统的冗余，当系统中某台机器发生损坏的时候，其它后备的机器可以迅速的接替它来启动服务。 如何解决： 如果我们有一个监控程序能够监控各个机器的状态并及时调整，手动操作变为自动操作，Sentinel的出现就是为了解决这个问题。 哨兵机制的原理​ Reids Sentinel一个分布式架构，其中包含若干个Sentinel节点和Redis数据节点，每个Sentinel节点会对数据节点和其余Sentinel节点进行监控，当它发现节点不可达的时候，会对节点做下线标识。 ​ 如果被标识的是主节点，它还会和其它Sentinel节点进行协商，当大多数Sentinel节点都认为主节点不可达时，它们会选举出一个Sentinel节点来完成自动故障转移的工作，同时会将这个变化实时通知给Redis应用方。整个过程完全是自动的，不需要人工来介入，所以这套方案很有效地解决了Redis高可用的问题。 基本的故障转移流程： 主节点出现故障，此时两个从节点与主节点失去连接，主从复制失败。 每个Sentinel节点通过定期监控发现主节点出现了故障 多个Sentinel节点对主节点的故障达成一致会选举出其中一个节点作为领导者负责故障转移。 Sentinel领导者节点执行了故障转移，整个过程基本是跟我们手动调整一致的，只不过是自动化完成的。 故障转移后整个Redis Sentinel的结构，重新选举了新的主节点。 Redis Sentinel具有的功能： 监控：Sentinel节点会定期检查Redis数据节点、其余Sentinel节点是否可达。 通知：Sentinel节点会将故障转移的结果通知给应用方。 主节点故障转移：实现从节点晋升为主节点并维护后续正确的主从关系。 配置提供者：在Redis Sentinel结构中，客户端在初始化的时候连接的是Sentinel节点集合，从中获取主节点信息。 同时Redis Sentinel包含了若干个Sentinel节点，这样做也带了两个好处： 对于节点的故障判断是由多个Sentinel节点共同完成，这样可以有效地防止误判。 Sentinel节点集合是由若干个Sentinel节点组成的，这样即使个别Sentinel节点不可用，整个Sentinel节点集合依然是健壮的。 但是Sentinel节点本身就是独立的Reids节点，只不过它们有一些特殊，不存储数据，只支持部分命令。 docker-compose 实现 redis-sentinel容器名称 容器IP 映射端口号 服务运行模式 Redis-master 192.168.3.2 6380-&gt;6379 Master Redis-slave1 192.168.3.3 6381-&gt;6379 Slave Redis-slave2 192.168.3.4 6382-&gt;6379 Slave Redis-sentinel1 192.168.3.11 26380-&gt;26379 Sentinel Redis-sentinel2 192.168.3.12 26381-&gt;26379 Sentinel Redis-sentinel3 192.168.3.13 26382-&gt;26379 Sentinel 在这里我用的镜像是redis官方的6.0.5。去网上把配置文件下载下来(redis.conf、sentinel.conf) 然后开始进行： 创建目录，并且把配置文件拷贝进去。 sentinel目录下的所有配置文件进行简单的修改： 搜索sentinel monitor 改为 sentinel monitor mymaster 192.168.3.2 6379 2 server目录下进行修改： bind 127.0.0.1改为bind 0.0.0.0 replicaof 改为replicaof 192.168.3.2 6379(除master目录) 创建docker-compose.yml： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374version: &quot;3.6&quot;services: redis-master: image: redis container_name: &quot;redis-master&quot; ports: - &quot;6380:6379&quot; volumes: - /Users/gaobinzhan/Documents/Redis/server/master:/redis command: redis-server /redis/conf/redis.conf networks: redis-test: ipv4_address: 192.168.3.2 redis-slave1: image: redis container_name: &quot;redis-slave1&quot; ports: - &quot;6381:6379&quot; volumes: - /Users/gaobinzhan/Documents/Redis/server/slave1:/redis command: redis-server /redis/conf/redis.conf networks: redis-test: ipv4_address: 192.168.3.3 redis-slave2: image: redis container_name: &quot;redis-slave2&quot; ports: - &quot;6382:6379&quot; volumes: - /Users/gaobinzhan/Documents/Redis/server/slave2:/redis command: redis-server /redis/conf/redis.conf networks: redis-test: ipv4_address: 192.168.3.4 redis-sentinel1: image: redis container_name: &quot;redis-sentinel1&quot; ports: - &quot;26380:26379&quot; volumes: - /Users/gaobinzhan/Documents/Redis/sentinel/sentinel1:/redis command: redis-sentinel /redis/conf/sentinel.conf networks: redis-test: ipv4_address: 192.168.3.11 redis-sentinel2: image: redis container_name: &quot;redis-sentinel2&quot; ports: - &quot;26381:26379&quot; volumes: - /Users/gaobinzhan/Documents/Redis/sentinel/sentinel2:/redis command: redis-sentinel /redis/conf/sentinel.conf networks: redis-test: ipv4_address: 192.168.3.12 redis-sentinel3: image: redis container_name: &quot;redis-sentinel3&quot; ports: - &quot;26382:26379&quot; volumes: - /Users/gaobinzhan/Documents/Redis/sentinel/sentinel3:/redis command: redis-sentinel /redis/conf/sentinel.conf networks: redis-test: ipv4_address: 192.168.3.13networks: redis-test: driver: bridge ipam: config: - subnet: &quot;192.168.3.0/24&quot; 进行docker-compose up，执行完毕后： redis-cli工具运行redis-cli -p 26380输入info： 出现以上信息即搭建成功。。 Sentinel的核心配置： sentinel monitor mymaster 192.168.3.2 6379 2 监控的主节点的名字、IP 和端口，最后一个2的意思是有几台 Sentinel发现有问题，就会发生故障转移，例如 配置为2，代表至少有2个 Sentinel 节点认为主节点不可达，那么这个不可达的判定才是客观的。对于设置的越小，那么达到下线的条件越宽松，反之越严格。一般建议将其设置为 Sentinel 节点的一半加1。最后的参数不可大于Sentinel节点数。 sentinel down-after-millseconds mymaster 30000 这个是超时的时间（单位为毫米）。打个比方，当你去ping一个机器的时候，多长时间后仍ping不通，那么就认为它是有问题。 sentinel parallel-syncs my master 1 当Sentinel节点集合对主节点故障判断达成一致时，Sentinel领导者节点会被做故障转移操作，选出新的主节点，原来的从节点会向新的主节点发起复制操作，paraller-syncs就是用来限制在一次故障转移之后，每次向新的主节点发起复制操作的从节点个数，指出Sentinel属于并发还是串行。1代表每次只能复制一个，可以减轻Master的压力。 sentinel auth-pass 如果 Sentinel 监控的主节点配置了密码，sentinel auth-pass 配置通过添加主节点的密码，防止 Sentinel 节点对主节点无法监控。 sentinel failover-timeout mymaster 180000 表示故障转移的时间。","link":"/2020/09/20/docker-compose%E6%90%AD%E5%BB%BAredis-sentinel.html"},{"title":"docker实现redis主从复制","text":"在实际的场景当中单一节点的redis容易面临风险。比如: 机器故障。我们部署到一台 Redis 服务器，当发生机器故障时，需要迁移到另外一台服务器并且要保证数据是同步的。而数据是最重要的，如果你不在乎， 基本上也就不会使用 Redis 了。 要实现分布式数据库的更大的存储容量和承受高并发访问量，我们会将原来集中式数据库的数据分别存储到其他多个网络节点上。 Redis 为了解决这个单一节点的问题，也会把数据复制多个副本部署到其他节点上进行复制，实现 Redis的高可用，实现对数据的冗余备份，从而保证数据和服务 的高可用。 什么是主从复制 主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave),数据的复制是单向的，只能由主节点到 从节点。 默认情况下，每台Redis服务器都是主节点，且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。 主从复制的作用 数据冗余:主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。 故障恢复:当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复;实际上是一种服务的冗余。 负载均衡:在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务(即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点) 分担服务器负载;尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。 读写分离:可以用于实现读写分离，主库写、从库读，读写分离不仅可以提高服务器的负载能力，同时可根据需求的变化，改变从库的数量; 高可用基石:除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。 主从复制启用从节点开启主从复制，有3种方式: 配置文件 在从服务器的配置文件中加入:slaveof 不推荐使用 配置文件可被动态修改 启动命令 redis-server启动命令后加入 –slaveof 客户端命令 Redis服务器启动后，直接通过客户端执行命令:slaveof ，则该Redis实例成为从节点。 通过 info replication 命令可以看到复制的一些参数信息 主从复制原理主从复制的原理以及过程必须要掌握，这样我们才知道为什么会出现这些问题 主从复制过程大体可以分为3个阶段:连接建立阶段(即准备阶段)、数据同步阶段、命令传播阶段。在从节点执行 slaveof 命令后，复制过程便开始运作，下面图示大概可以看到， 从图中可以看出复制过程大致分为6个过程 构建dockerfile构建redis镜像DockerFile 123456789101112131415161718192021222324FROM alpineRUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g' /etc/apk/repositories \\ &amp;&amp; apk add gcc g++ libc-dev wget vim openssl-dev make linux-headers \\ &amp;&amp; rm -rf /var/cache/apk/*#通过选择更小的镜像，删除不必要文件清理不必要的安装缓存，从而瘦身镜像#创建相关目录能够看到日志信息跟数据跟配置文件RUN mkdir -p /usr/src/redis \\ &amp;&amp; mkdir -p /usr/src/redis/data \\ &amp;&amp; mkdir -p /usr/src/redis/conf \\ &amp;&amp; mkdir -p /usr/src/redis/log \\ &amp;&amp; mkdir -p /var/log/redisRUN wget -O /usr/src/redis/redis-4.0.11.tar.gz &quot;http://download.redis.io/releases/redis-4.0.11.tar.gz&quot; \\ &amp;&amp; tar -xzf /usr/src/redis/redis-4.0.11.tar.gz -C /usr/src/redis \\ &amp;&amp; rm -rf /usr/src/redis/redis-4.0.11.tar.tgzRUN cd /usr/src/redis/redis-4.0.11 &amp;&amp; make &amp;&amp; make PREFIX=/usr/local/redis install \\&amp;&amp; ln -s /usr/local/redis/bin/* /usr/local/bin/ &amp;&amp; rm -rf /usr/src/redis/redis-4.0.11#COPY ./conf/redis.conf /usr/src/redis/confCMD [&quot;/usr/local/bin/redis-server&quot;,&quot;/usr/src/redis/conf/redis.conf&quot;] 切换到当前dockfile文件目录下 执行命令 docker build -t redis . 等待构建完成就可以了 docker创建自定义网络及redis主从集群规划执行自定义网络命令docker network create --subnet=192.168.1.0/24 redis-network 容器名称 容器IP地址 映射端口号 宿主机IP地址 服务运行模式 redis-master 192.168.1.2 6380-&gt;6379 127.0.0.1 master redis-slave 192.168.1.3 6381-&gt;6379 127.0.0.1 slave docker启动容器在 /data/ 下面创建该目录结构 data和log下面文件忽略 目录代码 提取码：r8r1 下载完放到 /data 下面 用户可自行定义宿主机目录 masterdocker run -itd --name redis-master --net redis-network -v /data/redis/master:/usr/src/redis -p 6380:6379 --ip 192.168.1.2 redis slavedocker run -itd --name redis-slave --net redis-network -v /data/redis/slave:/usr/src/redis -p 6381:6379 --ip 192.168.1.3 redis 测试主从复制主从的配置文件 没有设置redis密码 开两个终端分别执行 docker exec -it redis-master sh docker exec -it redis-slave sh 进入容器后执行(都要执行) redis-cli 在slave执行 SLAVEOF 192.168.1.2 6379 info replication master_link_status为up就成功了！ 当前是通过内网连接 端口号为6379 如果通过宿主机IP连接 端口号为6380 这时候在master进行操作 就可以看到slave的变化了！","link":"/2020/09/20/docker%E5%AE%9E%E7%8E%B0redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6.html"},{"title":"ElasticSearch全文检索引擎-介绍","text":"博主： gaobinzhan 发布时间：2019 年 03 月 16 日 747次浏览 暂无评论 1504字数 分类： ElasticSearch [TOC] 一种将文件种或者数据库中所有文本与检索项匹配的文字资料检索方法。对全文数据的检索 数据分类 结构化数据 行数据，存储在数据库里，可以用二维表结构来逻辑表达实现的数据 能够用数据或统一的结构加以表示 数字、符号去表示 非结构化数据 无法用数字或统一的结构表示 文本、图像、声音、网页 结构化数据属于非结构化数据 非结构化数据即为全文数据 两种方法 顺序扫描法 将数据库中所有的内容挨个扫描 索引扫描法 全文检索的基本思路，也即将非结构化数据中的一部分信息提取出来，重新组织，使其变得有一定结构，然后对此有一定结构的数据进行搜索，从而达到搜索相对较快的目的。 全文检索过程 索引创建 索引保存的是一个词元，对应文档的id 索引只会创建一次 如何创建： 一些要索引的原文档(Document) 将原文档传给分词组件(Tokenizer) 将得到的词元(Token)传给语言处理组件(LinguisticProcessor) 将得到的词(Term)传给索引组件(Indexer) 用户输入查询语句 对查询语句进行词法分析，语法分析，及语言处理 搜索索引，得到符号文档 全文检索引擎 **全文检索引擎是目前广泛应用的主流搜索引擎。它的工作原理是计算机索引程序通过扫描文章中的每一个词，对每一个词建立一个索引，指明该词在文章中出现的次数和位置，当用户查询时，检索程序就根据事先建立的索引进行查找，并将查找的结果反馈给用户的检索方式。** 相关产品 Lucene,Sphinx,Xapian,Nutch,DataparkSearch… ElasticSearch ElasticSearch是一个基于Apache Lucene(TM)的开源搜索引擎。无论在开源还是专有领域，Lucene可以被认为是迄今为止最先进、性能最好的，功能最全的搜索引擎库。 为什么要选择ElasticSearch ElasticSearch也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。 **分布式的实时文件存储，每个字段都被索引可被搜索分布式的实时分析搜索引擎 可以扩展到上百台服务器，处理PB级结构化或非结构化数据** **所有功能都集成在一个服务里面，可以通过RESTful API、各种语言的客户端甚至命令行与之交互上手容易，提供了很多合理的缺省值，开箱即用，学习成本低 可免费下载、使用和修改 配置灵活** [TOC] 一种将文件种或者数据库中所有文本与检索项匹配的文字资料检索方法。对全文数据的检索 数据分类 结构化数据 行数据，存储在数据库里，可以用二维表结构来逻辑表达实现的数据 能够用数据或统一的结构加以表示 数字、符号去表示 非结构化数据 无法用数字或统一的结构表示 文本、图像、声音、网页 结构化数据属于非结构化数据 非结构化数据即为全文数据 两种方法 顺序扫描法 将数据库中所有的内容挨个扫描 索引扫描法 全文检索的基本思路，也即将非结构化数据中的一部分信息提取出来，重新组织，使其变得有一定结构，然后对此有一定结构的数据进行搜索，从而达到搜索相对较快的目的。 全文检索过程 索引创建 索引保存的是一个词元，对应文档的id 索引只会创建一次 如何创建： 一些要索引的原文档(Document) 将原文档传给分词组件(Tokenizer) 将得到的词元(Token)传给语言处理组件(LinguisticProcessor) 将得到的词(Term)传给索引组件(Indexer) 用户输入查询语句 对查询语句进行词法分析，语法分析，及语言处理 搜索索引，得到符号文档 全文检索引擎 **全文检索引擎是目前广泛应用的主流搜索引擎。它的工作原理是计算机索引程序通过扫描文章中的每一个词，对每一个词建立一个索引，指明该词在文章中出现的次数和位置，当用户查询时，检索程序就根据事先建立的索引进行查找，并将查找的结果反馈给用户的检索方式。** 相关产品 Lucene,Sphinx,Xapian,Nutch,DataparkSearch… ElasticSearch ElasticSearch是一个基于Apache Lucene(TM)的开源搜索引擎。无论在开源还是专有领域，Lucene可以被认为是迄今为止最先进、性能最好的，功能最全的搜索引擎库。 为什么要选择ElasticSearch ElasticSearch也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。 **分布式的实时文件存储，每个字段都被索引可被搜索分布式的实时分析搜索引擎 可以扩展到上百台服务器，处理PB级结构化或非结构化数据** **所有功能都集成在一个服务里面，可以通过RESTful API、各种语言的客户端甚至命令行与之交互上手容易，提供了很多合理的缺省值，开箱即用，学习成本低 可免费下载、使用和修改 配置灵活**","link":"/2020/09/20/elasticsearch%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2%E5%BC%95%E6%93%8E-%E4%BB%8B%E7%BB%8D.html"},{"title":"ElasticSearch全文检索引擎-使用","text":"[TOC] 手册官网es-docses-php-docs 索引 创建索引 vim createindex.json 1234567891011121314151617181920212223242526272829303132{ &quot;settings&quot;: { &quot;refresh_interval&quot;: &quot;5s&quot;, &quot;number_of_shards&quot;: 1, &quot;number_of_replicas&quot;: 0 }, &quot;mappings&quot;: { &quot;_default_&quot;: { &quot;_all&quot;: { &quot;enabled&quot;: true } } }, &quot;products&quot;: { &quot;dynamic&quot;: false, &quot;properties&quot;: { &quot;productid&quot;: { &quot;type&quot;: &quot;long&quot; }, &quot;title&quot;: { &quot;type&quot;: &quot;string&quot;, &quot;index&quot;: &quot;analyzed&quot;, &quot;analyzer&quot;: &quot;ik&quot; }, &quot;descr&quot;: { &quot;type&quot;: &quot;string&quot;, &quot;index&quot;: &quot;analyzed&quot;, &quot;analyzer&quot;: &quot;ik&quot; } } }} 具体的字段意思手册上都有 创建 curl -XPOST &quot;http://ip:port/shop&quot; -d'@createindex.json 这里的shop就是我们要设置的索引名称 可以自定义 products 是 索引的type类型 可以自定义 添加数据 curl -XPUT &quot;http://119.23.51.33:9200/shop/products/1&quot; -d'{&quot;productid&quot;:1,&quot;title&quot;:&quot;这是一个商品的标题&quot;,&quot;descr&quot;:&quot;这是一个商品的描述&quot;}' curl -XPUT &quot;http://ip:port/shop/products/2?pretty&quot; -d'{&quot;productid&quot;:2,&quot;title&quot;:&quot;这是一部手机&quot;,&quot;descr&quot;:&quot;这是一个苹果手机的描述信息&quot;}' url地址后面的整值要跟文章id一致 pretty就是 Elasticsearch美化输出(pretty-print)JSON响应以便更加容易阅读。 搜索数据 vim search.json 1234567891011121314151617181920212223{ &quot;query&quot;: { &quot;multi_match&quot;: { &quot;query&quot;: &quot;苹果&quot;, &quot;fields&quot;: [ &quot;title&quot;, &quot;descr&quot; ] } }, &quot;highlight&quot;: { &quot;pre_tags&quot;: [ &quot;&quot; ], &quot;post_tags&quot;: [ &quot;&quot; ], &quot;fields&quot;: { &quot;title&quot;: {}, &quot;descr&quot;: {} } } } query 要查询的关键字 fields 哪些字段需要被查询 highlight 被查询出来的关键字 进行一些改变 相当于高亮显示 pre_tags 标签开始 post_tags标签结束 测试 curl -XGET &quot;http://ip:port/shop/_search?pretty&quot; -d&quot;@search.json&quot; elasticsearch-jdbc将数据库的数据同步到elasticsearch 下载 wget http://xbib.org/repository/org/xbib/elasticsearch/importer/elasticsearch-jdbc/2.3.4.0/elasticsearch-jdbc-2.3.4.0-dist.zip unzip elasticsearch-jdbc-2.3.4.0-dist.zip 修改配置 cd elasticsearch-jdbc-2.3.4.0/bin 为了防止出错 先备份一下 cp mysql-blog.sh mysql-blog.sh.bak vim mysql-blog.sh 将 echo 下的内容替换成以下内容 12345678910111213141516{ &quot;type&quot; : &quot;jdbc&quot;, &quot;jdbc&quot; : { &quot;url&quot; : &quot;jdbc:mysql://localhost:3306/good&quot;, &quot;user&quot; : &quot;root&quot;, &quot;password&quot; : &quot;1C292567e208&quot;, &quot;sql&quot; : &quot;select productid,title,descr,productid as _id from test&quot;, &quot;index&quot; : &quot;shop&quot;, &quot;type&quot; : &quot;products&quot;, &quot;elasticsearch&quot; : { &quot;cluster&quot; : &quot;search&quot;, &quot;host&quot; : &quot;ip&quot;, &quot;port&quot; : 9300 } }} url 是我们的数据库 good是库名 对哪个库进行操作 user password 用户名和密码 sql语句 就是 执行后 把查询出来的数据添加到es中 这里呢productid as _id 是因为es的唯一标识是根据_id生成的 index 我们刚刚创建的索引名称 products 是索引type类型 cluster 是我们es配置文件中的项目名称 host port 分别为ip和端口号 port为9300 这个地方不可以改 运行 ./mysql-blog.sh curl -XGET &quot;http://119.23.51.33:9200/shop/_search?pretty&quot; 可以看到数据库的内容被添加进去了 但是修改数据库内容 或者 添加内容 es却不会改变 下面怎么改变呢 监控 实时同步 123456789101112131415161718192021222324{ &quot;type&quot; : &quot;jdbc&quot;, &quot;jdbc&quot; : { &quot;url&quot; : &quot;jdbc:mysql://localhost:3306/good&quot;, &quot;schedule&quot; : &quot;0 0-59 0-23 ? * *&quot;, &quot;user&quot; : &quot;root&quot;, &quot;password&quot; : &quot;1C292567e208&quot;, &quot;sql&quot; : [{ &quot;statement&quot;: &quot;select productid,title,descr,productid as _id from test where updatetime &gt; unix_timestamp(?) &quot;, &quot;parameter&quot;: [&quot;$metrics.lastexecutionstart&quot;]} ], &quot;index&quot; : &quot;shop&quot;, &quot;type&quot; : &quot;products&quot;, &quot;metrics&quot;: { &quot;enabled&quot; : true }, &quot;elasticsearch&quot; : { &quot;cluster&quot; : &quot;search&quot;, &quot;host&quot; : &quot;ip&quot;, &quot;port&quot; : 9300 } }} 这时需要一个字段去判断 那就是我们数据的修改时间 parameter 里面的内容 就是获取上次脚本执行时间 sql 的where条件 就是判断 修改时间大于上次脚本执行时间 就属于新数据 重新执行下脚本 就可以了 怎么用php操作呢 现在有好多框架的轮子 或者直接看es-php-docs php框架： laravel-elasticsearch yii2-elasticsearch 去GitHub上查找就行","link":"/2020/09/23/elasticsearch%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2%E5%BC%95%E6%93%8E-%E4%BD%BF%E7%94%A8.html"},{"title":"ElasticSearch全文检索引擎-安装","text":"ElasticSearch安装 安装JDK 安装ElasticSearch 安装ik中文分词 ElasticSearch和ik分词安装成功 下载rpm包 wget --no-cookies --no-check-certificate --header &quot;Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie&quot; &quot;https://download.oracle.com/otn-pub/java/jdk/8u201-b09/42970487e3af4f5aa5bca3f542482c60/jdk-8u201-linux-x64.rpm&quot; rpm安装 rpm -ivh jdk-8u201-linux-x64.rpm 安装成功后测试 java javac java -version 命令都能使用 官网 ElasticSearch 下载 这里我下载的2.4.6版本 wget https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/rpm/elasticsearch/2.4.6/elasticsearch-2.4.6.rpm 安装ElasticSearch yum install elasticsearch-2.4.6.rpm 修改配置文件 vim /etc/elasticsearch/elasticsearch.yml cluster.name: my-application这行取消注释 并且改为自己的应用名称 node.name: node-1 这行也一样 改为自己的节点名称 为了方便操作 应用名称改为 search 节点名称为 master network.host: 192.168.0.1 取消注释 改为 0.0.0.0 http.port: 9200 取消注释就行 可以自行修改端口号 切记 取消注释后 首字母前面不能有空格 不然启动会报错 运行ElasticSearch service elasticsearch start 浏览器访问ip+端口号 如果出现界面证明 成功 安装git和maven 如果有的话跳过此步 安装git yum install -y git 下载maven包 wget https://mirrors.tuna.tsinghua.edu.cn/apache/maven/maven-3/3.5.4/binaries/apache-maven-3.5.4-bin.tar.gz 解压到指定目录 tar -xzvf apache-maven-3.5.4-bin.tar.gz -C /usr/local 进入指定目录 cd /usr/local/ 创建软连接 ln -s apache-maven-3.5.4 maven 编辑文件 添加maven环境变量 vim /etc/profile 在文件末尾添加以下代码 MAVEN_HOME=//usr/local/maven export MAVEN_HOME export PATH=${PATH}:${MAVEN_HOME}/bin 运行命令 source /etc/profile mvn -v 出现版本 安装maven成功 安装ik分词克隆 git clone https://github.com/medcl/elasticsearch-analysis-ik.git 根据elasticsearch版本号切换相对应的ik分词版本号 这里es是2.4.6 相对应是1.10.6 克隆好之后进入该目录 cd elasticsearch-analysis-ik/ 切换版本 git checkout tags/v1.10.6 执行 mvn package 执行成功后会在 target/releases/ 目录下生成一个插件包 进入该目录 cd target/releases/ 复制到es的插件目录下解压 cp elasticsearch-analysis-ik-1.10.6.zip /usr/share/elasticsearch/plugins/ 进入目录 cd /usr/share/elasticsearch/plugins/ 解压 unzip elasticsearch-analysis-ik-1.10.6.zip 为了方便管理 新建个文件夹 把刚刚解压出来的文件移动进去 mkdir ik mv ./* ik 重启elasticsearch service elasticsearch restart 测试下 curl -XPOST &quot;http://ip:port/_analyze?analyzer=ik&amp;pretty&quot; -d '这是一个商品的标题'","link":"/2019/10/27/elasticsearch%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2%E5%BC%95%E6%93%8E-%E5%AE%89%E8%A3%85.html"},{"title":"Go典型并发任务","text":"[toc] 仅运行一次最容易联想到的单例模式： 1234567891011121314151617181920212223242526272829303132333435363738394041type Singleton struct {}var singleInstance *Singletonvar once sync.Oncefunc GetSingletonObj() *Singleton { once.Do(func() { fmt.Println(&quot;Create Obj&quot;) singleInstance = new(Singleton) }) return singleInstance}func TestGetSingletonObj(t *testing.T) { var wg sync.WaitGroup for i := 0; i &lt; 10; i++ { wg.Add(1) go func() { obj := GetSingletonObj() fmt.Printf(&quot;%x\\n&quot;, unsafe.Pointer(obj)) wg.Done() }() } wg.Wait() /** 运行结果： === RUN TestGetSingletonObj Create Obj 1269f78 1269f78 1269f78 1269f78 1269f78 1269f78 1269f78 1269f78 1269f78 1269f78 --- PASS: TestGetSingletonObj (0.00s) */} 仅需任意任务完成任务堆里面，只需任务一个完成就返回。 123456789101112func runTask(id int) string { time.Sleep(10 * time.Millisecond) return fmt.Sprintf(&quot;the result is from %d&quot;, id)}func FirstResponse() string { numOfRunner := 10 ch := make(chan string) // 非缓冲channel for i := 0; i &lt; numOfRunner; i++ { go func(i int) { ret := runTask(i) ch","link":"/2020/09/20/go%E5%85%B8%E5%9E%8B%E5%B9%B6%E5%8F%91%E4%BB%BB%E5%8A%A1.html"},{"title":"Go包和依赖管理","text":"package： 基本复用模块单元 以首字母大写来表明可被包外代码访问 代码的 package 可以和所在的目录不一致 同一目录里的 Go 代码的 package 要保持一致 需要把包目录加入到GOPATH 目录结构： 12345678~/Documents/Go- learning - src - fifteen - client - package_test.go - series - my_series.go 查看 go env 12$ go envGOPATH=&quot;/Users/gaobinzhan/Documents/Go/learning:/Users/gaobinzhan/Documents/Go&quot; 可以看到这个目录已经加入GOPATH里了。 my_series.go 1234567891011package series// 首字母必须大写 才可被包外代码访问func GetFibonacci(n int) ([]int, error) { fibList := []int{1, 2} for i := 2; i &lt; n; i++ { fibList = append(fibList, fibList[i-2]+fibList[i-1]) } return fibList, nil} package_test.go 123456789101112131415package clientimport ( &quot;fifteen/series&quot; &quot;testing&quot;)func TestPackage(t *testing.T) { t.Log(series.GetFibonacci(5)) /** 运行结果： === RUN TestPackage TestPackage: package_test.go:9: [1 2 3 5 8] --- PASS: TestPackage (0.00s) */} init方法： 在 main 被执行前，所有依赖的 package 的 init 方法都会被执行 不同包的 init 函数按照包导入的依赖关系决定执行顺序 每个包可以有多个 init 函数 包的每个源文件 下面修改文件 my_series.go 1234567891011121314151617181920package seriesimport &quot;fmt&quot;func init() { fmt.Println(&quot;init 1&quot;)}func init() { fmt.Println(&quot;init 2&quot;)}func GetFibonacci(n int) ([]int, error) { fibList := []int{1, 2} for i := 2; i &lt; n; i++ { fibList = append(fibList, fibList[i-2]+fibList[i-1]) } return fibList, nil} package_test.go 1234567891011121314151617package clientimport ( &quot;fifteen/series&quot; &quot;testing&quot;)func TestPackage(t *testing.T) { t.Log(series.GetFibonacci(5)) /** 运行结果： init 1 init 2 === RUN TestPackage TestPackage: package_test.go:10: [1 2 3 5 8] --- PASS: TestPackage (0.00s) */} 获取远程package： 通过 go get 来获取远程依赖 go get -u 强制从网络更新远程依赖 注意代码在 Github 上的组织形式，以适应 go get 直接以代码路径开始，不要有 src 示例：go get -u https://github.com/easierway/concurrent\\_map 代码： 123456789101112131415161718package remote_packageimport ( cm &quot;github.com/easierway/concurrent_map&quot; &quot;testing&quot;)func TestConcurrentMap(t *testing.T) { m := cm.CreateConcurrentMap(99) m.Set(cm.StrKey(&quot;key&quot;), 10) t.Log(m.Get(cm.StrKey(&quot;key&quot;))) /** 运行结果： === RUN TestConcurrentMap TestConcurrentMap: remote_package_test.go:11: 10 true --- PASS: TestConcurrentMap (0.00s) */} 依赖管理Go未解决的依赖问题： 同一环境下，不同项目使用同一包的不同版本 无法管理对包的特定版本的依赖 vendor路径： 随着 Go 1.5 release 版本的发布，vendor ⽬录被添加到除了 GOPATH 和 GOROOT 之外的依赖⽬录查找的解决⽅案。在 Go 1.6 之前，你需要⼿动 的设置环境变量 查找依赖包路径的解决⽅案如下： 当前包下的 vendor ⽬录 向上级⽬录查找，直到找到 src 下的 vendor ⽬录 在 GOPATH 下⾯查找依赖包 在 GOROOT ⽬录下查 常用的依赖管理工具： 简单用一下 安装 gilde brew install glide 删除我们刚刚 go get 下来的包 然后执行 glide init 然后会在目录下面生成一个 glide.yaml文件 执行 glide install 会生成 vendor 目录 里面就是我们的依赖包 执行原来的测试文件，依然可以执行成功。","link":"/2020/09/20/go%E5%8C%85%E5%92%8C%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86.html"},{"title":"Go单元测试及Benchmark","text":"之前在刚开始写了如何编写测试程序。 内置单元测试框架： 123456789101112131415161718192021222324func TestErrorInCode(t *testing.T) { fmt.Println(&quot;Start&quot;) t.Error(&quot;Error&quot;) fmt.Println(&quot;End&quot;) /** 运行结果： === RUN TestErrorInCode Start TestErrorInCode: functions_test.go:25: Error End --- FAIL: TestErrorInCode (0.00s) */}func TestFatalInCode(t *testing.T) { fmt.Println(&quot;Start&quot;) t.Fatal(&quot;Error&quot;) fmt.Println(&quot;End&quot;) /** 运行结果： === RUN TestFatalInCode Start TestFatalInCode: functions_test.go:38: Error --- FAIL: TestFatalInCode (0.00s) */} 使用断言： go get -u github.com/stretchr/testify 123456789101112func square(op int) int { return op * op}func TestSquareWithAssert(t *testing.T) { inputs := [...]int{1, 2, 3} expected := [...]int{1, 4, 9} for i := 0; i &lt; len(inputs); i++ { ret := square(inputs[i]) assert.Equal(t, expected[i], ret) }} Benchmark文件名以下划线_benchmark结尾，方法名以Benchmark开头，参数为b *testing.B 1234567891011121314151617181920212223242526272829303132333435363738394041424344// 利用+=连接func TestConcatStringByAdd(t *testing.T) { assert := assert.New(t) elems := []string{&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;} ret := &quot;&quot; for _, elem := range elems { ret += elem } assert.Equal(&quot;12345&quot;, ret)}// 利用buffer连接func TestConcatStringBytesBuffer(t *testing.T) { assert := assert.New(t) var buf bytes.Buffer elems := []string{&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;} for _, elem := range elems { buf.WriteString(elem) } assert.Equal(&quot;12345&quot;, buf.String())}func BenchmarkConcatStringByAdd(b *testing.B) { elems := []string{&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;} b.ResetTimer() for i := 0; i &lt; b.N; i++ { ret := &quot;&quot; for _, elem := range elems { ret += elem } } b.StopTimer()}func BenchmarkConcatStringBytesBuffer(b *testing.B) { elems := []string{&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;} b.ResetTimer() for i := 0; i &lt; b.N; i++ { var buf bytes.Buffer for _, elem := range elems { buf.WriteString(elem) } }} 在命令行输入 go test -bench=. -benchmem Windows 下使⽤ go test 命令⾏时，-bench=.应写为-bench=”.” 运行结果： 12345678$ go test -bench=. -benchmemgoos: darwingoarch: amd64pkg: eighteen/benchmarkBenchmarkConcatStringByAdd-8 8982729 130 ns/op 16 B/op 4 allocs/opBenchmarkConcatStringBytesBuffer-8 17703706 64.9 ns/op 64 B/op 1 allocs/opPASSok eighteen/benchmark 2.532s 使用 buffer 连接字符串的性能比 += 要好很多。 BDDBDD in Go： 项⽬⽹站 ： https://github.com/smartystreets/goconvey 安装： go get -u github.com/smartystreets/goconvey/convey 启动 WEB UI ： $GOPATH/bin/goconvey 123456789101112func TestSpec(t *testing.T) { convey.Convey(&quot;Given 2 even numbers&quot;, t, func() { a := 2 b := 4 convey.Convey(&quot;When add the two numbers&quot;, func() { c := a + b convey.Convey(&quot;Then the result is still even&quot;, func() { convey.So(c%2, convey.ShouldEqual, 0) }) }) })} 运行结果： 12345678910111213$ go test -v bdd_spec_test.go === RUN TestSpec Given 2 even numbers When add the two numbers Then the result is still even ✔1 total assertion--- PASS: TestSpec (0.00s)PASSok command-line-arguments 0.006s 可以看到最后一步为 ✔","link":"/2020/09/23/go%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E5%8F%8Abenchmark.html"},{"title":"Go反射编程","text":"reflect.TypeOf vs. reflect.ValueOf： reflflect.TypeOf 返回类型 (reflflect.Type) reflflect.ValueOf 返回值 (reflflect.Value) 可以从 reflflect.Value 获得类型 通过 kind 的来判断类型 123456789101112131415161718192021func CheckType(v interface{}) { t := reflect.TypeOf(v) switch t.Kind() { case reflect.Float32, reflect.Float64: fmt.Println(&quot;Float&quot;) case reflect.Int, reflect.Int32, reflect.Int64: fmt.Println(&quot;Integer&quot;) default: fmt.Println(&quot;Unknown&quot;, t) }}func TestBasicType(t *testing.T) { var f float64 = 12 CheckType(f) /** 运行结果： === RUN TestBasicType Float --- PASS: TestBasicType (0.00s) */} 利用反射编写灵活的代码： 按名字访问结构的成员 reflect.ValueOf(*e).FieldByName(&quot;Name&quot;) 按名字访问结构的方法 reflect.ValueOf(*e).MethodByName(&quot;UpdateAge&quot;).Call([]reflect.Value{reflect.ValueOf(1)}) 1234567891011121314151617181920212223242526272829type Employee struct { EmployeeId string Name string `format:&quot;normal&quot;` Age int}func (e *Employee) UpdateAge(newVal int) { e.Age = newVal}func TestInvokeByName(t *testing.T) { e := &amp;Employee{&quot;1&quot;, &quot;Mike&quot;, 30} // 按名字获取成员 t.Logf(&quot;Name：value(%[1]v)，Type(%[1]T)&quot;, reflect.ValueOf(*e).FieldByName(&quot;Name&quot;)) if nameField, ok := reflect.TypeOf(*e).FieldByName(&quot;Name&quot;); !ok { t.Error(&quot;Failed to get 'Name' field.&quot;) } else { t.Log(&quot;Tag:format&quot;, nameField.Tag.Get(&quot;format&quot;)) } reflect.ValueOf(e).MethodByName(&quot;UpdateAge&quot;).Call([]reflect.Value{reflect.ValueOf(1)}) t.Log(&quot;Updated Age:&quot;, e) /** 运行结果： === RUN TestInvokeByName TestInvokeByName: reflect_test.go:28: Name：value(Mike)，Type(reflect.Value) TestInvokeByName: reflect_test.go:32: Tag:format normal TestInvokeByName: reflect_test.go:35: Updated Age: &amp;{1 Mike 1} --- PASS: TestInvokeByName (0.00s) */} Struct Tag： 1234type BasicInfo struct { Name string `json:&quot;name&quot;` Age int `json:&quot;age&quot;`} 访问Struct： 1234if nameField, ok := reflect.TypeOf(*e).FieldByName(&quot;Name&quot;); !ok {t.Error(&quot;Failed to get 'Name' field.&quot;)} else {t.Log(&quot;Tag:format&quot;, nameField.Tag.Get(&quot;format&quot;)) } Reflect.Type 和 Reflflect.Value 都有 FieldByName ⽅法，注意他们的区别。 DeepEqual： 比较切片和map 123456789101112131415161718192021222324252627282930type Customer struct { CookieID string Name string Age int}func TestDeepEqual(t *testing.T) { a := map[int]string{1: &quot;one&quot;, 2: &quot;two&quot;, 3: &quot;three&quot;} b := map[int]string{1: &quot;one&quot;, 2: &quot;two&quot;, 4: &quot;three&quot;} fmt.Println(reflect.DeepEqual(a, b)) s1 := []int{1, 2, 3} s2 := []int{1, 2, 3} s3 := []int{2, 3, 1} t.Log(&quot;s1 == s2?&quot;, reflect.DeepEqual(s1, s2)) t.Log(&quot;s1 == s3?&quot;, reflect.DeepEqual(s1, s3)) c1 := Customer{&quot;1&quot;, &quot;Mike&quot;, 40} c2 := Customer{&quot;1&quot;, &quot;Mike&quot;, 40} fmt.Println(reflect.DeepEqual(c1, c2)) /** 运行结果： === RUN TestDeepEqual false TestDeepEqual: fiexible_reflect_test.go:23: s1 == s2? true TestDeepEqual: fiexible_reflect_test.go:24: s1 == s3? false true --- PASS: TestDeepEqual (0.00s) */} 关于“反射”你应该知道的： 提⾼了程序的灵活性 降低了程序的可读性 降低了程序的性能 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273type Employee struct { EmployeeID string Name string `format:&quot;normal&quot;` Age int}func (e *Employee) UpdateAge(newVal int) { e.Age = newVal}type Customer struct { CookieID string Name string Age int}func fillBySettings(st interface{}, settings map[string]interface{}) error { // func (v Value) Elem() Value // Elem returns the value that the interface v contains or that the pointer v points to. // It panics if v's Kind is not Interface or Ptr. // It returns the zero Value if v is nil. if reflect.TypeOf(st).Kind() != reflect.Ptr { return errors.New(&quot;the first param should be a pointer to the struct type.&quot;) } // Elem() 获取指针指向的值 if reflect.TypeOf(st).Elem().Kind() != reflect.Struct { return errors.New(&quot;the first param should be a pointer to the struct type.&quot;) } if settings == nil { return errors.New(&quot;settings is nil.&quot;) } var ( field reflect.StructField ok bool ) for k, v := range settings { if field, ok = (reflect.ValueOf(st)).Elem().Type().FieldByName(k); !ok { continue } if field.Type == reflect.TypeOf(v) { vstr := reflect.ValueOf(st) vstr = vstr.Elem() vstr.FieldByName(k).Set(reflect.ValueOf(v)) } } return nil}func TestFillNameAndAge(t *testing.T) { settings := map[string]interface{}{&quot;Name&quot;: &quot;Mike&quot;, &quot;Age&quot;: 30} e := Employee{} if err := fillBySettings(&amp;e, settings); err != nil { t.Fatal(err) } t.Log(e) c := new(Customer) if err := fillBySettings(c, settings); err != nil { t.Fatal(err) } t.Log(*c) /** 运行结果： === RUN TestFillNameAndAge TestFillNameAndAge: fiexible_reflect_test.go:69: { Mike 30} TestFillNameAndAge: fiexible_reflect_test.go:74: { Mike 30} --- PASS: TestFillNameAndAge (0.00s) */} ”不安全“行为的危险性： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364func TestUnsafe(t *testing.T) { i := 10 f := *(*float64)(unsafe.Pointer(&amp;i)) t.Log(unsafe.Pointer(&amp;i)) t.Log(f) /** 运行结果： === RUN TestUnsafe TestUnsafe: unsafe_test.go:11: 0xc000016268 TestUnsafe: unsafe_test.go:12: 5e-323 --- PASS: TestUnsafe (0.00s) */}// The cases is suitable for unsafetype MyInt int// 合理的类型转换func TestConvert(t *testing.T) { a := []int{1, 2, 3, 4} b := *(*[]MyInt)(unsafe.Pointer(&amp;a)) t.Log(b) /** 运行结果： === RUN TestConvert TestConvert: unsafe_test.go:26: [1 2 3 4] --- PASS: TestConvert (0.00s) */}// 原子类型操作func TestAtomic(t *testing.T) { var shareBuffer unsafe.Pointer writeDataFn := func() { data := []int{} for i := 0; i &lt; 100; i++ { data = append(data, i) } atomic.StorePointer(&amp;shareBuffer, unsafe.Pointer(&amp;data)) } readDataFn := func() { data := atomic.LoadPointer(&amp;shareBuffer) fmt.Println(data, *(*[]int)(data)) } var wg sync.WaitGroup writeDataFn() for i := 0; i &lt; 10; i++ { wg.Add(1) go func() { for i := 0; i &lt; 10; i++ { writeDataFn() time.Sleep(time.Microsecond * 100) } wg.Done() }() wg.Add(1) go func() { for i := 0; i &lt; 10; i++ { readDataFn() time.Sleep(time.Microsecond * 100) } wg.Done() }() } wg.Wait()}","link":"/2020/09/23/go%E5%8F%8D%E5%B0%84%E7%BC%96%E7%A8%8B.html"},{"title":"Go基本程序结构","text":"测试程序： 源码文件以_test结尾：x x x_test.go 测试方法名以Test开头：func TestXXX(t *testing.T) {...} 1234567package testimport &quot;testing&quot;func TestFirstTry(t *testing.T) { t.Log(&quot;My first try!&quot;)} 实现Fibonacci数列 1234567891011121314151617181920212223package testimport ( &quot;testing&quot;)func TestFibonacciList(t *testing.T) { //var a int = 1 // 定义变量 //var b int = 1 var ( a int = 1 b int = 1 ) // 这样也可以定义变量 // a := 1 直接赋值 // b := 1 t.Log(a) for i := 0; i &lt; 5; i++ { t.Log(&quot; &quot;, b) tmp := a a = b b = tmp + a }} 变量及常量变量 赋值可以进行自动类型推断 在一个赋值语句中可以对多个变量进行同时赋值 123456789func TestExchange(t *testing.T) { a := 1 b := 2 //tmp := a //a = b //b = tmp a, b = b, a // 变量交换 t.Log(a, b)} 常量 进行快速 设置连续值 123456789101112const ( Monday = iota + 1 Tuesday // 2 Wednesday // 3 Thursday // 4 Friday // 5 Saturday // 6 Sunday // 7)const ( Readable = 1 检查左边值是否大于右边值 检查左边值是否大于等于右边值","link":"/2020/09/20/go%E5%9F%BA%E6%9C%AC%E7%A8%8B%E5%BA%8F%E7%BB%93%E6%9E%84.html"},{"title":"Go字符串","text":"字符串： string是数据类型，不是引用或指针类型 string是只读的byte slice，len函数可以获取它所包含的byte数 string的byte数组可以存放任何数据 12345678910111213func TestStringInit(t *testing.T) { var s string t.Log(s) // 初始化为默认零值&quot;&quot; 空字符串 s = &quot;hello&quot; t.Log(len(s)) // 5 5个byte //s[1] = 3 // string是不可变的byte slice 不可以赋值 s = &quot;\\xE4\\xB8\\xA5&quot; // 可以存储任何二进制数据 t.Log(s) // 严 t.Log(len(s)) // 3 为3个byte} Unicode UTF8： Unicode是一种字符集（code point） UTF8是unicode的存储实现（转换为字节序列的规则） 编码和存储： 字符 Unicode UTF-8 string/[]byte “中” 0x4E2D 0xE4B8AD [0xE4,0xB8,0xAD] 123456789101112func TestUnicode(t *testing.T) { s := &quot;中&quot; t.Log(len(s)) // 3 为3个byte // 新的数据类型 rune 能够取出字符串的unicode c := []rune(s) t.Log(len(c)) // 1 // %x 输出十六进制 t.Logf(&quot;中 unicode %x&quot;, c[0]) // 中 unicode 4e2d t.Logf(&quot;中 utf8 %x&quot;, s) // 中 utf8 e4b8ad} 字符串遍历： 1234567891011121314151617181920212223func TestStringToRange(t *testing.T) { s := &quot;PHP是世界上最好的语言&quot; for _, c := range s { // 都用第一个参数 t.Logf(&quot;%[1]c %[1]x&quot;, c) } /** 运行结果： === RUN TestStringToRange TestStringToRange: string_test.go:37: P 50 TestStringToRange: string_test.go:37: H 48 TestStringToRange: string_test.go:37: P 50 TestStringToRange: string_test.go:37: 是 662f TestStringToRange: string_test.go:37: 世 4e16 TestStringToRange: string_test.go:37: 界 754c TestStringToRange: string_test.go:37: 上 4e0a TestStringToRange: string_test.go:37: 最 6700 TestStringToRange: string_test.go:37: 好 597d TestStringToRange: string_test.go:37: 的 7684 TestStringToRange: string_test.go:37: 语 8bed TestStringToRange: string_test.go:37: 言 8a00 --- PASS: TestStringToRange (0.00s) */} 常用字符串函数： 123456789101112131415161718func TestStringFn(t *testing.T) { s := &quot;A,B,C&quot; // 字符串切割 parts := strings.Split(s, &quot;,&quot;) for _, part := range parts { t.Log(part) } // 字符串拼接 t.Log(strings.Join(parts, &quot;-&quot;)) /** 运行结果： === RUN TestStringFn TestStringFn: string_fun_test.go:12: A TestStringFn: string_fun_test.go:12: B TestStringFn: string_fun_test.go:12: C TestStringFn: string_fun_test.go:14: A-B-C --- PASS: TestStringFn (0.00s) */} 数据类型转换： 12345678910111213141516func TestStrConv(t *testing.T) { // 整型转字符串 s := strconv.Itoa(10) t.Log(&quot;str&quot; + s) // 字符串转整型对错误值需要做一个判断 if i, err := strconv.Atoi(&quot;10&quot;); err == nil { t.Log(10 + i) } /** 运行结果： === RUN TestStrConv TestStrConv: string_fun_test.go:29: str10 TestStrConv: string_fun_test.go:33: 20 --- PASS: TestStrConv (0.00s) */}","link":"/2020/09/20/go%E5%AD%97%E7%AC%A6%E4%B8%B2.html"},{"title":"Go常用集合","text":"[Toc] 数组和切片数组声明： 1234567var a [3]int // 声明并初始化为默认零值a[0] = 1b := [3]int{1, 2, 3} // 声明同时初始化c := [2][2]int{{1, 2}, {3, 4}} // 多维数组初始化t.Log(a[0], a[2])t.Log(b[2])t.Log(c[1][1]) 遍历： 12345678910111213arr := [...]int{1, 2, 3, 4, 5, 6} // 自动判断长度for i := 0; i &lt; len(arr); i++ { // 典型写法遍历数组 t.Log(arr[i])}for idx, e := range arr { // 相当于其它语言的foreach t.Log(idx, e)}for _, e := range arr { // 我们可能用不到 idx 但go语言定义一个值不去使用编译会不通过 使用_代表不关心这个结果，来占位 t.Log(e)} 截取： a[开始索引(包含):结束索引(不包含)] 123456arr := [...]int{1, 2, 3, 4, 5, 6}// a[开始索引(包含):结束索引(不包含)]t.Log(arr[0:1]) // 1t.Log(arr[2:]) // 3 4 5 6t.Log(arr[1:len(arr)]) // 2 3 4 5 6t.Log(arr[1:3]) // 2 3 切片内部结构： 声明： 12345678910111213141516var s0 []int // 定义看起来特别像数组，但没有指定长度t.Log(len(s0), cap(s0)) // 0 0s0 = append(s0, 1)t.Log(len(s0), cap(s0)) // 1 1s1 := []int{1, 2, 3, 4} // 初始化一个切片t.Log(len(s1), cap(s1)) // 4 4// []type,len,cap 其中len个元素会被初始化为默认零值，未初始化元素不可以访问s2 := make([]int, 3, 5) // len为3 cap为5t.Log(len(s2), cap(s2)) // 3 5t.Log(s2[0], s2[1], s2[2]) // 成功被初始化 结果：0 0 0//t.Log(s2[0], s2[1], s2[2], s2[3]) // 出现了一个错误 index out of range [3]s2 = append(s2, 1)t.Log(s2[0], s2[1], s2[2], s2[3]) // 0 0 0 1t.Log(len(s2), cap(s2)) // 4 5 len变成了4 共享存储结构： 1234567891011121314151617s := []int{}for i := 0; i &lt; 10; i++ { s = append(s, i) // 为什么重新赋值给s,是因为结构体指向的连续存储空间进行了变化,并把原有的连续存储空间拷贝到新的连续存储空间 t.Log(len(s), cap(s))}/** 运行结果：当len不够用的时候会增长，cap不够用的时候增长为前一个cap的2倍 TestSliceGrowing: slice_test.go:28: 1 1 TestSliceGrowing: slice_test.go:28: 2 2 TestSliceGrowing: slice_test.go:28: 3 4 TestSliceGrowing: slice_test.go:28: 4 4 TestSliceGrowing: slice_test.go:28: 5 8 TestSliceGrowing: slice_test.go:28: 6 8 TestSliceGrowing: slice_test.go:28: 7 8 TestSliceGrowing: slice_test.go:28: 8 8 TestSliceGrowing: slice_test.go:28: 9 16 TestSliceGrowing: slice_test.go:28: 10 16*/ Map声明、元素访问及遍历声明： 12345678m1 := map[int]int{1: 1, 2: 4, 3: 9} // 初始化一个mapt.Log(m1[2]) // 4t.Logf(&quot;len m1 = %d&quot;, len(m1)) // len m1 = 3m2 := map[int]int{} // 初始化一个空mapm2[4] = 16 // 赋值t.Logf(&quot;len m2 = %d&quot;, len(m2)) // len m2 = 1m3 := make(map[int]int, 10) // 使用make初始化mapt.Logf(&quot;len m3 = %d&quot;, len(m3)) // len m3 = 0 填的len为10,但打印出来为0 元素访问： 12345678910111213141516171819// key在map中存在吗？// key存在但是对应的值是空值m1 := map[int]int{}t.Log(m1[1]) // 0 不存在输出0m1[2] = 0 // 设置value正好为0t.Log(m1[2]) // 0 也是0 该如何判断key是否存在呢// 需要主动去判断if v, ok := m1[3]; ok { t.Logf(&quot;key 3's value is %d&quot;, v)} else { t.Log(&quot;key 3 is not existing.&quot;) // 将输出这句话}m1[3] = 9if v, ok := m1[3]; ok { t.Logf(&quot;key 3's value is %d&quot;, v) // 将输出这句话} else { t.Log(&quot;key 3 is not existing.&quot;)} 遍历： 123456789m1 := map[int]int{1: 1, 2: 4, 3: 9}for k, v := range m1 { t.Log(k, v)}/** 运行结果 TestTravelMap: map_test.go:41: 1 1 TestTravelMap: map_test.go:41: 2 4 TestTravelMap: map_test.go:41: 3 9 */ Map与工厂模式，实现Set Map的value可以是一个方法 与Go的Dock type接口方式一起，可以方便的实现单一方法对象的工厂模式 1234567891011m := map[int]func(op int) int{}m[1] = func(op int) int { return op}m[2] = func(op int) int { return op * op}m[3] = func(op int) int { return op * op * op}t.Log(m[1](2), m[2](2), m[3](2)) // 运行结果 2 4 8 实现Set： Go内置集合中没有Set实现，可以map[type]bool 元素的唯一性 基本操作 12345678910111213141516mySet := map[int]bool{}mySet[1] = true // 添加元素 value置为truen := 1if mySet[n] { t.Logf(&quot;%d is existing.&quot;, n) // 输出这句话} else { t.Logf(&quot;%d is not existing.&quot;, n)}delete(mySet, 1) // 把1这个key从map中删除if mySet[n] { t.Logf(&quot;%d is existing.&quot;, n)} else { t.Logf(&quot;%d is not existing.&quot;, n) // 输出这句话}","link":"/2020/09/27/go%E5%B8%B8%E7%94%A8%E9%9B%86%E5%90%88.html"},{"title":"Go常见架构模式的实现","text":"Pipe-Filter 模式： ⾮常适合与数据处理及数据分析系统 Filter封装数据处理的功能 Pipe⽤于连接Filter传递数据或者在异步处理过程中缓冲数据流 进程内同步调⽤时，pipe演变为数据在⽅法调⽤间传递 松耦合：Filter只跟数据（格式）耦合 Filter和组合模式： 示例： 简单示例代码： filter.go 1234567891011121314// Package pipefilter is to define the interfaces and the structures for pipe-filter style implementationpackage pipefilter// Request is the input of the filtertype Request interface{}// Response is the output of the filtertype Response interface{}// Filter interface is the definition of the data processing components// Pipe-Filter structuretype Filter interface { Process(data Request) (Response, error)} split_filter.go 12345678910111213141516171819202122232425package pipefilterimport ( &quot;errors&quot; &quot;strings&quot;)var SplitFilterWrongFormatError = errors.New(&quot;input data should be string&quot;)type SplitFilter struct { delimiter string}func NewSplitFilter(delimiter string) *SplitFilter { return &amp;SplitFilter{delimiter}}func (sf *SplitFilter) Process(data Request) (Response, error) { str, ok := data.(string) //检查数据格式/类型，是否可以处理 if !ok { return nil, SplitFilterWrongFormatError } parts := strings.Split(str, sf.delimiter) return parts, nil} split_filter_test.go 1234567891011121314151617181920212223242526272829package pipefilterimport ( &quot;reflect&quot; &quot;testing&quot;)func TestStringSplit(t *testing.T) { sf := NewSplitFilter(&quot;,&quot;) resp, err := sf.Process(&quot;1,2,3&quot;) if err != nil { t.Fatal(err) } parts, ok := resp.([]string) if !ok { t.Fatalf(&quot;Repsonse type is %T, but the expected type is string&quot;, parts) } if !reflect.DeepEqual(parts, []string{&quot;1&quot;, &quot;2&quot;, &quot;3&quot;}) { t.Errorf(&quot;Expected value is {\\&quot;1\\&quot;,\\&quot;2\\&quot;,\\&quot;3\\&quot;}, but actual is %v&quot;, parts) }}func TestWrongInput(t *testing.T) { sf := NewSplitFilter(&quot;,&quot;) _, err := sf.Process(123) if err == nil { t.Fatal(&quot;An error is expected.&quot;) }} 实现micro-kernel framework 特点 要点 内核包含公共流程或通⽤逻辑 抽象扩展点⾏为，定义接⼝ 示例： 简单示例代码： agent.go 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package microkernelimport ( &quot;context&quot; &quot;errors&quot; &quot;fmt&quot; &quot;strings&quot; &quot;sync&quot;)const ( Waiting = iota Running)var WrongStateError = errors.New(&quot;can not take the operation in the current state&quot;)type CollectorsError struct { CollectorErrors []error}func (ce CollectorsError) Error() string { var strs []string for _, err := range ce.CollectorErrors { strs = append(strs, err.Error()) } return strings.Join(strs, &quot;;&quot;)}type Event struct { Source string Content string}type EventReceiver interface { OnEvent(evt Event)}type Collector interface { Init(evtReceiver EventReceiver) error Start(agtCtx context.Context) error Stop() error Destory() error}type Agent struct { collectors map[string]Collector evtBuf chan Event cancel context.CancelFunc ctx context.Context state int}func (agt *Agent) EventProcessGroutine() { var evtSeg [10]Event for { for i := 0; i &lt; 10; i++ { select { case evtSeg[i] =","link":"/2020/09/23/go%E5%B8%B8%E8%A7%81%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%AE%9E%E7%8E%B0.html"},{"title":"Go并发编程","text":"Thead vs. Groutine 创建时默认的 stack 的大小 JDK5 以后的 Java Thread stack 默认为1M Groutine 的 Stack 初始化大小为2k 和 KSE（Kernel Space Entity）的对应关系 Java Thread 是 1:1 Groutine 是 M:N Go的GMP调度： M：系统线程 P：Go实现的协程处理器 G：协程 从图中可看出，Processor 在不同的系统线程中，每个 Processor 都挂着准备运行的协程队列。 Processor 依次运行协程队列中的协程。 这时候问题就来了，假如一个协程运行的时间特别长，把整个 Processor 都占住了，那么在队列中的协程是不是就会被延迟的很久？ 在Go启动的时候，会有一个守护线程来去做一个计数，计每个 Processor 运行完成的协程的数量，当一段时间内发现，某个 Processor 完成协程的数量没有发生变化的时候，就会往这个正在运行的协程任务栈插入一个特别的标记，协程在运行的时候遇到非内联函数，就会读到这个标记，就会把自己中断下来，然后插到这个等候协程队列的队尾，切换到别的协程进行运行。 当某一个协程被系统中断了，例如说 io 需要等待的时候，为了提高整体的并发，Processor 会把自己移到另一个可使用的系统线程当中，继续执行它所挂的协程队列，当这个被中断的协程被唤醒完成之后，会把自己加入到其中某个 Processor 的队列里，会加入到全局等待队列中。 当一个协程被中断的时候，它在寄存器里的运行状态也会保存到这个协程对象里，当协程再次获得运行状态的时候，重写写入寄存器，继续运行。 话不多说，直接上代码，如何在代码里启动一个协程： 123456789101112131415161718192021222324func TestGroutine(t *testing.T) { for i := 0; i &lt; 10; i++ { // int 参数 go func(i int) { fmt.Println(i) }(i) // 传入参数 } // 有可能测试程序结束的非常快 加个等待 time.Sleep(time.Millisecond * 50) /** 运行结果 === RUN TestGroutine 1 4 5 2 6 3 0 8 9 7 --- PASS: TestGroutine (0.05s) */} 共享内存并发机制Lock如果你是 Java 或者 C++ 程序员，那么以下代码非常常见，使用锁来进行并发控制（可惜我是个Phper）： 123456789lock lock = ...;lock.lock();try{ // process (thread-safe)}catch(Exception ex){ }finally{ lock.unlock();} 同样Go也提供了这样的机 package sync： Mutex 互斥锁 RWLock 读写锁 不使用锁的情况： 123456789101112131415func TestCounter(t *testing.T) { counter := 0 for i := 0; i &lt; 5000; i++ { go func(i int) { counter++ }(i) } time.Sleep(time.Second * 1) t.Logf(&quot;counter = %d&quot;, counter) /** 运行结果： === RUN TestCounter TestCounter: share_memory_test.go:16: counter = 4627 --- PASS: TestCounter (1.01s) */} 可以发现结果与预期结果不一样，这是因为 conuter 变量在不同的协程里面去做自增，导致了一个并发的竞争条件，传统意义来讲就是一个不是线程安全的程序。要保证线程安全，就要对共享的内存进行锁保护。 12345678910111213141516171819202122func TestCounterThreadSafe(t *testing.T) { var mut sync.Mutex counter := 0 for i := 0; i &lt; 5000; i++ { go func(i int) { // defer 释放锁 defer func() { mut.Unlock() }() // 加锁 mut.Lock() counter++ }(i) } time.Sleep(time.Second * 1) t.Logf(&quot;counter = %d&quot;, counter) /** 运行结果： === RUN TestCounterThreadSafe TestCounterThreadSafe: share_memory_test.go:40: counter = 5000 --- PASS: TestCounterThreadSafe (1.01s) */} 这次就得到了预期结果。 WaitGroup等待所有协程完成，才能往下执行操作。 上面代码中，怕代码执行太快，所以加了 sleep。 但我们无法控制这个 sleep 需要睡眠时间。 下面来用 WaitGroup： 12345678910111213141516171819202122232425func TestCounterWaitGroup(t *testing.T) { var mut sync.Mutex var wg sync.WaitGroup counter := 0 for i := 0; i &lt; 5000; i++ { wg.Add(1) // 增加一个要等待的协程 go func(i int) { // defer 释放锁 defer func() { mut.Unlock() }() // 加锁 mut.Lock() counter++ wg.Done() // 一个协程完成了 }(i) } wg.Wait() // 等待所有添加的协程完成 才继续向下运行 t.Logf(&quot;counter = %d&quot;, counter) /** 运行结果： === RUN TestCounterWaitGroup TestCounterWaitGroup: share_memory_test.go:66: counter = 5000 --- PASS: TestCounterWaitGroup (0.00s) */} CSP并发机制有人可能会说不就是 Actor Model 嘛 CSP vs. Actor 和 Actor 的直接通讯不同，CSP模式则是通过Channel进行通讯的，更松耦合一些。 Go中的channel是有容量限制并且独立于处理Groutine，而如Erlang，Actor模式中的mailbox容量是无限的，接收进程也总是被动地处理消息。 Channel Go中Channel的基本机制： 上图左边（非缓冲channel）： 通讯的两方必须同时在channel的两边，才能完成这次交互。任何一方不在，另一方就会被阻塞在那里等待，直到等到另一方才能完成这次交互。 上图右边（缓冲channel）： 就是对这个channel设置容量，在未满的情况下，放消息的人就能放进去，如果满了，就会发生阻塞等待。 等待拿消息的人去拿，空出来容量。反之，拿消息一样。 12345678910111213141516171819202122func service() string { time.Sleep(time.Millisecond * 50) // 模拟阻塞 return &quot;Done&quot;}func otherTask() { fmt.Println(&quot;working on something else&quot;) time.Sleep(time.Millisecond * 100) // 模拟阻塞 fmt.Println(&quot;Task is done.&quot;)}func TestService(t *testing.T) { fmt.Println(service()) otherTask() /** 运行结果： === RUN TestService Done working on something else Task is done. --- PASS: TestService (0.16s) */} 由运行结果可知，完全是串行的，耗时为 0.16s 对 service进行改造，在调用的时候启动另外一个协程去执行，而不是阻塞当前写的协程。 123456789101112131415161718func service() string { time.Sleep(time.Millisecond * 50) // 模拟阻塞 return &quot;Done&quot;}func otherTask() { fmt.Println(&quot;working on something else&quot;) time.Sleep(time.Millisecond * 100) // 模拟阻塞 fmt.Println(&quot;Task is done.&quot;)}func AsyncService() chan string { retCh := make(chan string) // 创建一个非缓冲string类型的channel //retCh := make(chan string, 1) // 创建一个容量为1 string类型的缓冲channel go func() { ret := service() fmt.Println(&quot;returned result.&quot;) retCh","link":"/2020/09/20/go%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B.html"},{"title":"Go的函数及可变参数和defer","text":"函数是一等公民： 可以有多个返回值 所有参数都是值传递：slice、map、channel 会有传引用的错觉 函数可以作为变量的值 函数可以作为参数和返回值 123456789func returnMultiValues() (int, int) { // 返回两个值 return rand.Intn(10), rand.Intn(20)}func TestFn(t *testing.T) { a, b := returnMultiValues() t.Log(a, b) // 1 7} 可变参数： 123456789101112131415161718func Sum(ops ...int) int { ret := 0 for _, op := range ops { ret += op } return ret}func TestVarParams(t *testing.T) { t.Log(Sum(1, 2, 3, 4)) t.Log(Sum(1, 2, 3, 4, 5)) /** 运行结果 === RUN TestVarParams TestVarParams: func_test.go:48: 10 TestVarParams: func_test.go:49: 15 --- PASS: TestVarParams (0.00s) */} defer： 在最后执行完执行，通常我们用于释放资源及释放锁 1234567891011121314func TestDefer(t *testing.T) { defer func() { t.Log(&quot;Clean resources&quot;) }() t.Log(&quot;Started&quot;) // panic 手动触发宕机 panic(&quot;Fatal error&quot;) // defer 仍然会执行 /** 运行结果 === RUN TestDefer TestDefer: func_test.go:56: Started TestDefer: func_test.go:54: Clean resources --- FAIL: TestDefer (0.00s) */}","link":"/2020/09/20/go%E7%9A%84%E5%87%BD%E6%95%B0%E5%8F%8A%E5%8F%AF%E5%8F%98%E5%8F%82%E6%95%B0%E5%92%8Cdefer.html"},{"title":"Go编写好的错误处理","text":"Go的错误机制： 没有异常机制 error 类型实现了 error 接口 123type error interface { Error() string} 可以通过 errors.News 来快速创建错误实例 1errors.News(&quot;n must be in the range [0,10]&quot;) 拿Fibonacci举例： 12345678910111213141516171819func GetFibonacci(n int) []int { fibList := []int{1, 2} for i := 2; i &lt; n; i++ { fibList = append(fibList, fibList[i-2]+fibList[i-1]) } return fibList}func TestGetFibonacci(t *testing.T) { t.Log(GetFibonacci(10)) t.Log(GetFibonacci(-10)) /** 运行结果 === RUN TestGetFibonacci TestGetFibonacci: err_test.go:15: [1 2 3 5 8 13 21 34 55 89] TestGetFibonacci: err_test.go:21: [1 2] --- PASS: TestGetFibonacci (0.00s) */} 可以看到没有对入参进行校验 现在做下校验： 12345678910111213141516171819202122232425func GetFibonacci(n int) ([]int, error) { if n &lt; 2 n &gt; 100 { return nil, errors.New(&quot;n should be in [2,100]&quot;) } fibList := []int{1, 2} for i := 2; i &lt; n; i++ { fibList = append(fibList, fibList[i-2]+fibList[i-1]) } return fibList, nil}func TestGetFibonacci(t *testing.T) { // 如果有错误进行错误输出 if v, err := GetFibonacci(-10); err != nil { t.Error(err) } else { t.Log(v) } /** 运行结果 === RUN TestGetFibonacci TestGetFibonacci: err_test.go:22: n should be in [2,100] --- FAIL: TestGetFibonacci (0.00s) */} 假设现在有个需求，返回的值是太小了还是太大了，返回不同的错误，最简单的方法直接改造GetFibonacci： 12345678910111213141516func GetFibonacci(n int) ([]int, error) { if n &lt; 2 { return nil, errors.New(&quot;n should be not less than 2&quot;) } if n &gt; 100 { return nil, errors.New(&quot;n should be not larger than 100&quot;) } fibList := []int{1, 2} for i := 2; i &lt; n; i++ { fibList = append(fibList, fibList[i-2]+fibList[i-1]) } return fibList, nil} 如果区分错误类型，依靠字符串去匹配简直太麻烦还容易出错，最常见的解决方法，定义两个预置的错误： 1234567891011121314151617181920212223242526272829303132333435363738var LessThanTwoError = errors.New(&quot;n should be not less than 2&quot;)var LargerThenHundredError = errors.New(&quot;n should be not larger than 100&quot;)func GetFibonacci(n int) ([]int, error) { if n &lt; 2 { return nil, LessThanTwoError } if n &gt; 100 { return nil, LargerThenHundredError } fibList := []int{1, 2} for i := 2; i &lt; n; i++ { fibList = append(fibList, fibList[i-2]+fibList[i-1]) } return fibList, nil}func TestGetFibonacci(t *testing.T) { // 如果有错误进行错误输出 if v, err := GetFibonacci(-10); err != nil { // 假如调用者需要判断错误的就比较简单了 if err == LessThanTwoError { fmt.Println(&quot;It is less.&quot;) } t.Error(err) } else { t.Log(v) } /** 运行结果 === RUN TestGetFibonacci It is less. TestGetFibonacci: err_test.go:36: n should be not less than 2 --- FAIL: TestGetFibonacci (0.00s) */} 总结： 定义不同的错误变量，以便于判断错误类型 及早失败，避免嵌套，提高代码可读性 panic和recoverpanicpanic： panic 用于不可以恢复的错误 panic 退出前会执行 defer 指定的内容 panic vs. os.Exit： os.Exit 退出时不会调用 defer 指定的函数 os.Exit 退出时不输出当前调用栈的信息 123456789101112131415161718192021222324252627282930313233343536373839404142func TestExit(t *testing.T) { fmt.Println(&quot;Start&quot;) os.Exit(-1) /** 运行结果 === RUN TestExit Start Process finished with exit code 1 */}func TestPanic(t *testing.T) { defer func() { fmt.Println(&quot;Finally!&quot;) }() fmt.Println(&quot;Start&quot;) panic(errors.New(&quot;Something wrong!&quot;)) /** 运行结果： === RUN TestPanic Start Finally! --- FAIL: TestPanic (0.00s) panic: Something wrong! [recovered] panic: Something wrong! goroutine 6 [running]: testing.tRunner.func1.1(0x1119860, 0xc000046510) /usr/local/Cellar/go/1.14.2_1/libexec/src/testing/testing.go:940 +0x2f5 testing.tRunner.func1(0xc00011a120) /usr/local/Cellar/go/1.14.2_1/libexec/src/testing/testing.go:943 +0x3f9 panic(0x1119860, 0xc000046510) /usr/local/Cellar/go/1.14.2_1/libexec/src/runtime/panic.go:969 +0x166 command-line-arguments.TestPanic(0xc00011a120) /Users/gaobinzhan/Documents/Go/learning/src/test/err_test.go:65 +0xd7 testing.tRunner(0xc00011a120, 0x114afa0) /usr/local/Cellar/go/1.14.2_1/libexec/src/testing/testing.go:991 +0xdc created by testing.(*T).Run /usr/local/Cellar/go/1.14.2_1/libexec/src/testing/testing.go:1042 +0x357 Process finished with exit code 1 */} recover大家在写c++或者php代码的时候，总有一种习惯不希望这个程序被中断或者退出，用来捕获。 php代码： 12345try {} catch (\\Throwable $throwable) { } c++ 代码： 12345try{ ...}catch(...){ } go代码： 12345defer func(){ if err := recover(); err != nil { // 恢复错误 }}() 12345678910111213141516func TestRecover(t *testing.T) { defer func() { if err := recover(); err != nil { // 没有写错误恢复 只是打印出来了 fmt.Println(&quot;recovered from&quot;, err) } }() fmt.Println(&quot;Start&quot;) panic(errors.New(&quot;Something wrong!&quot;)) /** 运行结果： === RUN TestRecover Start recovered from Something wrong! --- PASS: TestRecover (0.00s) */} 最常见的”错误恢复”： 12345defer func() { if err := recover(); err != nil { log.Error(&quot;recovered panic&quot;,err) }}() 当心！recover 成为恶魔： 形成僵尸服务进程，导致 health check 失效。 “Let it Crash!” 往往是我们恢复不确定性错误的最好方法。 就如上常见的“错误恢复”只是记录了一下，这样的恢复方式是非常危险的。 一定要当心我们自己 recover 在做的事，因为我们 recover 的时候并不去检测错误到底发生了什么错误，而是简单的记录了一下或者忽略。 这时候可能是系统里面的某些核心资源已经消耗完了，我们这样把它强制恢复掉，其实系统依然不能够正常地工作的，还是导致我们的一些健康检查程序 health check 没有办法检查出当前系统的问题。 因为很多的这种 health check 只是检查当前的系统进程在还是不在，因为我们的进程是在的，所以就会导致一种僵尸服务进程，它好像活着，但它也不能提供服务。 这种情况下个人认为倒不如采用一种可恢复的设计模式其中的一种叫 Let it Crash ，干脆 Crash掉，一旦Crash掉 守护进程 ，就会帮我们的服务进程重新提起来。","link":"/2020/09/20/go%E7%BC%96%E5%86%99%E5%A5%BD%E7%9A%84%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86.html"},{"title":"Go面向对象编程","text":"Is Go an object-oriented language? Yes and no. Although Go has types and methods and allows an object oriented style of programming, there is no type hierarchy. The concept of “interface” in Go provides a different approach that we believe is easy to use and in some ways more general. Also, the lack of a type hierarchy makes “objects” in Go feel much more lightweight than in languages such as C++ or Java. 行为的定义和实现结构体定义： 12345type Employee struct { Id string Name string Age int} 实例创建及初始化： 123456789101112131415161718192021222324func TestCreateEmployee(t *testing.T) { e := Employee{&quot;0&quot;, &quot;Bob&quot;, 20} // 分别把值放进去 e1 := Employee{Name: &quot;Mike&quot;, Age: 30} // 指定某个field的值 e2 := new(Employee) // new关键字 去创建指向实例的指针 这里返回的引用/指针 相当于 e:=Employee{} e2.Id = &quot;2&quot; // 通过 example.filed 去赋值 e2.Name = &quot;Rose&quot; e2.Age = 22 t.Log(e) t.Log(e1) t.Log(e1.Id) t.Log(e2) t.Logf(&quot;e is %T&quot;, e) t.Logf(&quot;e2 is %T&quot;, e2) /** 运行结果： === RUN TestCreateEmployee TestCreateEmployee: encap_test.go:18: {0 Bob 20} TestCreateEmployee: encap_test.go:19: { Mike 30} TestCreateEmployee: encap_test.go:20: TestCreateEmployee: encap_test.go:21: &amp;{2 Rose 22} TestCreateEmployee: encap_test.go:22: e is test.Employee TestCreateEmployee: encap_test.go:23: e2 is *test.Employee --- PASS: TestCreateEmployee (0.00s) */} 行为定义： 1234567891011121314// 第一种定义方式在实例对应方法被调用时，实例的成员会进行值复制func (e Employee) String() string { return fmt.Sprintf(&quot;ID:%s-Name:%s-Age:%d&quot;, e.Id, e.Name, e.Age)}func TestStructOperations(t *testing.T) { e := Employee{&quot;0&quot;, &quot;Bob&quot;, 20} t.Log(e.String()) /** 运行结果： === RUN TestStructOperations TestStructOperations: encap_test.go:46: ID:0-Name:Bob-Age:20 --- PASS: TestStructOperations (0.00s) */} 1234567891011121314// 通常情况下为了避免内存拷贝我们使用第二种定义方式func (e *Employee) String() string { return fmt.Sprintf(&quot;ID:%s/Name:%s/Age:%d&quot;, e.Id, e.Name, e.Age)}func TestStructOperations(t *testing.T) { e := Employee{&quot;0&quot;, &quot;Bob&quot;, 20} t.Log(e.String()) /** 运行结果： === RUN TestStructOperations TestStructOperations: encap_test.go:51: ID:0/Name:Bob/Age:20 --- PASS: TestStructOperations (0.00s) */} 在Go语言中不管通过指针访问还是通过实例访问，都是一样的 那么这两种定义没有区别吗？？ 1234567891011121314151617func (e *Employee) String() string { fmt.Printf(&quot;Address is %x \\n&quot;, unsafe.Pointer(&amp;e.Name)) return fmt.Sprintf(&quot;ID:%s/Name:%s/Age:%d&quot;, e.Id, e.Name, e.Age)}func TestStructOperations(t *testing.T) { e := Employee{&quot;0&quot;, &quot;Bob&quot;, 20} fmt.Printf(&quot;Address is %x \\n&quot;, unsafe.Pointer(&amp;e.Name)) t.Log(e.String()) /** 运行结果： === RUN TestStructOperations Address is c000060370 Address is c000060370 TestStructOperations: encap_test.go:54: ID:0/Name:Bob/Age:20 --- PASS: TestStructOperations (0.00s) */} 可以发现两个地址一致 1234567891011121314151617func (e Employee) String() string { fmt.Printf(&quot;Address is %x \\n&quot;, unsafe.Pointer(&amp;e.Name)) return fmt.Sprintf(&quot;ID:%s-Name:%s-Age:%d&quot;, e.Id, e.Name, e.Age)}func TestStructOperations(t *testing.T) { e := Employee{&quot;0&quot;, &quot;Bob&quot;, 20} fmt.Printf(&quot;Address is %x \\n&quot;, unsafe.Pointer(&amp;e.Name)) t.Log(e.String()) /** 运行结果： === RUN TestStructOperations Address is c000092370 Address is c0000923a0 TestStructOperations: encap_test.go:55: ID:0-Name:Bob-Age:20 --- PASS: TestStructOperations (0.00s) */} 这时候两个地址不一致，说明结构体的数据被复制了，会造成开销 Go语言的相关接口Java的接口与依赖： Go的 Duck Type 式接口实现： 接口为非入侵性，实现不依赖与接口定义 所以接口的定义可以包含在接口使用者包内 123456789101112131415161718192021type Programmer interface { WriteHelloWorld() string}type GoProgrammer struct {}func (g *GoProgrammer) WriteHelloWorld() string { return &quot;Hello World&quot;}func TestClient(t *testing.T) { var p Programmer p = new(GoProgrammer) t.Log(p.WriteHelloWorld()) /** 运行结果： === RUN TestClient TestClient: interface_test.go:19: Hello World --- PASS: TestClient (0.00s) */} 接口变量： 自定义类型： type IntConvertionFn func(n int) int type MyPoint int 扩展和复用复合： 匿名类型嵌入： 它不是继承，如果我们把“内部 struct”看作父类，把“外部 struct” 看作子类，会发现如下问题： 不支持子类替换 子类并不是真正继承了父类的方法 123456789101112131415161718192021222324252627282930313233type Pet struct {}func (p *Pet) Speak() { fmt.Print(&quot;...&quot;)}func (p *Pet) SpeakTo(string string) { p.Speak() fmt.Println(&quot; &quot;, string)}type Dog struct { p *Pet}func (d *Dog) Speak() { fmt.Print(&quot;Wang!&quot;)}func (d *Dog) SpeakTo(string string) { d.p.SpeakTo(string)}func TestDog(t *testing.T) { dog := new(Dog) dog.SpeakTo(&quot;Gao&quot;) // 没有打印 Wang! 需要改动 dog中SpeakTo方法 /** 运行结果： === RUN TestDog ... Gao --- PASS: TestDog (0.00s) */} 多态与空接口多态： 123456789101112131415161718192021222324252627282930313233343536type Code string // 自定义类型type Programmer interface { WriteHelloWorld() Code}type GoProgrammer struct {}type PhpProgrammer struct {}func (g *GoProgrammer) WriteHelloWorld() Code { return &quot;fmt.Println(\\&quot;Hello World\\&quot;)&quot;}func (p *PhpProgrammer) WriteHelloWorld() Code { return &quot;echo \\&quot;Hello World\\&quot;&quot;}func writeFirstProgram(p Programmer) { fmt.Printf(&quot;%T %v\\n&quot;, p, p.WriteHelloWorld())}func TestPolymorphism(t *testing.T) { goProg := new(GoProgrammer) phpProg := new(PhpProgrammer) writeFirstProgram(goProg) writeFirstProgram(phpProg) /** 运行结果 === RUN TestPolymorphism *test.GoProgrammer fmt.Println(&quot;Hello World&quot;) *test.PhpProgrammer echo &quot;Hello World&quot; --- PASS: TestPolymorphism (0.00s) */} 空接口与断言： 空接口可以表示任何类型 通过断言来将空接口转换为制定类型 v, ok := p.(int) // ok=true 时为转换成功 123456789101112131415161718192021222324252627282930313233343536func DoSomething(p interface{}) { // 如果传入的参数能被断言成一个整型 if i, ok := p.(int); ok { fmt.Println(&quot;Integer&quot;, i) return } // 如果传入的参数能被断言成一个字符型 if s, ok := p.(string); ok { fmt.Println(&quot;String&quot;, s) return } fmt.Println(&quot;Unknow Type&quot;) // 也可以通过switch来判断 /*switch v := p.(type) { case int: fmt.Println(&quot;Integer&quot;, v) case string: fmt.Println(&quot;String&quot;, v) default: fmt.Println(&quot;Unknow Type&quot;) }*/}func TestEmptyInterfaceAssertion(t *testing.T) { DoSomething(10) DoSomething(&quot;gaobinzhan&quot;) /** 运行结果 === RUN TestEmptyInterfaceAssertion Integer 10 String gaobinzhan --- PASS: TestEmptyInterfaceAssertion (0.00s) */} Go接口最佳实践：","link":"/2020/09/20/go%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B.html"},{"title":"Hello,Go","text":"Go的特点 只有25个关键字 强类型语言 垃圾回收 指针直接访问内存 开发环境构建 1.8之前必须设置 1.8之后没用设置，将使用默认值 扩展名必须为go 编写第一个go程序hello.go 12345678910package main // 包，表明代码所在的模块import ( &quot;fmt&quot;) // 引入代码依赖// 功能实现func main() { fmt.Println(&quot;Hello, World!&quot;)} 两种运行方式： 12$ go run hello.goHello, World! 12345$ go build hello.go$ lshello hello.go$ ./helloHello, World! 应用程序入口： 必须是main包 package main 必须是main 方法 func main() 文件名不一定是main.go 退出返回值： Go中main函数不支持任何返回值 通过os.Exit来返回状态 获取命令行参数： Go中main函数不支持任何返回值 main函数不支持传入参数 func main(arg []string) 在程序中直接通过os.Args获取命令行参数 12345678910111213package main // 包，表明代码所在的模块import ( &quot;fmt&quot; &quot;os&quot;) // 引入代码依赖// 功能实现func main() { fmt.Println(&quot;Hello, World!&quot;) fmt.Println(os.Args[0], os.Args[1]) // 默认情况下 参数0返回可执行文件路径 os.Exit(100)} 12345$ go run hello.go gaobinzhanHello, World!参数0：/var/folders/qr/9vkwk7xn5rzbtnmykx7sxyv00000gn/T/go-build024626496/b001/exe/hello参数1：gaobinzhanexit status 100 公众号 : Tinkled","link":"/2020/09/20/hellogo.html"},{"title":"Laravel5框架安装Markdown编辑器","text":"composer require chenhua/laravel5-markdown-editor 2.完成上面操作，修改 config/app.php 中 providers 数组Chenhua\\MarkdownEditor\\MarkdownEditorServiceProvider::class, 3. 修改 config/app.php 中 aliases 数组'MarkdownEditor' =&gt; Chenhua\\MarkdownEditor\\Facades\\MarkdownEditor::class, 4. 执行 artisan 命令，生成 config/markdowneditor.php 配置文件php artisan vendor:publish --tag=markdown 5. 根据自己所需修改 config/markdowneditor.php 配置文件使用方法在 xxx.blade.php 相应位置添加代码12345 @include('markdown::encode',['editors'=&gt;['test-editormd']]) 解析 markdown 格式文本为 html 格式① 前端js方式解析 markdown 文本 1234567 # 这是一个h1标签## 这是一个h2标签 @include('markdown::decode',['editors'=&gt;['doc-content']]) ② PHP方式解析 markdown 文本 1echo MarkdownEditor::parse(&quot;#中间填写markdown格式的文本&quot;); 效果图：","link":"/2020/09/20/laravel5%E6%A1%86%E6%9E%B6%E5%AE%89%E8%A3%85markdown%E7%BC%96%E8%BE%91%E5%99%A8.html"},{"title":"Laravel使用repository模式","text":"什么是Repository模式？Repository 模式是架构模式，在设计架构时，才有参考价值； Repository 模式主要是封装数据查询和存储逻辑； Repository 模式实际用途：更换、升级 ORM 引擎，不影响业务逻辑； Repository 模式能提高测试效率，单元测试时，用 Mock 对象代替实际的数据库存取，可以成倍地提高测试用例运行速度。 详细了解 https://blog.csdn.net/ZuoAnYinXiang/article/details/80711936 REPOSITORY模式是怎样工作的呢？Repository 是一个独立的层，介于领域层与数据映射层（数据访问层）之间。它的存在让领域层感觉不到数据访问层的存在，它提供一个类似集合的接口提供给领域层进行领域对象的访问。Repository 是仓库管理员，领域层需要什么东西只需告诉仓库管理员，由仓库管理员把东西拿给它，并不需要知道东西实际放在哪。 详细了解 http://www.jquerycn.cn/a\\_17077 当controller不使用Repository模式 ，在controller的各个方法中存在花式的数据库操作(这是非常糟糕的)，如果需求变更，重写将变得非常困难。 Laravel如何部署Laravel 5 Repositories用于抽象数据层，使我们的应用程序更易于维护。 安装composer require prettus/l5-repository laravel部署laravel&gt;=5.5在框架的config/app.php中的providers数组添加如下代码：‘ Prettus\\Repository\\Providers\\RepositoryServiceProvider::class, 发布配置 php artisan vendor:publish --provider &quot;Prettus\\Repository\\Providers\\RepositoryServiceProvider&quot; 命令要生成模型所需的所有内容，请运行以下命令： php artisan make:entity Post 这将创建Controller，Validator，Model，Repository，Presenter和Transformer类。它还将创建一个新的服务提供程序，用于将Eloquent Repository与其相应的Repository Interface绑定。要加载它，只需将其添加到AppServiceProvider @ register方法： $this-&gt;app-&gt;register(RepositoryServiceProvider::class); 自定义使用方法在你的控制器中 123456789101112131415161718namespace App\\Http\\Controllers;use App\\PostRepository;class PostsController extends Controller { /** * @var PostRepository */ protected $repository; public function __construct(PostRepository $repository){ $this-&gt;repository = $repository; } public function index(){ return $this-&gt;repository-&gt;all(); }} 更多操作：GitHub : https://github.com/andersao/l5-repository/tree/3.0-develop","link":"/2019/10/27/laravel%E4%BD%BF%E7%94%A8repository%E6%A8%A1%E5%BC%8F.html"},{"title":"Laravel使用全文检索引擎TNTSearch和中文分词jieba-php实现中文全文搜索","text":"搜索基本就是每个网站必备的虽然是搜索 但是去搜索我是一个php程序员，我是一个java程序员完全是两个概念一般搜索都是 sql 的 like 去查询比如 php是世界上最好的语言 这句话如果我们用 sql 的 like 的 % 模糊查询的话搜索的词要连贯并且一字不差； 可以搜 like 'php是%' 也可以搜 like '%最好的语言' 或者 like '%世界上最好%' ； 但你要是搜索 世界最好语言 还能搜索到吗？？像 百度谷歌 可能会让用户一字不差的输入进去吗这时候就会用到我们的全文搜索简单的来说全文搜索的原理就是把内容按关键字给拆分了比如说上面这句话拆成 php 、世界 、最好 、 语言 也就是php不用依赖第三方实现全文搜索的TNTSearch 英文句子实现比较简单可以按空格去拆分而中文 它并不懂 世界 、最好 、 语言 这些是词语会把它给拆成单个字这时候就需要中文分词了中文分词就是会智能按中文的词语来拆分成关键字 作为 TNTSearch 中文分词的jieba-php 为了方便 先创建一个测试表和测试模型 php artisan make:model Models/Test -m 添加字段/database/migrations/2019_01_16_055730_create_tests_table.php 1234567891011121314/** * Run the migrations. * * @return void */public function up(){ Schema::create('tests', function (Blueprint $table) { $table-&gt;increments('id'); $table-&gt;string('title')-&gt;default('')-&gt;comment('测试标题'); $table-&gt;mediumText('content')-&gt;comment('测试内容'); $table-&gt;timestamps(); });} .env文件数据库配置 就不用多说了吧 运行迁移命令生成数据表 php artisan migrate 创建数据填充文件 php artisan make:seed TestsTableSeeder 生成测试数据/database/seeds/TestsTableSeeder.php 12345678910111213public function run() { DB::table('tests')-&gt;insert([ [ 'title' =&gt; 'TNTSearch', 'content' =&gt; 'PHP编写的全文搜索引擎,非常强大' ], [ 'title' =&gt; 'jieba-php', 'content' =&gt; '强大的中文分词，最好的php中文分词，中文拆分成关键字' ] ]); } 运行填充 php artisan db:seed --class=TestsTableSeeder 这时候可以看到数据表里面有数据了 接下来测试 /routes/web.php 1234use App\\Models\\Test;Route::get('search', function () { dump(Test::all()-&gt;toArray());}); 进入web页面 显示以下数据 依赖 SQLite 存储索引再确认下自己的 php 是否开启以下扩展： pdo_sqlite sqlite3 mbstring vanry为我们造的轮子 laravel-scout-tntsearch 直接通过composer安装 composer require vanry/laravel-scout-tntsearch config/app.php 123456// config/app.php'providers' =&gt; [ // ... Laravel\\Scout\\ScoutServiceProvider::class, Vanry\\Scout\\TNTSearchScoutServiceProvider::class,], 在 .env 文件中添加 SCOUT_DRIVER=tntsearch然后就可以将 scout.php 配置文件发布到 config 目录。 php artisan vendor:publish --provider=&quot;Laravel\\Scout\\ScoutServiceProvider&quot; 在 config/scout.php 中添加: 123456789101112131415161718192021222324252627282930313233343536373839404142'tntsearch' =&gt; [ 'storage' =&gt; storage_path('indexes'), //必须有可写权限 'fuzziness' =&gt; env('TNTSEARCH_FUZZINESS', false), 'searchBoolean' =&gt; env('TNTSEARCH_BOOLEAN', false), 'asYouType' =&gt; false, 'fuzzy' =&gt; [ 'prefix_length' =&gt; 2, 'max_expansions' =&gt; 50, 'distance' =&gt; 2, ], 'tokenizer' =&gt; [ 'driver' =&gt; env('TNTSEARCH_TOKENIZER', 'default'), 'jieba' =&gt; [ 'dict' =&gt; 'small', //'user_dict' =&gt; resource_path('dicts/mydict.txt'), //自定义词典路径 ], 'analysis' =&gt; [ 'result_type' =&gt; 2, 'unit_word' =&gt; true, 'differ_max' =&gt; true, ], 'scws' =&gt; [ 'charset' =&gt; 'utf-8', 'dict' =&gt; '/usr/local/scws/etc/dict.utf8.xdb', 'rule' =&gt; '/usr/local/scws/etc/rules.utf8.ini', 'multi' =&gt; 1, 'ignore' =&gt; true, 'duality' =&gt; false, ], ], 'stopwords' =&gt; [ '的', '了', '而是', ],], 目前支持 jieba, phpanalysis 和 scws 中文分词，在 .env 文件中配置 TNTSEARCH_TOKENIZER 可选值 为 jieba, analysis, scws, default， 其中 default 为 TNTSearch 自带的分词器。考虑到性能问题，建议生产环境使用由C语言编写的scws分词扩展。 使用 jieba 分词器，需安装 fukuball/jieba-php composer require fukuball/jieba-php 使用 phpanalysis 分词器，需安装 lmz/phpanalysis composer require lmz/phpanalysis 使用 scws 分词器，需安装 vanry/scws composer require vanry/scws 分别在 config/scout.php 中的 jieba, analysis 和 scws 中修改配置。 这里我使用的jieba 先安装 然后在.env文件配置TNTSEARCH_TOKENIZER=jieba 模型中定义全文搜索；/app/Models/Test.php","link":"/2019/10/27/laravel%E4%BD%BF%E7%94%A8%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2%E5%BC%95%E6%93%8Etntsearch%E5%92%8C%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8Djieba-php%E5%AE%9E%E7%8E%B0%E4%B8%AD%E6%96%87%E5%85%A8%E6%96%87.html"},{"title":"Linux五大网络IO模型图解","text":"[TOC] 对于一个应用程序即一个操作系统进程来说，它既有内核空间(与其他进程共享),也有用户空间(进程私有)，它们都是处于虚拟地址空间中。用户进程是无法访问内核空间的，它只能访问用户空间，通过用户空间去内核空间复制数据，然后进行处理。 阻塞io(同步io)发起请求就一直等待，直到数据返回。好比你去商场试衣间，里面有人，那你就一直在门外等着。(全程阻塞) 非阻塞io(同步io)不管有没有数据都返回，没有就隔一段时间再来请求，如此循环。好比你要喝水，水还没烧开，你就隔段时间去看一下饮水机，直到水烧开为止。(复制数据时阻塞) io复用(同步io)I/O是指网络I/O,多路指多个TCP连接(即socket或者channel）,复用指复用一个或几个线程。意思说一个或一组线程处理多个连接。比如课堂上学生做完了作业就举手，老师就下去检查作业。(对一个IO端口，两次调用，两次返回，比阻塞IO并没有什么优越性；关键是能实现同时对多个IO端口进行监听，可以同时对多个读/写操作的IO函数进行轮询检测，直到有数据可读或可写时，才真正调用IO操作函数。) 信号驱动io(同步io)事先发出一个请求，当有数据后会返回一个标识回调，这时你可以去请求数据。好比银行排号，当叫到你的时候，你就可以去处理业务了(复制数据时阻塞)。 异步io发出请求就返回，剩下的事情会异步自动完成，不需要做任何处理。好比有事秘书干，自己啥也不用管。 总结五种IO的模型：阻塞IO、非阻塞IO、多路复用IO、信号驱动IO和异步IO；前四种都是同步IO，在内核数据copy到用户空间时都是阻塞的。 阻塞IO和非阻塞IO的区别在于第一步，发起IO请求是否会被阻塞，如果会那就是传统的阻塞IO，如果不会那就是非阻塞IO。 同步IO和异步IO的区别就在于第二个步骤是否阻塞，如果实际的IO读写阻塞请求进程，那么就是同步IO；如果不阻塞，而是操作系统帮你做完IO操作再将结果返回给你，那么就是异步IO","link":"/2020/09/20/linux%E4%BA%94%E5%A4%A7%E7%BD%91%E7%BB%9Cio%E6%A8%A1%E5%9E%8B%E5%9B%BE%E8%A7%A3.html"},{"title":"php SPL四种常用的数据结构","text":"123456789$stack = new SplStack();$stack-&gt;push('data1');$stack-&gt;push('data2');$stack-&gt;push('data3');echo $stack-&gt;pop();//输出结果为//data3 12345678$queue = new SplQueue();$queue-&gt;enqueue(&quot;data1&quot;);$queue-&gt;enqueue(&quot;data2&quot;);$queue-&gt;enqueue(&quot;data3&quot;);echo $queue-&gt;dequeue();//输出结果为//data1 12345678$heap = new SplMinHeap();$heap-&gt;insert(&quot;data1&quot;);$heap-&gt;insert(&quot;data2&quot;);echo $heap-&gt;extract();//输出结果为//data1 123456789101112$array = new SplFixedArray(5);$array[0]=1;$array[3]=3;$array[2]=2;var_dump($array);//输出结果为// object(SplFixedArray)[1]// public 0 =&gt; int 1// public 1 =&gt; null// public 2 =&gt; int 2// public 3 =&gt; int 3// public 4 =&gt; null 原文：https://blog.csdn.net/zhengwish/article/details/51742264","link":"/2020/09/20/php-spl%E5%9B%9B%E7%A7%8D%E5%B8%B8%E7%94%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.html"},{"title":"php yield关键字及协程实现","text":"迭代是指反复执行一个过程，每执行一次叫做迭代一次 php提供了统一的迭代器接口，之前文章我已经写过了。传送门 通过实现Iterator接口，可以自行决定如何遍历。 生成器 相比迭代器，生成器提供了更容易的方法来简单实现对象的迭代，性能开销和复杂性大大降低。 一个生成器函数看起来更像一个普通的函数，不同的是普通函数返回的是一个值，而生成器可以yield生成许多个值。 生成器yield关键字不是返回值，而是返回Generator对象，不能被实力化，且继承了Iterator接口。 生成器优点： 生成器会对php应用的性能有非常大的影响。 代码运行时，节省大量内存。 适合计算大量的数据。 颠覆常识的yield大家都知道range函数创建一个包含指定范围的元素的数组。","link":"/2020/09/23/php-yield%E5%85%B3%E9%94%AE%E5%AD%97%E5%8F%8A%E5%8D%8F%E7%A8%8B%E5%AE%9E%E7%8E%B0.html"},{"title":"php用select实现I&#x2F;O复用","text":"在Linux Socket服务器短编程时，为了处理大量客户的连接请求，需要使用非阻塞I/O和复用，select、poll和epoll是Linux API提供的I/O复用方式，其实I/O多路复用就是通过一种机制，可以监视多个描述符，一旦某个描述符就绪(一般是读就绪或者写就绪)，能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的。现在比较受欢迎的的nginx就是使用epoll来实现I/O复用支持高并发，所以理解好select，poll，epoll对于nginx如何应对高并发还是很有帮助的。 select调用过程 select缺点 单个进程监控的文件描述符有限，通常为1024*8个文件描述符。 当然可以改进，由于select采用轮询方式扫描文件描述符。文件描述符数量越多，性能越差。 内核/用户数据拷贝频繁，操作复杂。 select在调用之前，需要手动在应用程序里将要监控的文件描述符添加到fed_set集合中。然后加载到内核进行监控。用户为了检测时间是否发生，还需要在用户程序手动维护一个数组，存储监控文件描述符。当内核事件发生，在将fed_set集合中没有发生的文件描述符清空，然后拷贝到用户区，和数组中的文件描述符进行比对。再调用selecct也是如此。每次调用，都需要了来回拷贝。 轮回时间效率低 select返回的是整个数组的句柄。应用程序需要遍历整个数组才知道谁发生了变化。轮询代价大。 select是水平触发 应用程序如果没有完成对一个已经就绪的文件描述符进行IO操作。那么之后select调用还是会将这些文件描述符返回，通知进程。 代码实现Worker.php","link":"/2020/09/23/php%E7%94%A8select%E5%AE%9E%E7%8E%B0i-o%E5%A4%8D%E7%94%A8.html"},{"title":"php迭代器","text":"博主： gaobinzhan 发布时间：2018 年 12 月 25 日 701次浏览 暂无评论 945字数 分类： PHP 1234567891011121314151617181920212223242526272829class Season implements Iterator{ private $position = 0;//指针指向0 private $arr = array('一','二','三','四'); //重置迭代器 public function rewind(){ return $this -&gt; position = 0; } //验证迭代器是否有数据 public function valid() {// return isset($this -&gt; arr[$this -&gt; position]); return $this-&gt;positionarr); } //获取当前内容 public function current(){ return $this -&gt; arr[$this -&gt; position]; } //获取迭代器位置key public function key(){ return $this -&gt; position; } //移动key到下一个 public function next() { ++$this -&gt; position; }}$obj = new Season();foreach ($obj as $k =&gt; $v){ echo $k.':'.$v.'';} 结果： 0:一1:二2:三 3:四 php有对数组指针的操作，可不用定义$position1.key();从关联数组中取得键名，没有取到返回NULL2.current();返回数组中当前单元3.next();将数组中的内部指针向前移动一位4.prev();将数组的内部指针倒回一位5.reset();将数组的内部指针指向第一个单元 6.end();将数组的内部指针指向最后一个单元 1234567891011121314151617181920212223242526272829class Season implements Iterator{ private $position = 0;//指针指向0 private $arr = array('一','二','三','四'); //重置迭代器 public function rewind(){ return $this -&gt; position = 0; } //验证迭代器是否有数据 public function valid() {// return isset($this -&gt; arr[$this -&gt; position]); return $this-&gt;positionarr); } //获取当前内容 public function current(){ return $this -&gt; arr[$this -&gt; position]; } //获取迭代器位置key public function key(){ return $this -&gt; position; } //移动key到下一个 public function next() { ++$this -&gt; position; }}$obj = new Season();foreach ($obj as $k =&gt; $v){ echo $k.':'.$v.'';} 结果： 0:一1:二2:三 3:四 php有对数组指针的操作，可不用定义$position1.key();从关联数组中取得键名，没有取到返回NULL2.current();返回数组中当前单元3.next();将数组中的内部指针向前移动一位4.prev();将数组的内部指针倒回一位5.reset();将数组的内部指针指向第一个单元 6.end();将数组的内部指针指向最后一个单元","link":"/2020/09/20/php%E8%BF%AD%E4%BB%A3%E5%99%A8.html"},{"title":"Redis-简单动态字符串SDS","text":"Redis-简单动态字符串SDS 好久没写博客了，今天水一篇文章。 Redis没有使用c语言传统的字符串去表示。而是构建了一种名为简单动态字符串（simple dynamic string, SDS）的抽象类型，并将sds用作redis的默认字符串表示。 举个例子set msg &quot;hello world&quot;： 键值对的键是一个字符串对象，对象的底层实现是一个保存着字符串”msg“的sds。 键值对的值也是一个字符串对象，对象的底层实现是一个保存着字符串“hello world”的sds。 又比如rpush fruits &quot;apple&quot; &quot;banana&quot;： 键值对的键是一个字符串对象，对象的底层实现是一个保存着字符串”msg“的sds。 键值对的值是一个列表对象，列表对象包含了两个字符串对象，一个sds保存着apple，另一个保存着banana。 SDS的定义每个sds.h/sdshdr结构表示一个SDS值： 12345678910struct sdshdr { // 记录buf数组中已使用字节数量 等于sds所保存字符串的长度 int len; // 记录buf数组中未使用的字节数量 int free; // 字节数组 用于保存字符串 char buf[];} free属性值为0，表示这个sds没有分配任何使用空间。 len属性值为5，表示这个sds保存了一个五字节长的字符串。 buf属性是一个char类型的数组，数组的前5个字节分别保存了为R，e，d，i，s五个字符，而最后一个字节则保存了空字符�。 sds遵循c语言字符串以空字符结尾的惯例，保存空字符的1字节空间不计算在sds的len属性里面。并且为空字符分配额外的1字节空间及添加空字符到字符串末尾等操作都是有sds函数自动完成，所以这个空字符对于sds的使用者是完全透明的。 SDS与C字符串的区别c语言字符串使用长度为N+1的字符数组表示长度为N的字符串，并且字符数组的最后一个元素为空字符�。 这种简单的字符串不能满足redis对字符串在安全性、效率性以及功能方面的要求。 常数复杂度获取字符串长度c字符串并不记录自身的长度信息，所以获取一个c字符串的长度，程序需要遍历整个字符串，对遇到的每个字符进行计数，直到遇到代表字符串结尾的空字符为止，时间复杂度为O(N)。 sds在len属性记录了sds本身的长度，所以获取一个sds的长度复杂度为O(1)。 设置和更新sds的长度工作是由sds的api在执行时自动完成的，使用sds无须进行任何手动修改长度的工作。 通过使用sds而不是c字符串，redis将获取字符串长度所需的时间复杂度从O(N)降低到了O(1)，这确保了获取字符串长度的工作不会成为redis的性能瓶颈。 杜绝缓冲区溢出c字符串不记录自身长度将会带来另一个问题：容易造成缓冲区溢出（buffer overflow）。 strcat函数可以将src字符串的内容拼接到dest字符串末尾： 1char *strcat(char *dest, const char *src); 因为c字符串不记录自身的长度，所以stract假定用户在执行这个函数时，已经为dest分配了足够多的内存，可以容纳src字符串中的所有内容，而一旦这个假定不成立，就会产生缓冲区溢出。 举个例子，假设程序有两个在内存中紧邻着的c字符串s1和s2，其中s1保存了字符串redis，而s2则保存了字符串MongoDb。如图： 如果一个程序决定通过执行： 1strcat(s1, &quot; Cluster&quot;); 将s1的内容修改为Redis Cluster，但粗心的却忘记了在执行strcat之前为s1分配足够的空间，那么函数执行之后，s1的数据将溢出到s2所在的空间中，导致s2保存的内容被意外的修改。如图： 与c字符串不同，sds的空间分配策略完全杜绝了发生缓冲区溢出的可能性：当sds的api需要对sds进行修改时，api会先检查sds的空间是否满足修改所需的要求，如果不满足，会自动将sds的空间扩展至执行修改所需要的大小，然后才执行实际的修改操作。所以使用sds不需要手动修改sds的空间大小，也不会出现缓冲区溢出问题。 举个例子： 1sdscat(s, &quot; Cluster&quot;) sdscat将在执行拼接操作之前检查s的长度是否足够，不够将扩展空间，才去执行拼接操作，拼接完成后的sds如图： sdscat不仅为这个sds进行拼接操作，还分配了13字节的未使用空间，并且拼接之后的字符串正好也是13字节，这不是bug，而是与sds的分配空间策略有关，下面会说明。 减少修改字符串时带来的内存重分配次数因为c字符串的长度和底层数组的长度直接存在着关联关系，所以c语言字符串每次增长或者缩短都要进行一次内存重新分配操作； 如果程序执行增长字符串操作，执行操作前，程序需要先通过内存重新分配来扩展底层空间大小，忘记这步操作将会产生缓冲区溢出。 如果程序执行缩短字符串操作，执行操作后，程序需要通过内存重新分配来释放字符串不使用的空间，忘记这步操作会产生内存泄露。 对于redis，经常被用于速度要求严苛、数据被频繁修改的场景，如果每次修改字符串长度都要执行一次内存分配，光是执行内存重新分配的时间就会占去修改字符串所用时间的一大部分，如果这种修改频繁发生，可能会对性能造成影响。 为了避免c字符串的这种缺陷，sds通过未使用空间解决了字符串长度和底层数组长度之间的关联。通过未使用空间，sds实现了空间预分配和惰性空间释放两种优化策略。 空间预分配： 空间预分配用于优化sds的字符串增长操作：当sds的api对一个sds进行修改，并且需要对sds进行空间扩展的时候，程序不仅会为sds分配修改所必须要的空间，还会为sds分配额外的未使用空间。 其中，额外分配未使用空间数量由以下公式决定： 如果对sds进行修改后，sds的长度将小于1mb，那么程序会分配和len属性同样大小的未使用空间，这时sds的len属性和free的值相同。举个例子，进行修改后len为10，那么free也为10，sds的buf数组的实际长度为10 + 10 + 1 = 21。 如果对sds进行修改后，sds的长度将大于1mb，那么程序会分配1mb的使用空间。举个例子，进行修改后len为10mb，那么free为1mb，sds的buf数组的实际长度为10mb + 1mb + 1byte。 懒惰空间释放 懒惰空间释放用于优化sds的字符串缩短操作：当sds的api需要缩短sds保存的字符串时，程序并不会立即使用内存重分配来回收缩短后多出来的自己，而是使用free属性将这些字节的数量记录起来，并等待将来使用。 举个例子，sdstrim函数接受一个sds和一个c字符串作为参数，从sds左右两端分别移出所以在c字符串中出现的字符。 如图： 执行： 1sdstrim(s, &quot;XY&quot;); // 移除 sds 字符串中所有 ‘X’和‘Y’ 会将sds修改成如下图： 注意执行sdstrim之后的sds并没有释放出来多余的8字节空间，而是将这8字节空间作为未使用空间保留在了sds里面，如果将来要sds进行增长操作，这些未使用空间就会用上。 举个例子，现在对s执行： 1sdscat(s, &quot; Redis&quot;); 那么完成这次sdscat操作将不需要执行内存重新分配，因为sds预留的8字节空间足以拼接6个字节的 Redis，通过惰性空间释放策略，sds避免了缩短字符串所需的内存重分配操作，并为将来可能有的增长操作提供了优化，如图： 与此同时，sds也提供了相应的api，让我们可以在有需要时，真正的释放sds的未使用空间，所以不必担心惰性空间释放策略会造成内存浪费。 二进制安全c字符串中的字符必须符合某种编码（比如 ASCII），并且除了字符串的末尾之外，字符串里面不能包含空字符串，否则最先被程序读入的空字符将被误认为是字符串结尾，这些限制使得c字符串只能保存文本数据，不能保存图片、音频这样的二进制数据。 举个例子，如果有一种使用空字符串分割多个单词的特殊数据格式，那么这种格式就不能使用c字符串来保存，因为c字符串所用的函数之后识别出其中的Redis，而忽略之后的Cluster。如图： 而sds的buf属性被成为字节数组的原因——redis不是用这个数组来保存字符，而是用它来保存一系列二进制数据。 例如，使用sds来保存之前提到的数据格式就没有问题，因为sds使用len属性的值而不是空字符来判断字符串是否结束，如图： 兼容部分c字符串函数虽然sds的api都是二进制安全，但它们一样遵循c字符串以空字符串结尾的惯例：这些api总会将sds保存的数据的末尾设置为空字符，并且总会在为buf数组分配空间时多分配一个字节来容纳这个字符串，这是为了让那些保存文本数据的sds可以重用一部分&lt;string.h&gt;库定义的函数。 举个例子，如果有一个保存文本数据的sds，如上图，那么我们就可以重用&lt;string.h&gt;/strasecmp函数，使用它来对比sds保存的字符串另一个c字符串： 1strcasecmp(sds-&gt;buf, &quot;hello world&quot;); 遵循c字符串以空字符结尾的惯例，sds可以在有需要时重用&lt;string.h&gt;函数库，避免不必要的代码重复。 总结C字符串 SDS 获取字符串长度的复杂度为O(N) 获取字符串长度的复杂度为O(1) API是不安全的，可能会造成缓冲区溢出 API是安全的，不会造成缓冲区溢出 修改字符串长度N次必然需要执行N次内存重分配 修改字符串长度N次最多需要执行N次内存重分配 只能保存文本数据 可以保存文本数据或者二进制数据 可以使用&lt;string.h&gt;库中的函数 可以使用一部分&lt;string.h&gt;库中的函数 打赏如果我的文章对您有帮助：打赏一下哟！传送门","link":"/2021/03/31/redis-%E7%AE%80%E5%8D%95%E5%8A%A8%E6%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2sds.html"},{"title":"Redis-链表","text":"Redis-链表链表提供了高效的节点重排能力，以及顺序性的节点访问方式，并且可以通过增删节点来灵活的调整链表的长度。 作为一种常用数据结构，链表内置在很多高级的编程语言里面，因为Redis使用的c语言并没有内置这种数据结构，所以Redis构建了自己的链表实现。 链表在Redis中的应用非常广泛，比如列表键的底层实现之一就是链表。当一个列表键包含了数量比较多的元素，又或者列表中包含的元素都是比较长的字符串的时，Redis就会使用链表作为列表键的实现。 举个例子，以下展示的integers列表键包含了1-1024共一千零二十四个整数： 1234567891011121314redis&gt; LLEN integers(integer) 1024redis&gt; LRANGE integers 0 101) &quot;1&quot;2) &quot;2&quot;3) &quot;3&quot;4) &quot;4&quot;5) &quot;5&quot;6) &quot;6&quot;7) &quot;7&quot;8) &quot;8&quot;9) &quot;9&quot;10) &quot;10&quot;11) &quot;11&quot; integers列表键的底层实现就是一个链表，链表中的每个节点都保存了一个整数值。除了链表键之外，发布与订阅、慢查询、监视器等功能也用到了链表，Redis服务器本身还是要链表保存多个客户端信息的状态信息，以及使用链表来构建客户端输出缓冲区（output buffer）。 链表和链表节点的实现每个链接节点使用一个adlist.h/listNode结构来表示： 12345678typedef struct listNode { // 前置节点 struct listNode *prev; // 后置节点 struct listNode *next; // 节点的值 void *value;} listNode; 多个listNode可以通过prev和next指针组成双端列表，如下图： 虽然仅仅使用多个listNode结构就可以组成链表，但使用adlist.h/list来持有链表的话，操作起来会更方便： 1234567891011121314typedef struct list { // 表头节点 listNode *head; // 表尾节点 listNode *tail; // 节点值复制函数 void *(*dup)(void *ptr); // 节点值释放函数 void (*free)(void *ptr); // 节点值对比函数 int (*match)(void *ptr, void *key); // 链表所包含的节点数量 unsigned long len;} list; list结构为链表提供了表头指针head、表尾指针tail，以及链表长度计数器len，而dup、free和match成员则是用于实现多态链表所需要的类型特定函数： dup函数用于复制链表节点所保存的值； free函数用于释放链表节点所保存的值； match函数则用于对比链表节点所保存的值和另一个输入值是否相等； 下图是由一个list结构和三个listNode结构组成的链表。 总结Redis的链表实现的特性可以总结如下： 双端：链表节点带有prev和next指针，获取某个节点的前置节点和后置节点的复杂度都是O(1)。 无环：表头节点的prev指针和表尾节点的next指针都指向NULL，对链表的访问以NULL为终点。 带表头指针和表尾指针：通过list结构的head指针和tail指针，程序获取链表的表头节点和表为节点的复杂度为O(1)。 带链表长度计数器：程序使用list结构的len属性来对list持有的链表节点进行计数，程序获取链表中节点数量的的复杂度为O(1)。 多态：链表节点使用void*指针来保存节点值，并且可以通过list结构的dup，free，match三个属性为节点值设置类型特定函数，所以链表可以用于保存各种不同类型的值。 打赏如果我的文章对您有帮助：打赏一下哟！传送门","link":"/2021/04/01/redis-%E9%93%BE%E8%A1%A8.html"},{"title":"redis主从之全量复制及增量复制","text":"在之前我写了一篇docker实现redis主从复制的文章，点击进入 对于主从复制的好处，在上篇文章我也写了，下面说一下注意事项。 注意事项： 安全 对于数据比较重要的节点，主节点会通过设置requirepass参数进行密码验证，这时候所有的客户端访问必须使用auth命令进行验证。从节点与主节点的复制链接是通过一个特殊标识的客户端来完成。因此需要配置从节点的masterauth参数与主节点密码保持一致，这样从节点才可以正确地链接到主节点并发起复制流程。 从节点只读 默认情况下slave-read-only=yes配置为只读，由于复制只能从主节点到从节点，对于从节点的任何修改主节点都无法感知，修改从节点会造成主从数据不一致。因此没必要就不要动这个配置。 网络延迟问题 主从节点一般部署在不同机器上，复制时的网络延迟就成为需要考虑的问题，redis为我们提供了repl-disable-tcp-nodelay参数用于控制是否关闭 tcp nodelay，默认是关闭的，说明如下： 当关闭时，主节点产生的命令数据无论大小都会及时地发送给从节点，这样主从之间延迟将会变小，但增加了网络宽带的消耗。适用于主从之间的网络环境较好的场景。 当开启时，主节点会合并较小的TCP数据包从而节省宽带。默认发送时间间隔取决于Linux的内核，一般默认为40ms。这种配置节省了宽带但增大主从之间的延迟。适用于主从网络环境复杂或宽带紧张的场景。 部署主从节点时需要考虑网络延迟、宽带使用率、防灾级别等因素，如要求低延迟时，建议同机房部署并关闭repl-disable-tcp-nodelay，如考虑容灾性，可以跨机房部署并开启repl-disable-tcp-nodelay。 拓扑图一主一从1234graph TDA[Redis-master] --&gt; B[Redis-slave] 一主多从12345graph TDA[Redis-master] --&gt; B[Redis-slave]A[Redis-master] --&gt; C[Redis-slave]A[Redis-master] --&gt; D[Redis-slave] 树状主从123456graph TDA[Redis-master] --&gt; B[Redis-slave]A[Redis-master] --&gt; C[Redis-slave]B[Redis-slave] --&gt; D[Redis-slave]B[Redis-slave] --&gt; E[Redis-slave] 原理12345678910graph TDA[slaveof] --&gt;127.0.0.1:6379 B[slave]B[slave] --&gt; D[保存主节点信息]D[保存主节点信息] --&gt; E[主从建立socket连接]E[主从建立socket连接] --&gt; F[发送ping命令]F[发送ping命令] --&gt; G[权限验证]G[权限验证] --&gt; H[同步数据集]H[同步数据集] --&gt; I[命令持续复制]I[命令持续复制] --&gt; J[master] 从上图可以看出来大致分为6个过程： 执行slaveof后从节点保存主节点的地址信息便返回，这时候复制流程还没开始。 从节点内部通过每秒运行的定时任务维护复制相关逻辑，当定时任务发现存在新的主节点后，会尝试与该节点建立网络连接，从节点会建立一个socket套接字。 发送ping命令，检测主从之间网络套接字是否可用，检测主节点是否可用接受处理命令。如果发送 ping 命令后，从节点没有收到主节点的 pong 回复或者超时，比如网络超时或者主节点正在阻塞无法响应命令，从节点会断开复制连接，下次定时任务会发起重连。 如果主节点配置了requirepass参数，则需要密码认证，从节点必须配置masterauth参数保证与主节点相同的密码才能通过验证。 主从复制连接正常通信后，对于首次建立复制的场景，主节点会把持有的数据全部发送给从节点，这部分操作是耗时最长的步骤。 当主节点把当前的数据同步给从节点后，便完成了复制的建立流程。接下来主节点会持续地把写命令发送给从节点，保证主从数据一致性。 主从同步的过程中，从节点会把原来的数据清空。 数据同步同步方式： 全量复制 用于初次复制或其它无法进行部分复制的情况，将主节点中的所有数据都发送给从节点。当数据量过大的时候，会造成很大的网络开销。 部分复制 用于处理在主从复制中因网络闪退等原因造成数据丢失场景，当从节点再次连上主节点，如果条件允许，主节点会补发丢失数据给从节点，因为补发的数据远远小于全量数据，可以有效避免全量复制的过高开销。但需要注意，如果网络中断时间过长，造成主节点没有能够完整地保存中断期间执行的写命令，则无法进行部分复制，仍使用全量复制 。 复制偏移量： 参与复制的主从节点都会维护自身复制偏移量，主节点在处理完写入命令操作后，会把命令的字节长度做累加记录，统计信息在info replication中的master_repl_offset指标中。 从节点每秒钟上报自身的复制偏移量给主节点，因此主节点也会保存从节点的复制偏移量slave0:ip=192.168.1.3,port=6379,state=online,offset=116424,lag=0 从节点在接收到主节点发送的命令后，也会累加记录自身的偏移量。统计信息在info replication中的slave_repl_offset中。 复制积压缓冲区： 复制积压缓冲区是保存在主节点上的一个固定长度的队列，默认大小为1MB，当主节点有连接的从节点时被创建，这时主节点响应写命令时，不但会把命令发给从节点，还会写入复制积压缓冲区。 在命令传播阶段，主节点除了将写命令发送给从节点，还会发送一份给复制积压缓冲区，作为写命令的备份；除了存储写命令，复制积压缓冲区中还存储了其中 的每个字节对应的复制偏移量(offset) 。由于复制积压缓冲区定长且先进先出，所以它保存的是主节点最近执行的写命令；时间较早的写命令会被挤出缓冲区。 主节点运行ID： 每个redis节点启动后都会动态分配一个40位的十六进制字符串为运行ID。运行ID的主要作用是来唯一识别redis节点，比如从节点保存主节点的运行ID识别自已正在复制是哪个主节点。如果只使用ip+port的方式识别主节点，那么主节点重启变更了整体数据集（如替换RDB/AOF文件），从节点再基于偏移量复制数据将是不安全的，因此当运行ID变化后从节点将做全量复制。可以在info server命令查看当前节点的运行ID。 需要注意的是redis关闭再启动，运行的id会随之变化。 Psync命令： 从节点使用psync命令完成部分复制和全量复制功能psync runid offset 流程说明： 从节点(slave)发送psync命令给主节点，参数runid是当前从节点保存的主节点运行id，如果没有则默认值为 ？, 参数offset是当前从节点保存的复制偏移量，如果是第一次参与复制则默认值为-1。 主节点根据pysnc参数和自身数据情况决定响应结果： 如果回复+FULLRESYNC {runid} {offset}，那么从节点将触发全量复制流程。 如果回复+CONTINUE，从节点将触发部分复制流程。 如果回复-ERR，说明主节点版本低于Redis2.8。 全量复制流程： 发送psync命令进行数据同步，由于是第一次进行复制，从节点没有复制偏移量和主节点的运行id，所以发送psync ? -1 主节点根据psync ? -1解析出当前为全量复制，回复+FULLRESYNC响应(主机会向从机发送 runid 和 offset，因为 slave 并没有对应的 offset，所以是全量复制) 从节点接收主节点的响应数据保存运行ID和偏移量offset(从机 slave 会保存 主机master 的基本信息 save masterInfo) 主节点收到全量复制的命令后，执行bgsave（异步执行），在后台生成RDB文件（快照），并使用一个缓冲区（称为复制缓冲区）记录从现在开始执行的所有写命令 主节点发送RDB文件给从节点，从节点把接收到的RDB文件保存在本地并直接作为从节点的数据文件，接收完RDB后从节点打印相关日志，可以在日志中查看主节点发送的数据量(主机send RDB 发送 RDB 文件给从机) 注意！对于数据量较大的主节点，比如生成的RDB文件超过6GB以上时要格外小心。传输文件这一步操作非常耗时，速度取决于主从节点之间网络带宽。 通过细致分析Full resync和MASTER SLAVE这两行日志的时间差，可以算出RDB文件从创建到传输完毕消耗的总时间。如果总时间超过repl-timeout所配置的值 (默认60秒)，从节点将放弃接受RDB文件并清理已经下载的临时文件，导致全量复制失败;针对数据量较大的节点，建议调大repl-timeout参数防止出现全量同步数据超时; 例如对于千兆网卡的机器，网卡带宽理论峰值大约每秒传输100MB,在不考虑其他进程消耗带宽的情况下，6GB的RDB文件至少需要60秒传输时间，默认配置下，极易出现主从数同步超时。 对于从节点开始接收RDB快照到接收完成期间，主节点仍然响应读写命令，因此主节点会把这期间写命令数据保存在复制客户端缓冲区内，当从节点加载完RDB文件后，主节点再把缓冲区内的数据发送给从节点，保证主从之间数据致性。(发送缓冲区数据) 从节点接收完主节点传送来的全部数据后会清空自身旧数据(刷新旧的数据，从节点在载入主节点的数据之前要先将老数据清除) 从节点清空数据后开始加载RDB文件，对于较大的RDB文件，这一步操作依然比较消耗时间，可以通过计算日志之间的实际差来判断加载RDB的总消耗时间(加载 RDB 文件将数据库状态更新至主节点执行bgsave时的数据库状态和缓冲区数据的加载。) 从节点成功加载完RDB后，如果当前节点开启了AOF持久化的功能，它会立刻做bgrewriteeaof的操作，为了保证全量复制后AOF持久化文件立刻可用。 通过分析全量复制的所有流程，全量复制是一个非常耗时费力的操作。他的实际开销主要包括： 主节点bgsave时间 RDB文件网络传输时间 从节点清空数据时间 从节点加载RDB的时间 可能的AOF重写时间 部分复制流程： 部分复制是 Redis 2.8 以后出现的，之所以要加入部分复制，是因为全量复制会产生很多问题，比如像上面的时间开销大、无法隔离等问题， Redis 希望能够在主节点出现抖动（相当于断开连接）的时候，可以有一些机制将复制的损失降低到最低 当主从节点之间网络出现中断时，如果超过repl-timeout时间，主节点会认为从节点出问题了并断开复制链接（如果网络抖动（连接断开 connection lost））。 主从连接中断期间主节点依然响应命令，但因复制链接中断命令无法发送给从节点不过主节点内部存在的复制积压缓存去，依然可以保存一段时间的写命令数据，默认最大缓存1MB(主机master 还是会写 replbackbuffer（复制缓冲区）) 当主从节点网络恢复后，从节点会再次连上主节点。(从机slave会继续尝试连接主机) 当主从连接恢复后，由于从节点之前保存了自身已复制的偏移量和主节点的运行id。因此会把他们当作psync参数发送给主节点，要求进行部分复制操作。(从机 slave 会把自己当前 runid 和偏移量传输给主机 master，并且执行 pysnc 命令同步) 主节点接到psync命令后首先核对参数的runid，如果 master 发现你的偏移量是在缓冲区的范围内，根据参数offset在缓冲区查找复制内内，如果在偏移量之后的数据存在缓存区中，则对从节点发送continue表示可以进行部分复制 主节点根据偏移量把复制积压缓冲区里的数据发送给从节点，保证主从复制进入正常状态。(同步了 offset 的部分数据，所以部分复制的基础就是偏移量 offset) 心跳： 主节点在建立成功后会维护这长连接彼此发送心跳检测 主从节点彼此都有心跳检测机制，各自模拟成对方的客户端进行通信，通过client list命令查看复制相关客户端信息，主节点的连接状态为flags=M,从节点连接状态 flags=S。 主节点默认每隔10秒对从节点发送ping命令，判断从节点的存活性和连接状态。可通过参数repl-ping-slave-period控制发送频率。 从节点在主线程中每隔1秒发送replconf ack {offset} 命令，给主节点上报自身当前的复制偏移量。 缓冲区大小调节： 由于缓冲区长度固定且有限，因此可以备份的写命令也有限，当主从节点offset的差距过大超过缓冲区长度时，将无法执行部分复制，只能执行全量复制。 反过来说，为了提高网络中断时部分复制执行的概率，可以根据需要增大复制积压缓冲区的大小(通过配置repl-backlog-size)来设置； 例如 如果网络中断的平均时间是 60s，而主节点平均每秒产生的写命令(特定协议格式)所占的字节数为100KB，则复制积压缓冲区的平均需求为6MB，保险起见， 可以设置为12MB，来保证绝大多数断线情况都可以使用部分复制。","link":"/2020/09/23/redis%E4%B8%BB%E4%BB%8E%E4%B9%8B%E5%85%A8%E9%87%8F%E5%A4%8D%E5%88%B6%E5%8F%8A%E5%A2%9E%E9%87%8F%E5%A4%8D%E5%88%B6.html"},{"title":"redis之主从问题处理","text":"Slaveof slaveof slave实例需要配置该项，指向master的(ip,port) masterauth masterauth 如果master实例启用了密码保护，则该配置项需要填master的启动密码； 如果未启用，需要将该配置项注视掉。 slave-serve-stale-data 指定slave与master连接中断时的动作。默认为yes，表明slave会继续应答来自client的请求，但这些数据可能已经过期（因为连接中断导致无法从master同步）。若配置为no，则slave除正常应答“INFO”和“SLAVEOF”命令外，其余来自客户端的请求命令均会得到“SYNC with master in progress“的应答，直到该slave与master连接重建成功或该slave被提升为master。 slave-read-only 指定slave是否只读，默认为yes。若配置为no，表示slave是可写的，但写的内容在主从同步完成后会被删除掉。 repl-disable-tcp-nodelay 指定向slave同步数据时，是否禁用socket的NO_DELAY选项。若配置为yes，则禁用NO_DELAY，则TCP协议栈会合并小包统一发送，这样可以减少主从节点间的包数量并节省宽带，但会增加数据同步到slave的时间。若配置为no，表明启用NO_DELAY，则TCP协议栈不会延迟小包的发送时间，这样数据同步的延时会减少，但需要更大的宽带。 slave-priority 指定slave的优先级。在不只1个slave存在的部署环境下，当master宕机时，Redis Sentinel 会将priority值最小的slave提升为master。需要注意的是，若该配置项为0，则对应的slave永远不会被Redis Sentinel 自动提升为master。 Redis复制数据的延迟由于异步复制特性是无法避免的，延迟取决于网络宽带和命令阻塞情况，比如刚在主节点写入数据后立刻在从节点上读取可能获取不到。需要业务场景允许短时间内的数据延迟。对于无法容忍大量延迟场景，可以编写外部监控程序监听主从节点的复制偏移量，当延迟较大时触发报警或通知客户端避免读取延迟过高的从节点。 具体实现逻辑： 监控程序定期检查主从节点的偏移量，主节点偏移量在info replication的master_repl_offset指标记录，从节点偏移量可以查询主节点的slave0字段的offset指标，它们的差值就是主从节点延迟的字节量。 对于无法容忍大量延迟场景，可以编写外部监控程序监听主从节点的复制偏移量，当延迟较大时触发报警或者通知客户端避免读取延迟过高的从节点，同时从节点的slave-serve-stable-data参数也与此有关，它控制这种情况下从节点的表现，当从库同主机失去连接或者复制正在进行，从机库有两种运行方式。 读取过期数据当主节点存储大量设置超时的数据时，redis内部需要维护过期数据删除策略，删除策略主要有两种： 惰性删除 主节点每次处理读取命令时，都会检查健是否超时，如果超时则执行·del命令删除键对象，之后del命令也会异步发给从节点。因为保持复制的一致性，从节点自身永远不会主动删除超时数据。 定时删除 Redis主节点在内部定时任务会循环采样一定数据量的键，当发现采用的键过期时会执行del命令，之后再同步给从节点。 从节点故障问题对于从节点的故障问题，需要在客户端维护一个可用从节点可用列表，当从节点故障时，立刻切换到其他从节点或主节点，redis Cluster可以解决这个问题。 配置不一致主节点和从节点不同，经常导致主节点和从节点的配置不同，并带来问题。 主从配置不一致是一个容易忽视的问题。对于有些配置主从之间是可以不一致，比如：主节点关闭AOF，从节点开启AOF。但对于内存相关的配置必须要一致，比如maxmemory,hash-max-ziplist-entries等参数。 数据丢失：主机和从机有时候发生配置不一致的情况，例如maxmemory不一致。假如主机配置maxmemory为8G，从机设置为4G，这个时候是可以用的，而且不会报错。但如果要做高可用，让从节点变成主节点的时候，就会发现数据已经丢失，而且无法挽回。 规避全量复制全量复制指的是当slave断开并重启后，runid产生变化而导致需要在master主机里拷贝全部数据。这种拷贝全部数据的过程非常耗资源。 全量复制是不可避免的，例如第一次的全量复制就不可避免，这时我们需要选择小主节点，且maxmemory值不要过大，这样就会比较快。同时选择在低峰值的时候做全量复制。 造成全量复制的原因： 主从机的运行runid不匹配。解释一下，主节点如果重启，runid将会发生变化。如果从节点监控到runid不是同一个，它就会认为你的节点不安全。当发生故障转移的时候，如果主节点发生故障，那么从节点就会变成主节点（哨兵和集群）。 复制缓冲区空间不足，比如默认值为1M，可以部分复制，但如果缓冲区不够大的话，首先需要网络中断，部分复制将无法满足。其次需要增大复制缓冲区配置repl-backlog-size，对网络的缓冲增强。 怎么解决： 在一些场景下，可能希望对主节点进行重启，例如主节点内存碎片率过高，或者希望调整一些只能在启动时调整的参数。如果使用普通的手段重启主节点，会使得runid发生变化，可能导致不必要的全量复制。 为了解决这个问题，Redis提供了debug reload的重启方式：重启后，主节点的runid和offset都不受影响，避免了全量复制。 规避复制风暴复制风暴是指大量从节点对同一主节点或者对同一台机器的多个主节点短时间内发起全量复制的过程。复制风暴对发起复制的主节点或者机器造成大量开销，导致 CPU、内存、带宽消耗。因此我们应该分析出复制风暴发生的场景，提前采用合理的方式规避。规避方式有如下几个。 单节点复制风暴当一个主机下面挂了很多个 slave从机的时候，主机 master 挂了，这时 master 主机重启后，因为 runid 发生了变化，所有的 slave 从机都要做一次全量复制。这将引起单节点和单机器的复制风暴，开销会非常大。 解决： 可以采用树状结构降低多个从节点对主节点的消耗。 从节点采用树状树非常有用，网络开销交给位于中间层的从节点，而不必消耗顶层的主节点。但是这种树状结构也带来了运维的复杂性，增加了手动和自动 处理故障转移的难度。 单机器复制风暴由于 Redis 的单线程架构，通常单台机器会部署多个 Redis 实例。当一台机器（machine）上同时部署多个主节点（master）时，如果每个 master 主机只有一台 slave 从机，那么当机器宕机以后，会产生大量全量复制。这种情况是非常危险的情况，带宽马上会被占用，会导致不可用。 解决： 应该把主节点尽量分散在多台机器上，避免在单台机器上部署过多的主节点。 当主节点所在机器故障后提供故障转移机制，避免机器恢复后进行密集的全量复制。 补充###########从库############## #设置该数据库为其他数据库的从数据库 slaveof #主从复制中，设置连接master服务器的密码（前提master启用了认证） masterauth # 当从库同主库失去连接或者复制正在进行，从库有两种运行方式： # 1) 如果slave-serve-stale-data设置为yes(默认设置)，从库会继续相应客户端的请求 # 2) 如果slave-serve-stale-data设置为no，除了INFO和SLAVOF命令之外的任何请求都会返回一个错误”SYNC with master in progress“ slave-serve-stale-data yes #当主库发生宕机时候，哨兵会选择优先级最高的一个称为主库，从库优先级配置默认100，数值越小优先级越高 slave-priority 100 #从节点是否只读；默认yes只读，为了保持数据一致性，应保持默认。 slave-read-only yes ########主库配置############## #在slave和master同步后（发送psync/sync），后续的同步是否设置成TCP_NODELAY假如设置成yes，则redis会合并小的TCP包从而节省带宽，但会增加同步延迟（40ms），造成master与slave数据不一致假如设置成no，则redis master会立即发送同步数据，没有延迟。 #前者关注性能，后者关注一致性 repl-disable-tcp-nodelay no #从库会按照一个时间间隔向主库发送PING命令来判断主服务器是否在线，默认是10秒 repl-ping-slave-period 10 #复制积压缓冲区大小设置 repl-backlog-size 1mb #master没有slave一段时间会释放复制缓冲区的内存，repl-backlog-ttl用来设置该时间长度。单位为秒。 repl-backlog-ttl 3600 #redis提供了可以让master停止写入的方式，如果配置了min-slaves-to-write，健康的slave的个数小于N，mater就禁止写入。master最少得有多少个健康的slave存活才能执行写命令。这个配置虽然不能保证N个slave都一定能接收到master的写操作，但是能避免没有足够健康的slave的时候，master不能写入来避免数据丢失。设置为0是关闭该功能。 min-slaves-to-write 3 min-slaves-max-lag 10","link":"/2020/09/27/redis%E4%B9%8B%E4%B8%BB%E4%BB%8E%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86.html"},{"title":"redis哨兵故障转移及实现","text":"在上篇文章中docker-compose搭建redis-sentinel成功的搭建了1主2从3哨兵。 sentinel是一个特殊的redis节点，它有自己专属的api： sentinel masters 显示被监控的所有master以及它们的状态。 sentinel master 显示指定master的信息和状态。 sentinel slaves 显示指定master的所有slave及它们的状态。 sentinel sentinels 显示指定master的sentinel节点集合（不包含当前节点）。 sentinel get-master-addr-by-name 返回指定master的ip和port，如果正在进行failover或者failover已经完成，将会显示被提升为master的slave的ip和port。 sentinel failover 强制sentinel执行failover，并且不需要得到其它sentinel的同意。但是failover后会将最新的配置发送给其它sentinel。 sentinel masters 展示所有被监控的主节点状态及相关信息： 12345678127.0.0.1:26380&gt; sentinel masters1) 1) &quot;name&quot; 2) &quot;mymaster&quot; 3) &quot;ip&quot; 4) &quot;192.168.3.2&quot; 5) &quot;port&quot; 6) &quot;6379&quot;………………………………………………………… sentinel master 展示指定状态以及相关的信息： 12345678127.0.0.1:26380&gt; sentinel master mymaster 1) &quot;name&quot; 2) &quot;mymaster&quot; 3) &quot;ip&quot; 4) &quot;192.168.3.2&quot; 5) &quot;port&quot; 6) &quot;6379&quot; ……………………………… sentinel slaves 展示指定 的从节点状态以及相关的统计信息： 123456789101112131415127.0.0.1:26380&gt; sentinel slaves mymaster1) 1) &quot;name&quot; 2) &quot;192.168.3.4:6379&quot; 3) &quot;ip&quot; 4) &quot;192.168.3.4&quot; 5) &quot;port&quot; 6) &quot;6379&quot;…………………………………………2) 1) &quot;name&quot; 2) &quot;192.168.3.3:6379&quot; 3) &quot;ip&quot; 4) &quot;192.168.3.3&quot; 5) &quot;port&quot; 6) &quot;6379&quot;………………………………………… sentinel sentinels 展示指定 的sentinel节点集合（不包含当前sentinel节点）： 12345678127.0.0.1:26380&gt; sentinel sentinels mymaster1) 1) &quot;name&quot; 2) &quot;570de1d8085ec8bd7974431c01c589847c857edf&quot; 3) &quot;ip&quot; 4) &quot;192.168.3.13&quot; 5) &quot;port&quot; 6) &quot;26379&quot;……………………………………………… sentinel get-master-addr-by-name 获取主节点信息： 123127.0.0.1:26380&gt; sentinel get-master-addr-by-name mymaster1) &quot;192.168.3.2&quot;2) &quot;6379&quot; sentinel failover 对进行强制故障转移： 12345678910127.0.0.1:26380&gt; sentinel failover mymasterOK127.0.0.1:26380&gt; info sentinel# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0sentinel_simulate_failure_flags:0master0:name=mymaster,status=ok,address=192.168.3.3:6379,slaves=2,sentinels=3 修改配置： 添加新的监听：sentinel monitor test 127.0.0.1 6379 2 放弃对某个master监听：sentinel REMOVE test 设置配置选项：sentinel set failover-timeout mymaster 180000 Master可能会因为某些情况宕机了，如果客户端是固定一个地址去访问，肯定是不合理的，所以客户端请求是请求哨兵，从哨兵获取主机地址的信息，或者是从机的信息。可以实现一个例子： 随机选择一个哨兵连接，获取主机及从机信息。 模拟客户端定时访问，实现简单轮询效果，轮询从节点。 连接失败重试访问 Sentinel故障转移执行docker-composer up之后sentinel.conf发生了变化，每个配置文件变化如下： sentinel\\conf\\sentinel.conf 123456user default on nopass ~* +@allsentinel known-replica mymaster 192.168.3.3 6379sentinel known-replica mymaster 192.168.3.4 6379sentinel known-sentinel mymaster 192.168.3.12 26379 497f733919cb5d41651b4a2b5648c4adffae0a73sentinel known-sentinel mymaster 192.168.3.13 26379 0d0ee41bcb5d765e9ff78ed59de66be049a23a82sentinel current-epoch 0 sentine2\\conf\\sentinel.conf 123456user default on nopass ~* +@allsentinel known-replica mymaster 192.168.3.3 6379sentinel known-replica mymaster 192.168.3.4 6379sentinel known-sentinel mymaster 192.168.3.13 26379 0d0ee41bcb5d765e9ff78ed59de66be049a23a82sentinel known-sentinel mymaster 192.168.3.11 26379 f5f2a73dc0e60514e4f28c6f40517f48fa409eedsentinel current-epoch 0 sentine3\\conf\\sentinel.conf 123456user default on nopass ~* +@allsentinel known-replica mymaster 192.168.3.3 6379sentinel known-replica mymaster 192.168.3.4 6379sentinel known-sentinel mymaster 192.168.3.12 26379 497f733919cb5d41651b4a2b5648c4adffae0a73sentinel known-sentinel mymaster 192.168.3.11 26379 f5f2a73dc0e60514e4f28c6f40517f48fa409eedsentinel current-epoch 0 从变化中可以看出每台Sentinel分别记录了slave的节点信息和其它Sentinel节点信息。 在宿主机中随便进入一台Sentinel： 1234567127.0.0.1:26380&gt; sentinel masters1) 1) &quot;name&quot; 2) &quot;mymaster&quot; 3) &quot;ip&quot; 4) &quot;192.168.3.2&quot; 5) &quot;port&quot; 6) &quot;6379&quot; 可以观察到监听的所有master，将192.168.3.2这台master进行宕机 docker stop redis-master 宕机完之后等待Sentinel检测周期过了之后再对sentinel.conf和redis.conf进行观察。 3台Sentinel的sentinel monitor mymaster 192.168.3.2 6379 2变成了sentinel monitor mymaster 192.168.3.4 6379 2 其次master对应的slave节点信息也进行更改。 而192.168.3.3的redis.conf中replicaof 192.168.3.2 6379也变成了replicaof 192.168.3.4 6379。 192.168.3.2的redis.conf中replicaof 192.168.3.2 6379这行配置被删除掉了。 再次启动192.168.3.2的redis节点，而这台节点的redis.conf中增加了一行replicaof 192.168.3.4 6379。 其实就是将我们的操作自动化了。 Sentinel实现原理Sentinel的实现原理，主要分为三个步骤： 检测问题：三个定时任务，这三个内部的执行任务可以保证出现问题马上让Sentinel知道。 发现问题：主观下线和客观下线，当有一台Sentinel机器发现问题时，它就会对它主观下线。但是当多个Sentinel都发现问题的时候，才会出现客观下线。 找到解决问题的Sentinel：进行领导者选举，如何在Sentinel内部多台节点做领导者选择。 解决问题：就是要进行故障转移。 三个定时任务 每10s每个Sentinel对Master和Slave执行一次Info Replication。 Redis Sentinel可以对Redis节点做失败判断和故障转移，来Info Replication发现Slave节点，来确定主从关系。 每2s每个Sentinel通过Master节点的channel交换信息（pub/sub）。 类似于发布订阅，Sentinel会对主从关系进行判断，通过__sentinel__:hello频道交互。了解主从关系可以帮助更好的自动化操作Redis。然后Sentinel会告知系统消息给其它Sentinel节点，最终达到共识，同时Sentinel节点能够互相感知到对方。 每1s每个Sentinel对其它Sentinel和Redis执行ping。 对每个节点和其它Sentinel进行心跳检测，它是失败判断的依据。 主观下线和客观下线回顾上一篇文章中Sentinel的配置。 12sentinel monitor mymaster 192.168.3.2 6379 2sentinel down-after-millseconds mymaster 30000 主观下线：每个Sentinel节点对Redis失败的“偏见”。之所以是偏见，只是因为某一台机器30s内没有得到回复。 客观下线：这个时候需要所以Sentinel节点都发现它30s内无回复，才会达到共识。 领导者选举方式 每个做主观下线的Sentinel节点，会像其它的Sentinel节点发送命令，要求将它设置成为领导者。 收到命令的Sentinel节点，如果没有同意通过其它节点发送的命令，那么就会同意请求，否则就会拒绝。 如果Sentinel节点发现自己的票数超过半数，同时也超过了sentinel monitor mymaster 192.168.3.2 6379 2超过2个的时候，就会成为领导者。 进行故障转移操作。 如何选择“合适”的Slave节点​ Redis内部其实是有一个优先级配置的，在配置文件中replica-priority，这个参数是slave节点的优先级配置，如果存在则返回，如果不存在则继续。当上面这个优先级不满足的时候，Redis还会选择复制偏移量最大的Slave节点，如果存在则返回，如果不存在则继续。之所以选择偏移量最大，这是因为偏移量越小，和Master的数据越不接近，现在Master挂掉了，说明这个偏移量小的机器数据可能存在问题，这就是为什么选择偏移量最大的Slave的原因。如果发现偏移量都一样，这个时候 Redis 会默认选择 runid 最小的节点。 生产环境部署技巧： Sentinel节点不应该部署在一台物理机器上。 这里特意强调物理机是因为一台物理机做成了若干虚拟机或者现今比较流行的容器，它们虽然有不同的IP地址，但实际上它们都是同一台物理机，同一台物理机意味着如果这台机器有什么硬件故障，所有的虚拟机都会受到影响，为了实现Sentinel节点集合真正的高可用，请勿将Sentinel节点部署在同一台物理机器上。 部署至少三个且奇数个的Sentinel节点。通过增加Sentinel节点的个数提高对于故障判定的准确性，因为领导者选举需要至少一半加1个节点。 Sentinel常见问题哨兵集群在发现master node挂掉后会进行故障转移，也就是启动其中一个slave node为master node。在这过程中，可能会导致数据丢失的情况。 异步复制导致数据丢失 因为master-&gt;slave的复制是异步，所以有可能部分还没来得及复制到slave就宕机了，此时这些部分数据就丢失了。 集群脑裂导致数据丢失 脑裂，也就是说。某个master所在机器突然脱离了正常的网络，跟其它slave机器不能连接，但是实际上master还运行着。 造成的问题： ​ 此时哨兵可能就会认为master宕机了，然后开始选举，将其它slave切换成master。这时候集群里就会有2个master，也就是所谓的脑裂。此时虽然某个slave被切换成master，但是可能client还没来得及切换成新的master，还继续写向旧的master的数据可能就丢失了。因此旧master再次被恢复的时候，会被作为一个slave挂到新的master上去，自己的数据会被清空，重新从新的master复制数据。 怎么解决： 12min-slaves-to-write 1min-slaves-max-lag 10 要求至少有一个slave，数据复制和同步的延迟不能超过10s。 如果说一旦所有的slave，数据复制和同步的延迟都超过了10s，这个时候，master就不会再接收任何请求了。 上面两个配置可以减少异步复制和脑裂导致的数据丢失。 异步复制导致的数据丢失： ​ 在异步复制的过程当中，通过min-slaves-max-lag这个配置，就可以确保的说，一旦slave复制数据和ack延迟时间太长，就认为可能master宕机后损失的数据太多了，那么就拒绝写请求，这样就可以把master宕机时由于部分数据未同步到slave导致的数据丢失降低到可控范围内。 集群脑裂导致的数据丢失： ​ 集群脑裂因为client还没来得及切换成新的master，还继续写向旧的master的数据可能就丢失了通过min-slaves-to-write确保必须是有多少个从节点连接，并且延迟时间小于min-slaves-max-lag多少秒。 客户端需要怎么做： ​ 对于client来讲，就需要做些处理，比如先将数据缓存到内存当中，然后过一段时间处理，或者连接失败，接收到错误切换新的master处理。","link":"/2020/09/23/redis%E5%93%A8%E5%85%B5%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB%E5%8F%8A%E5%AE%9E%E7%8E%B0.html"},{"title":"redis持久化rdb及aof","text":"​ 持久化的功能：Redis是内存数据库，数据都是存储在内存中，为了避免进程退出导致数据的永久丢失，需要定期将Redis中的数据以某种形式（数据或命令）从内存保存到硬盘中。当下次Redis重启时，利用持久化文件实现数据恢复。除此之外，为了进行灾难备份，可以将持久化文件拷贝到一个远程位置。Redis持久化分为RDB和AOF，前者将当前数据保存到硬盘，后者则是将每次执行的写命令保存的硬盘。 RDB持久化​ RDB是一种快照存储持久方式，具体就是将Redis某一时刻的内存数据保存到硬盘的文件当中，默认保存的文件名为dump.rdb，而在Redis服务器启动时，会重新加载dump.rdb文件的数据到内存当中恢复数据。触发RDB持久化过程分为手动触发和自动触发。 触发机制手动触发分别对应save和bgsave命令： save命令：阻塞当前Redis服务器，直到RDB过程完成为止，对于内存比较大的实例会造成长时间阻塞，线上环境不建议使用。 bgsave命令：Redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短。 显示bgsave命令是针对save阻塞问题做的优化。因此Redis内部所有的涉及RDB的操作都采用bgsave的方式。 除了执行命令手动触发之外，Redis内部还存在自动触发RDB的持久化机制，例如以下场景： 使用save相关配置，如save m n。表示m秒内数据集存在n次修改时，自动触发bgsave。 如果从节点执行全量复制操作，主节点自动执行bgsave生成RDB文件并发送给从节点。 执行debug reload命令重载Redis时，也会自动触发save操作。 默认情况下执行shutdown命令时，如果没有开启AOF持久化功能则自动执行bgsave。 执行流程bgsave是主流的触发RDB持久化方式： 执行bgsave命令，Redis父进程判断当前是否存在正在执行的子进程，如RDB/AOF子进程，如果存在bgsave命令直接返回。 父进程执行fork操作创建子进程，fork操作过程中父进程会阻塞，通过info stats命令查看latest_fork_usec选项，可以获得最近一个fork操作的耗时，单位为微妙。 父进程fork完成后，bgsave命令返回Background saving started信息并不再阻塞父进程，可以继续响应其它命令。 子进程创建RDB文件，根据父进程内存生成临时快照文件，完成后原有文件进行原子替换。执行lastsave命令可以获取最后一次生成RDB的时间，对应info统计的rdb_last_save_time选项。 进程发送信号给父进程表示完成，父进程更新统计信息，具体见info Persistence下的rdb_*相关选项。 服务器配置自动触发​ 除了通过客户端发送命令外，还有一种方式，就是在Redis配置文件中的save指定到达触发RDB持久化的条件，比如【多少秒内至少达到多少写操作】就开启RDB数据同步。 例如我们可以在配置文件redis.conf指定如下的选项： 123456# 900s内至少达到1条写命令save 900 1# 300s内至少达到10条写命令save 300 10# 60s内至少达到1000条写命令save 60 1000 这种通过服务器配置文件触发RDB的方式，与bgsave命令类似，达到触发条件时，会fork一个子进程进行数据同步，不过最好不要通过这种方式来触发RDB持久化，因为设置触发的时间太短，则容易频繁写入rdb文件，影响服务器性能，时间设置太长会造成数据丢失。 RDB文件的处理保存： RDB文件保存在dir配置指定的目录下，文件名通过dbfilename配置指定。可通过执行config set dir {newDir}和config set dbfilename {newFileName}运行期动态执行，当下次运行时RDB文件会保存到新目录。 压缩： Redis默认采用LZF算法对生存的RDB文件做压缩处理，压缩后的文件远远小于内存大小，默认开启，可以通过参数config set rdbcompression {yesno}动态修改。 虽然压缩RDB会消耗CPU，但可大幅度降低文件的体积，方便保存到硬盘或通过网络发送给从节点，因此线上建议开启。 RDB方式的优缺点优点： RDB是一个非常紧凑的文件，它保存了Redis在某个时间点上的数据集。这种文件非常适合用于备份；比如说，你可以在最近的24小时内，每小时备份一次RDB文件，并且在每个月的每一天，也备份一个RDB文件。这样的话，即使遇上问题，也可以随时将数据集还原到不同的版本。 RDB可以最大化Redis的性能；父进程在保存RDB文件时唯一要做的就是fork出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无需执行任何磁盘I/O操作。 RDB在恢复大数据集时的速度要比AOF的恢复速度快。 缺点： RDB方式数据没办法做到实时持久化/秒级持久化。如果服务器宕机的话，采用RDB的方式会造成某个时段内数据的丢失，比如我们设置10分钟同步一次或者5分钟达到1000次写入就同步一次，那么如果还没达到触发条件服务器就死机了，那么这个时间段的数据会丢失。 使用bgsave命令在fork子进程时，如果数据量太大，fork的过程也会发生阻塞，另外，fork子进程会消耗内存。针对RDB不适合做实时持久化的问题，Redis提供了AOF持久化方式来解决。 AOF持久化​ AOF（append only file）持久化；与RDB存储某个时刻的快照不同，AOF持久化方式会记录客户端对服务器的每一次写操作命令到日志当中，并将这些操作以Redis协议追加保存到以后缀为aof文件末尾。 使用AOF​ 开启AOF功能需要设置配置；appendonly yes，默认不开启。AOF文件名通过appendfilename配置设置，默认文件名是appendonly.aof。保存路径同RDB持久化方式一致，通过dir配置指定。 持久化配置1234appendonly yes #启用aof持久化方式appendfsync always #每次收到命令就立即强制写入磁盘，最慢的大概只有几百的TPS，但是保证完全的持久化，不推荐使用appendfsync everysec #每秒钟强制写入磁盘一次，在性能和持久化方面做了很好的折中，推荐appendfsync no #完全依赖os，性能最好，持久化没保证，Redis不会主动调用fsync去将AOF日志内容同步到磁盘，所以这一切完全依赖于操作系统的调试了。对于大多数Linux操作系统，是每30s进行一次fsync，将缓冲区中的数据写的磁盘上。 执行流程 所以的写入命令会追加到aof_buf（缓冲区）中。 AOF缓冲区根据对应的策略向硬盘做同步操作。 随着AOF文件越来越大，需要定期对AOF文件进行重写，达到压缩的目的。 当Redis服务器重启时，可以加载AOF文件进行数据恢复。 在同步期间可能会发生阻塞问题 若果AOF文件fsync同步时间大于2s，Redis主进程就会阻塞。 若果AOF文件fsync同步时间小于2s，Redis主进程就会返回。 其实这样做是为了保证文件安全性的一种策略。 AOF追加阻塞会产生的问题： fsync大于2s时候，会阻塞redis主进程，我们都知道redis主进程是用来执行redis命令的，是不能阻塞的。 虽然每秒everysec刷盘策略，但是实际上不是丢失1s数据，实际有可能丢失2s数据。 重写机制 AOF将客户端的每一个写操作都追加到aof文件末尾，随着命令不断写入AOF，文件会越来越大，为了解决这个问题，Redis引入AOF重写机制压缩文件体积。 AOF文件重写是吧Redis进程内的数据转化为写命令同步到新AOF文件的过程。 比如：多条命令可以合并为一个，lpush list a、lpush list b可以转化为lpush list a b。 AOF重写降低了文件占用空间，除此之外，另一个目的是：更小的AOF文件可以更快地被加载。 触发机制： AOF重写过程可以手动触发和自动触发： 手动触发：直接调用bgrewriteaof命令。 自动触发：根据auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数确定自动触发。 auto-aof-rewrite-min-size表示运行AOF重写时文件最小体积，默认为64MB。 auto-aof-rewrite-percentage代表当前AOF文件空间（aof_current_size）和上一次重写后AOF文件空间（aof_base_size）的比值。 示例： auto-aof-rewrite-percentage：100 auto-aof-rewrite-min-size：64mb 默认配置时当AOF文件大小是上次rewrite后大小的一倍且文件大于64mb时触发。 当触发AOF重写时，内部流程： 执行AOF重写请求。如果当前进程正在执行AOF重写，请求不执行并返回如下响应：ERR Background append only file rewriting already in progress 父进程执行fork创建子进程，开销等同于bgsave过程。 主进程fork操作完成后，继续响应其它命令。所以修改命令依然写入AOF缓冲区并根据appendfsync策略同步到硬盘，保证原有AOF机制正确性。 由于fork操作运用写时复制技术，子进程只能共享fork操作时的内存数据。由于父进程依然响应命令，Redis使用AOF重写缓冲区保存这部分新数据，防止新AOF文件生成期间丢失这部分数据。 子进程根据内存快照，按照命令合并规则写入新的AOF文件，每次批量写入硬盘数据量由配置aof-rewrite-incremental-fsync控制，默认为32MB，防止单词刷盘数据过多造成硬盘阻塞。 新AOF文件写入完成后，子进程发送信号给父进程，父进程更新统计信息，具体见info persistence的aof_*相关统计。 父进程把AOF重写缓冲区的数据写入到新的AOF文件。 使用新AOF文件替换老文件，完成AOF重写。 注意事项​ 在写入AOF日志文件时，如果Redis服务器宕机，则aof日志文件会出现格式错误，在重启Redis服务器时，Redis服务器会拒绝载入这个aof文件，可以通过命令修复aof并恢复数据。 redid-check-aof -fix appendonly.aof AOF的优缺点优点： AOF可以设置完全不同步、每秒同步、每次操作同步，默认时每秒同步。因为AOF时操作指令的追加，所以可以频繁的大量的同步。 AOF文件是一个值追加日志的文件，即使服务宕机为写入完整的命令，也可以通过redis-check-aof工具修复这些问题。 如果AOF文件过大，Redis会在后台自动地重写AOF文件。重写后会使AOF文件压缩到最小所需的指令集。 AOF文件是有序保存数据看的所有写入操作，易读，易分析。即使如果不小心误操作数据看，也很容易找出业务错误指令，恢复到某个数据节点。例如不小FLUSHALL，可以非常容易恢复到执行命令之前。 缺点： 相同数据量下，AOF的文件通常体积会比RDB大。因为AOF是存指令的，而RDB是所有指令的结果快照。但AOF在日志重写后会压缩一些空间。 在大量写入和载入的时候，AOF的效率会比RDB低，因为大量写入，AOF会执行更多的保存命令，载入的时候也需要大量的重执行命令来得到最后的结果。RDB对此更有优势。 AOF常用配置appendonly no：是否开启AOF appendfilename &quot;appendonly.aof&quot;：AOF文件名 dir ./：RDB文件和AOF文件所在目录 appendfsync everysec：fsync持久化策略 no-appendfsync-on-rewrite no：AOF重写期间是否禁止fsync；如果开启该选项，可以减轻文件重写时CPU和硬盘的负载（尤其是硬盘），但是可能会丢失AOF重写期间的数据；需要在负载和安全性之间进行平衡 auto-aof-rewrite-percentage 100：文件重写触发条件之一 auto-aof-rewrite-min-size 64mb：文件重写触发提交之一 aof-load-truncated yes：如果AOF文件结尾损坏，Redis启动时是否仍载入AOF文件 重启加载的选择AOF和RDB文件都可以用于服务器重启时的数据恢复。 持久化的选择​ 在实际生产环境中，根据数据量、应用对数据的安全要求、预算限制等不同情况，会有各种各样的持久化策略；如完全不使用任何持久化、使用RDB或AOF的一种，或同时开启RDB和AOF持久化等。 ​ 此外，持久化的选择必须与Redis的主从策略一起考虑，因为主从复制与持久化同样具有数据备份的功能，而且主机master和从机slave可以独立的选择持久化方案。 面分场景来讨论持久化策略的选择，下面的讨论也只是作为参考，实际方案可能更复杂更具多样性。 如果Redis中的数据完全丢弃也没有关系（如Redis完全用作DB层数据的cache），那么无论是单机，还是主从架构，都可以不进行任何持久化。 在单机环境下（对于个人开发者，这种情况可能比较常见），如果可以接受十几分钟或更多的数据丢失，选择RDB对Redis的性能更加有利；如果只能接受秒级别的数据丢失，应该选择AOF。 但在多数情况下，我们都会配置主从环境，slave的存在既可以实现数据的热备，也可以进行读写分离分担Redis读请求，以及在master宕掉后继续提供服务。在这种情况下的做法是： master：完全关闭持久化（包括RDB和AOF），这样可以让master的性能达到最好； slave：关闭RDB，开启AOF（如果对数据安全要求不高，开启RDB关闭AOF也可以），并定时对持久化文件进行备份（如备份到其他文件夹，并标记好备份的时间）；然后关闭AOF的自动重写，然后添加定时任务，在每天Redis闲时（如凌晨12点）调用bgrewriteaof。 这里需要解释一下，为什么开启了主从复制，可以实现数据的热备份，还需要设置持久化呢？因为在一些特殊情况下，主从复制仍然不足以保证数据的安全，例如： master和slave进程同时停止：考虑这样一种场景，如果master和slave在同一个机房，则一次停电事故就可能导致master和slave机器同时关机，Redis进程停止；如果没有持久化，则面临的是数据的完全丢失。 master误重启：考虑这样一种场景，master服务因为故障宕掉了，如果系统中有自动拉起机制（即检测到服务停止后重启该服务）将master自动重启，由于没有持久化文件，那么master重启后数据是空的，slave同步数据也变成了空的；如果master和slave都没有持久化，同样会面临数据的完全丢失。需要注意的是，即便是使用了哨兵进行自动的主从切换，也有可能在哨兵轮询到master之前，便被自动拉起机制重启了。因此，应尽量避免“自动拉起机制”和“不做持久化”同时出现。 异地灾备：上述讨论的几种持久化策略，针对的都是一般的系统故障，如进程异常退出、宕机、断电等，这些故障不会损坏硬盘。但是对于一些可能导致硬盘损坏的灾难情况，如火灾地震，就需要进行异地灾备。 例如对于单机的情形，可以定时将RDB文件或重写后的AOF文件，通过scp拷贝到远程机器，如阿里云；对于主从的情形，可以定时在master上执行bgsave，然后将RDB文件拷贝到远程机器，或者在slave上执行bgrewriteaof重写AOF文件后，将AOF文件拷贝到远程机器上。 一般来说，由于RDB文件文件小、恢复快，因此灾难恢复常用RDB文件；异地备份的频率根据数据安全性的需要及其它条件来确定，但最好不要低于一 天一次。 持久化配置方案 企业级的持久化的配置策略 save 60 10000：如果你希望尽可能确保说，RDB最多丢1分钟的数据，那么尽量就是每隔1分钟都生成一个快照，低峰期，数据量很少，也没必要 10000-&gt;生成RDB，1000-&gt;RDB，这个根据你自己的应用和业务的数据量，自己去决定 AOF一定要打开。 auto-aof-rewrite-percentage 100: 就是当前AOF大小膨胀到超过上次**100%**，上次的两倍 auto-aof-rewrite-min-size 64mb: 根据你的数据量来定，16mb，32mb 数据备份方案 RDB非常适合做冷备，每次生成之后，就不会再有修改了 写crontab定时调度脚本去做数据备份 每小时都copy一份rdb的备份，到一个目录中去，仅仅保留最近48小时的备份 每天都保留一份当日的rdb的备份，到一个目录中去，仅仅保留最近1个月的备份 每次copy备份的时候，都把太旧的备份给删了 每天晚上将当前服务器上所有的数据备份，发送一份到远程的云服务上去【crontab】","link":"/2020/09/23/redis%E6%8C%81%E4%B9%85%E5%8C%96rdb%E5%8F%8Aaof.html"},{"title":"sl-im 基于 Swoft 微服务协程框架和 Layim 网页聊天系统 开发出来的聊天室","text":"简介sl-im 是基于 Swoft 微服务协程框架和 Layim 网页聊天系统 所开发出来的聊天室。 当前分支为2.x开发版本，如需部署，请下载releases 体验地址sl-im https://im.gaobinzhan.com 演示图 功能 登录注册（Http） 单点登录（Websocket） 私聊（Websocket） 群聊（Websocket） 在线人数（Websocket） 获取未读消息（Websocket） 好友在线状态（Websocket） 好友 查找 添加 同意 拒绝（Http+Websocket） 群 创建 查找 添加 同意 拒绝（Http+Websocket） 聊天记录存储 心跳检测 消息重发 断线重连 Requirement PHP 7.1+ Swoole 4.3.4+ Composer Swoft &gt;= 2.0.8 部署方式Composer1composer update beanapp/bean.php 12345678910111213'db' =&gt; [ 'class' =&gt; Database::class, 'dsn' =&gt; 'mysql:dbname=im;host=127.0.0.1:3306', 'username' =&gt; 'root', 'password' =&gt; 'gaobinzhan', 'charset' =&gt; 'utf8mb4', ],'db.pool' =&gt; [ 'class' =&gt; \\Swoft\\Db\\Pool::class, 'database' =&gt; bean('db'), 'minActive' =&gt; 5, // 自己调下连接池大小 'maxActive' =&gt; 10 ], 数据表迁移php bin/swoft mig:up env配置vim .env 1234567891011# basicAPP_DEBUG=0SWOFT_DEBUG=0# more ...APP_HOST=https://im.gaobinzhan.com/WS_URL=ws://im.gaobinzhan.com/im# 是否开启静态处理 这里我关了 让nginx去处理ENABLE_STATIC_HANDLER=false # swoole v4.4.0以下版本, 此处必须为绝对路径DOCUMENT_ROOT=/data/wwwroot/IM/public nginx配置12345678910111213141516171819202122232425262728293031323334353637server{ listen 80; server_name im.gaobinzhan.com; return 301 https://$server_name$request_uri;}server{ listen 443 ssl; root /data/wwwroot/IM/public/; add_header Strict-Transport-Security &quot;max-age=31536000&quot;; server_name im.gaobinzhan.com; access_log /data/wwwlog/im-gaobinzhan-com.access.log; error_log /data/wwwlog/im-gaobinzhan-com.error.log; client_max_body_size 100m; ssl_certificate /etc/nginx/ssl/full_chain.pem; ssl_certificate_key /etc/nginx/ssl/private.key; ssl_session_timeout 5m; ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; location / { proxy_pass http://127.0.0.1:9091; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Real-PORT $remote_port; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } location /im { proxy_pass http://127.0.0.1:9091; proxy_http_version 1.1; proxy_read_timeout 3600s; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; } location ~ .*\\.(jsicocssttfwoffwoff2pngjpgjpegsvggifhtm)$ { root /data/wwwroot/IM/public; }} Start1php bin/swoft ws:start 1php bin/swoft ws:start -d 怎么访问还用写吗？？？点个star吧 ✌️ 联系方式 WeChat：gaobinzhan QQ：975975398 我的博客即将同步至腾讯云+社区，邀请大家一同入驻：https://cloud.tencent.com/developer/support-plan?invite\\_code=14q93ezyewy0r","link":"/2020/08/05/sl-im-%E5%9F%BA%E4%BA%8E-swoft-%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%8D%8F%E7%A8%8B%E6%A1%86%E6%9E%B6%E5%92%8C-layim-%E7%BD%91%E9%A1%B5%E8%81%8A%E5%A4%A9%E7%B3%BB%E7%BB%9F-%E5%BC%80%E5%8F%91%E5%87%BA-5.html"},{"title":"Swoole协程模式实现Mysql连接池","text":"[TOC] 连接池定义永不断开，要求我们的这个程序是一个常驻内存的程序。数据库连接池（Connection pooling）是程序启 动时建立足够的数据库连接，并将这些连接组成一个连接池，由程序动态地对池中的连接进行申请，使用，释放。 为什么需要连接池？当并发量很低的时候，连接可以临时建立，但当服务吞吐达到几百、几千的时候，频繁 建立连接 Connect 和 销毁连接 Close 就有可能会成为服务的一个瓶颈，那么当服务启动的时候，先建立好若干个连接并存放于一个队列中，当需要使用时从队列中取出一个并使用，使用完后再反还到队列去，而对这个队列数据结构进行维护的，就是连接池。 使用channel实现连接池 必须在协程模式下 Pool.php","link":"/2020/09/20/swoole%E5%8D%8F%E7%A8%8B%E6%A8%A1%E5%BC%8F%E5%AE%9E%E7%8E%B0mysql%E8%BF%9E%E6%8E%A5%E6%B1%A0.html"},{"title":"Swoole处理Tcp粘包问题（面向过程）","text":"[TOC] TCP通信特点 TCP 是流式协议没有消息边界，客户端向服务器端发送一次数据，可能会被服务器端分成多次收到。客户端向服务器端发送多条数据。服务器端可能一次全部收到。 保证传输的可靠性，顺序。 TCP拥有拥塞控制，所以数据包可能会延后发送。 TCP粘包介绍TCP 粘包是指发送方发送的若干包数据 到 接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。 原因发送方：发送方需要等缓冲区满才发送出去，造成粘包接收方：接收方不及时接收缓冲区的包，造成多个包接收下图为tcp协议在传输数据的过程： swoole处理粘包 EOF结束协议：EOF切割需要遍历整个数据包的内容，查找EOF，因此会消耗大量CPU资源。上手比较简单 固定包头+包体协议：长度检测协议，只需要计算一次长度，数据处理仅进行指针偏移，性能非常高 重现TCP粘包问题服务端","link":"/2020/09/20/swoole%E5%A4%84%E7%90%86tcp%E7%B2%98%E5%8C%85%E9%97%AE%E9%A2%98%EF%BC%88%E9%9D%A2%E5%90%91%E8%BF%87%E7%A8%8B%EF%BC%89.html"},{"title":"使用 Clockwork 来调试 Laravel App","text":"博主： gaobinzhan 发布时间：2019 年 01 月 06 日 895次浏览 暂无评论 857字数 分类： Laravel PHP Clockwork 由两个部分组成: Chrome 插件 Clockwork服务器端的 Composer Package Github 项目 安装首先安装 Chrome 插件 Clockwork,然后可以根据 Github 的 readme 安装服务端 也可根据 以下操作 1. 运行命令composer require itsgoingd/clockwork 2.完成上面操作，修改 config/app.php 中 providers 数组Clockwork\\Support\\Laravel\\ClockworkServiceProvider::class 3. 修改 config/app.php 中 aliases 数组'Clockwork' =&gt; Clockwork\\Support\\Laravel\\Facade::class, 效果图： Clockwork 由两个部分组成: Chrome 插件 Clockwork服务器端的 Composer Package Github 项目 安装首先安装 Chrome 插件 Clockwork,然后可以根据 Github 的 readme 安装服务端 也可根据 以下操作 1. 运行命令composer require itsgoingd/clockwork 2.完成上面操作，修改 config/app.php 中 providers 数组Clockwork\\Support\\Laravel\\ClockworkServiceProvider::class 3. 修改 config/app.php 中 aliases 数组'Clockwork' =&gt; Clockwork\\Support\\Laravel\\Facade::class, 效果图：","link":"/2020/09/20/%E4%BD%BF%E7%94%A8-clockwork-%E6%9D%A5%E8%B0%83%E8%AF%95-laravel-app.html"},{"title":"如何搭建redis-cluster","text":"​ 假设在一台主从机器上配置了20G内存，但是业务需求是需要50G内存的时候，主从结构+哨兵可以实现高可用故障切换+冗余备份，但是不能解决数据容量的问题，用哨兵，每个redis实例存储的数据也都是完整的数据，浪费内存且有木桶效应。 ​ 为了最大化利用内存，可以采用cluster，就是分布式存储。即每台redis存储不同的内容。 Redis分布式方案一般有两种： 客户端分区方案：优点是分区逻辑可控，缺点是需要自己处理数据路由，实现高可用、故障转移等问题。比如在redis2.8之前通常的做法是获取某个key的hashcode，然后取余分布到不同节点，不过这种做法无法很好的支持动态伸缩性需求，一旦节点的增或者删操作，都会导致key无法在redis中命中。 代理方案：优点是简化客户端分布式逻辑和升级维护便利，缺点是加重架构部署复杂度和性能损耗。如twemproxy、codis。 而redis官方提供了专有的集群方案：Redis Cluster，它非常优雅的解决了Redis集群方面的问题，部署方便简单。 Redis Cluster​ Redis Cluster是Redis的分布式解决方案，在3.0版本正式推出，有效地解决了Redis分布式方面的需求。当遇到单机内存、并发、流量等瓶颈时，可以采用Cluster架构方案达到负载均衡的目的。 ​ 在Redis Cluster，它们任何两个节点之间都是相互连通的。客户端可以与任何一个节点相连接，然后就可以访问集群中的任何一个节点，对其进行存取和其它操作。 Redis Cluster提供的好处： 将数据自动切分到多个节点的能力 当集群中的一部分节点失效或者无法进行通讯时，仍然可以继续处理命令请求的能力，拥有自动故障转移的能力。 Redis Cluster 和 replication + sentinel 如何选择： 如果数据量很少，主要是承载高并发高性能的场景，比如你的缓存一般就几个G，单机就够了。 Replication：一个master，多个slave，要几个slave跟你的要求的读吞吐量有关系，结合sentinel集群，去保证redis主从架构的高可用就行了。 Redis Cluster：主要是针对海量数据+高并发+高可用的场景，海量数据，如果数据量很大，建议用Redis Cluster 数据分布理论： 分布式数据库首先要解决把整个数据集按照分区规则映射到多个节点的问题，即把数据集划分到多个节点上，每个节点负责整体数据的一个子集。 常见的分区规则有哈希分区和顺序分区两种： 顺序分布：把一整块数据分散到很多机器中，一般都是平均分配的。 哈希分区：通过hash的函数，取余产生的数。保证这串数字充分的打散，均匀的分配到各台机器上。 哈希分布和顺序分布只是场景上的适用。哈希分布不能顺序访问，比如你想访问1~100，哈希分布只能遍历全部数据，同时哈希分布因为做了hash后导致与业务数据无关了。 分区方式 描述 代表产品 哈希分区 离散度好数据分布业务无关无法顺序访问 RedisClusterCassandaDynamo 顺序分区 离散度易倾斜数据分布业务相关可顺序访问 BigtableHbaseHypertable 数据倾斜与数据迁移跟节点伸缩： 顺序分布是会导致数据倾斜的，主要是访问的倾斜。每次点击会重点访问某台机器，这就导致最后数据都到这台机器上了，这就是顺序分布最大的缺点。但哈希分布的时候，假如要扩容机器的时候，称之为“节点伸缩”，这个时候，因为是哈希算法，会导致数据迁移。 哈希分区方式： 节点取余分区： 使用特点的数据（包括redis的键或用户ID），再根据节点数量N，使用公式：hash(key)%N计算出一个0～（N-1）值，来决定数据映射到哪一个节点上。即哈希值对节点总数取余。 缺点：当节点数量N变化时（扩容或者收缩），数据和节点之间的映射关系需要重新计算，这样的话，按照新的规则映射，要么之前存储的数据找不到，要么之前数据被重新映射到新的节点（导致以前存储的数据发生数据迁移）。 实践：常用于数据库的分库分表规则，一般采用预分区的方式，提前根据数量规划好分区数，比如划分为512或1024张表，保证可支撑未来一段时间的数据量，再根据负载情况将表迁移到其它数据库中。 一致性哈希： 一致性哈希分区（Distributed Hash Table）实现思路是为系统中每个节点分配一个token，范围一般在0～232，这些token构成一个哈希环。数据读写执行节点查找操作时，先根据key计算hash值，然后顺时针找到第一个大于等于该哈希值的token节点。 上图就是一个一致性hash的原理解析。 假设有n1～n4这四台机器，我们对每一台机器分配一个唯一token，每次有数据（黄色代表数据），一致性哈希算法规则每次都顺时针漂移数据，也就是图中黄色的数据都指向n3。 这个时候我们需要增加一个节点n5，在n2和n3之间，数据还是会发生漂移（会偏移到大于等于的节点），但是这个时候你是否注意到，其实只有n2～n3这部分的数据被漂移，其它的数据都是不会变的，这种方式相比节点取余最大的好处在于加入和删除节点只影响哈希环中相邻的节点，对其它节点无影响。 缺点：每个节点的负载不相同，因为每个节点的hash是根据key计算出来的，换句话说就是假设key足够多，被hash算法打散得非常均匀，但是节点过少，导致每个节点处理的key个数不太一样，甚至相差很大，这就导致某些节点压力很大 实践：加减节点会造成哈希环中部分数据无法命中，需要手动处理或者忽略这部分数据，因此一致性哈希常用于缓存场景。 虚拟槽分区： 虚拟槽分区巧妙地使用了哈希空间，使用分散度良好的哈希函数把所有数据映射到一个固定范围的整数集合中，整数定义为槽（slot）。这个范围一般远远大于节点数，比如Redis Cluster槽范围是0～16383（也就是说有16383个槽）。槽是集群内数据管理和迁移的基本单位。采用大范围槽的主要目的是为了方便数据拆分和集群扩展。每个节点会负责一定数量的槽。 如上图所示，当前集群有5个节点，每个节点平均大约负责3276个槽。由于采用高质量的哈希算法，每个槽所映射的数据通常比较均匀，将数据平均划分到5个节点进行数据分区。Redis Cluster就是采用虚拟槽分区，每当key访问过来，Redis Cluster会计算哈希值是否在这个区间里。它们彼此都知道对应的槽在哪台机器上，这样就能做到平均分配了。 集群限制：批量key操作。 Docker-compose搭建Redis Cluster 因为没有多台机器去部署redis实例，所以这里采用docker来搭建，在生产环境中肯定是多台机器去部署的。 容器名称 ip 端口 redis-cluster1 192.168.3.101 6380-&gt;637916380-&gt;16379 redis-cluster2 192.168.3.102 6381-&gt;637916381-&gt;16379 redis-cluster3 192.168.3.103 6382-&gt;637916382-&gt;16379 redis-cluster4 192.168.3.104 6383-&gt;637916383-&gt;16379 redis-cluster5 192.168.3.105 6384-&gt;637916384-&gt;16379 Redis-cluster6 192.168.3.106 6385-&gt;637916385-&gt;16379 如上图把redis.conf复制进去，自行去下载，然后分别加入以下代码： 1234567bind 0.0.0.0cluster-enabled yescluster-config-file &quot;/redis/conf/nodes.conf&quot;cluster-node-timeout 5000protected-mode noport 6379daemonize no docker-compose.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980version: &quot;3.6&quot;services: redis-cluster1: image: redis container_name: redis-cluster1 ports: - &quot;6380:6379&quot; - &quot;16380:16379&quot; volumes: - /Users/gaobinzhan/Documents/Redis/cluster/cluster1:/redis command: redis-server /redis/conf/redis.conf networks: redis-test: ipv4_address: 192.168.3.101 redis-cluster2: image: redis container_name: redis-cluster2 ports: - &quot;6381:6379&quot; - &quot;16381:16379&quot; volumes: - /Users/gaobinzhan/Documents/Redis/cluster/cluster2:/redis command: redis-server /redis/conf/redis.conf networks: redis-test: ipv4_address: 192.168.3.102 redis-cluster3: image: redis container_name: redis-cluster3 ports: - &quot;6382:6379&quot; - &quot;16382:16379&quot; volumes: - /Users/gaobinzhan/Documents/Redis/cluster/cluster3:/redis command: redis-server /redis/conf/redis.conf networks: redis-test: ipv4_address: 192.168.3.103 redis-cluster4: image: redis container_name: redis-cluster4 ports: - &quot;6383:6379&quot; - &quot;16383:16379&quot; volumes: - /Users/gaobinzhan/Documents/Redis/cluster/cluster4:/redis command: redis-server /redis/conf/redis.conf networks: redis-test: ipv4_address: 192.168.3.104 redis-cluster5: image: redis container_name: redis-cluster5 ports: - &quot;6384:6379&quot; - &quot;16384:16379&quot; volumes: - /Users/gaobinzhan/Documents/Redis/cluster/cluster5:/redis command: redis-server /redis/conf/redis.conf networks: redis-test: ipv4_address: 192.168.3.105 redis-cluster6: image: redis container_name: redis-cluster6 ports: - &quot;6385:6379&quot; - &quot;16385:16379&quot; volumes: - /Users/gaobinzhan/Documents/Redis/cluster/cluster6:/redis command: redis-server /redis/conf/redis.conf networks: redis-test: ipv4_address: 192.168.3.106networks: redis-test: driver: bridge ipam: config: - subnet: &quot;192.168.3.0/24&quot; 然后进行docker-compose up 此刻每个目录下面多了nodes.conf 现在文件内容只是单单保存了redis实例自身的节点数据。 也可以随便连接一台redis，查看集群状态： 1234gaobinzhan-MBP:~ gaobinzhan$ redis-cli -p 6380127.0.0.1:6380&gt; info Cluster# Clustercluster_enabled:1 此刻集群只是开启状态，往里面写入数据会报错： 12127.0.0.1:6380&gt; set 1 2(error) CLUSTERDOWN Hash slot not served 是因为没有分配槽。 在redis之前的版本，需要手动分配槽，非常不方便。现在的版本只需要简单执行下命令就可以了。 随便进入一个容器当中 docker exec -it redis-cluster1 sh 然后执行redis-cli --cluster create 192.168.3.101:6379 192.168.3.102:6379 192.168.3.103:6379 192.168.3.104:6379 192.168.3.105:6379 192.168.3.106:6379 --cluster-replicas 1 12345678910111213141516171819202122gaobinzhan-MBP:~ gaobinzhan$ docker exec -it redis-cluster1 sh# redis-cli --cluster create 192.168.3.101:6379 192.168.3.102:6379 192.168.3.103:6379 192.168.3.104:6379 192.168.3.105:6379 192.168.3.106:6379 --cluster-replicas 1&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Master[0] -&gt; Slots 0 - 5460Master[1] -&gt; Slots 5461 - 10922Master[2] -&gt; Slots 10923 - 16383Adding replica 192.168.3.105:6379 to 192.168.3.101:6379Adding replica 192.168.3.106:6379 to 192.168.3.102:6379Adding replica 192.168.3.104:6379 to 192.168.3.103:6379M: 2a373fe66cde81d1530584bb86e49694b000d0c2 192.168.3.101:6379 slots:[0-5460] (5461 slots) masterM: 8de35d3b2439d05de839a2539f68e4833b90679d 192.168.3.102:6379 slots:[5461-10922] (5462 slots) masterM: caca339b5511d3a14e381d5ffd9434458c7368bd 192.168.3.103:6379 slots:[10923-16383] (5461 slots) masterS: 97eccf5edf7fb12d4a2e01b16dbf2d9c561896b3 192.168.3.104:6379 replicates caca339b5511d3a14e381d5ffd9434458c7368bdS: 64512db80b1a159ca823a25a7e9893154efd555c 192.168.3.105:6379 replicates 2a373fe66cde81d1530584bb86e49694b000d0c2S: 1722206f30f3b7c65706d30f4a1ee3b6e0cbca7c 192.168.3.106:6379 replicates 8de35d3b2439d05de839a2539f68e4833b90679dCan I set the above configuration? (type 'yes' to accept): 此刻会提示你，是否接受此配置，输入yes即可。 1234567891011121314151617181920212223242526272829Can I set the above configuration? (type 'yes' to accept): yes&gt;&gt;&gt; Nodes configuration updated&gt;&gt;&gt; Assign a different config epoch to each node&gt;&gt;&gt; Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join...&gt;&gt;&gt; Performing Cluster Check (using node 192.168.3.101:6379)M: 2a373fe66cde81d1530584bb86e49694b000d0c2 192.168.3.101:6379 slots:[0-5460] (5461 slots) master 1 additional replica(s)S: 64512db80b1a159ca823a25a7e9893154efd555c 192.168.3.105:6379 slots: (0 slots) slave replicates 2a373fe66cde81d1530584bb86e49694b000d0c2S: 1722206f30f3b7c65706d30f4a1ee3b6e0cbca7c 192.168.3.106:6379 slots: (0 slots) slave replicates 8de35d3b2439d05de839a2539f68e4833b90679dM: 8de35d3b2439d05de839a2539f68e4833b90679d 192.168.3.102:6379 slots:[5461-10922] (5462 slots) master 1 additional replica(s)S: 97eccf5edf7fb12d4a2e01b16dbf2d9c561896b3 192.168.3.104:6379 slots: (0 slots) slave replicates caca339b5511d3a14e381d5ffd9434458c7368bdM: caca339b5511d3a14e381d5ffd9434458c7368bd 192.168.3.103:6379 slots:[10923-16383] (5461 slots) master 1 additional replica(s)[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. 此时redis-cluster已经搭建好了，nodes.conf文件也发生了变化，执行cluster info： 1234567891011121314151617127.0.0.1:6380&gt; cluster infocluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6cluster_size:3cluster_current_epoch:6cluster_my_epoch:1cluster_stats_messages_ping_sent:234cluster_stats_messages_pong_sent:242cluster_stats_messages_sent:476cluster_stats_messages_ping_received:237cluster_stats_messages_pong_received:234cluster_stats_messages_meet_received:5cluster_stats_messages_received:476 状态是ok的，来试着写写数据。进入redis实例docker exec -it redis-cluster1 sh 1234gaobinzhan-MBP:~ gaobinzhan$ docker exec -it redis-cluster1 sh# redis-cli127.0.0.1:6379&gt; set 1 2(error) MOVED 9842 192.168.3.102:6379 报错了，因为槽的问题，这个数据需要写入到102那台实例当中，这时可以用集群方式启动redis-cli -c 123456# redis-cli -c127.0.0.1:6379&gt; set 1 2-&gt; Redirected to slot [9842] located at 192.168.3.102:6379OK192.168.3.102:6379&gt; get 1&quot;2&quot; 会发现提示数据移动到102节点了，因为是集群方式所以可以获取的，切换到102节点： 123# redis-cli -c -h 192.168.3.102192.168.3.102:6379&gt; get 1&quot;2&quot; 也可以正常的获取。 往期方式搭建集群准备节点Redis集群一般由多个节点组成，节点数量至少为6个才能保证组成完整高可用的集群，前面的主从复制跟哨兵共同构成了高可用。每个节点需要开启配置 cluster-enabled yes ，让Redis 运行在集群模式下。 性能：这是Redis赖以生存的看家本领，增加集群功能后当然不能对性能产生太大影响，所以Redis采取了P2P而非Proxy方式、异步复制、客户端重定向等设计，而牺牲了部分的一致性、使用性。 水平扩展：集群的最重要能力当然是扩展，文档中称可以线性扩展到1000结点。 可用性：在Cluster推出之前，可用性要靠Sentinel保证。有了集群之后也自动具有了Sentinel的监控和自动Failover能力 集群的相关配置： 12345678#节点端口port 6379#开启集群模式cluster-enabled yes#节点超时时间，单位毫秒cluster-node-timeout 15000#集群内部配置文件cluster-config-file &quot;nodes-6379.conf&quot; 其他配置和单机模式一致即可，配置文件命名规则redis-{port}.conf ，准备好配置后启动所有节点，第一次启动时如果没有集群配置文件，它会自动创建一份，文件名称采用 cluster-config-file 参数项控制，建议采用node-{port}.conf格式定义，也就是说会有两份配置文件。 当集群内节点信息发生变化，如添加节点、节点下线、故障转移等。节点会自动保存集群状态到配置文件中。需要注意的是， Redis自动维护集群配置文件，不要手动修改，防止节点重启时产生集群信息错乱。 然后就跟上面一样准备准备节点就行了。 节点握手节点握手是指一批运行在集群模式下的节点通过Gossip协议彼此通信，达到感知对方的过程。节点握手是集群彼此通信的第一步，由客户端发起命令：cluster meet{ip}{port} 通过命令cluster meet 127.0.0.1 6381让节点6380和6381节点进行握手通信。cluster meet命令是一个异步命令，执行之后立刻返回。内部发起与目标节点进行握手通信 。 节点6380本地创建6381节点信息对象，并发送meet消息。 节点6381接受到meet消息后，保存6380节点信息并回复pong消息。 之后节点6380和6381彼此定期通过ping/pong消息进行正常的节点通信。 通过cluster nodes命令确认6个节点都彼此感知并组成集群。 注意： 每个Redis Cluster节点会占用两个TCP端口，一个监听客户端的请求，默认是6379，另外一个在前一个端口加上10000， 比如16379，来监听数据的请求，节点和节点之间会监听第二个端口，用一套二进制协议来通信。节点之间会通过套协议来进行失败检测，配置更新，failover认证等等。为了保证节点之间正常的访问，需要注意防火墙的配置。 节点建立握手之后集群还不能正常工作，这时集群处于下线状态，所有的数据读写都被禁止。 设置从节点作为一个完整的集群，需要主从节点，保证当它出现故障时可以自动进行故障转移。集群模式下，Reids 节点角色分为主节点和从节点。 首次启动的节点和被分配槽的节点都是主节点，从节点负责复制主节点槽信息和相关的数据。 使用 cluster replicate {nodeId}命令让一个节点成为从节点。其中命令执行必须在对应的从节点上执行，将当前节点设置为node_id指定的节点的从节点。 分配槽Redis 集群把所有的数据映射到16384个槽中。每个key会映射为一个固定的槽，只有当节点分配了槽，才能响应和这些槽关联的键命令。通过cluster addslots命令为节点分配槽利用bash特性批量设置槽（slots），命令如下： redis-cli -h 192.168.3.101 cluster addslots {0..5461} redis-cli -h 192.168.3.102 cluster addslots {5462..10922} redis-cli -h 192.168.3.103 cluster addslots {10923..16383} 然后就可以进行操作了。 集群的命令： 1234567891011121314151617181920212223242526272829303132333435363738394041CLUSTER nodes： 列出集群当前已知的所有节点（node）的相关信息。 CLUSTER meet ： 将ip和port所指定的节点添加到集群当中。 CLUSTER addslots [slot ...]： 将一个或多个槽（slot）指派（assign）给当前节点。 CLUSTER delslots [slot ...]： 移除一个或多个槽对当前节点的指派。 CLUSTER slots： 列出槽位、节点信息。 CLUSTER slaves ： 列出指定节点下面的从节点信息。 CLUSTER replicate ： 将当前节点设置为指定节点的从节点。 CLUSTER saveconfig： 手动执行命令保存保存集群的配置文件，集群默认在配置修改的时候会自动保存配置文件。 CLUSTER keyslot ： 列出key被放置在哪个槽上。 CLUSTER flushslots： 移除指派给当前节点的所有槽，让当前节点变成一个没有指派任何槽的节点。 CLUSTER countkeysinslot ： 返回槽目前包含的键值对数量。 CLUSTER getkeysinslot ： 返回count个槽中的键。 CLUSTER setslot node 将槽指派给指定的节点，如果槽已经指派给另一个节点，那么先让另一个节点删除该槽，然后再进行指派。CLUSTER setslot migrating 将本节点的槽迁移到指定的节点中。 CLUSTER setslot importing 从 node_id 指定的节点中导入槽 slot 到本节点。 CLUSTER setslot stable 取消对槽 slot 的导入（import）或者迁移（migrate）。 CLUSTER failover： 手动进行故障转移。 CLUSTER forget ： 从集群中移除指定的节点，这样就无法完成握手，过期时为60s，60s后两节点又会继续完成握手。 CLUSTER reset [HARDSOFT]： 重置集群信息，soft是清空其他节点的信息，但不修改自己的id，hard还会修改自己的id，不传该参数则使用soft方式。 CLUSTER count-failure-reports ： 列出某个节点的故障报告的长度。 CLUSTER SET-CONFIG-EPOCH： 设置节点epoch，只有在节点加入集群前才能设置。 注意：在apline系统中不支持{1..10}操作 以上理论知识内容为网络整理。。。。","link":"/2020/09/20/%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAredis-cluster.html"},{"title":"微信自动回复图片","text":"在微信开发的页面上，设置好触发的关键词，及触发后跳转到指定的接口地址，如:http://www.gaobinzhan.com/picture.php然后在网站服务器上创建picture.php文件，文件代码如下： 这样，在微信服务号上输入对应的关键字，服务号上就会返回对应的图片。 MediaID的获取方法：登陆微信公众平台-&gt;开发者工具-&gt;在线接口调试工具 接口类型选：基础支持 先获取access_token access_token每次登陆都会变更 获取access_token后，接口列表选择多媒体文件上传接口填入access_token，type选择image，media选择要回复的图片，图片上传成功后，就会返回一个MediaID，把它填入上面的代码中就可以了。","link":"/2020/09/20/%E5%BE%AE%E4%BF%A1%E8%87%AA%E5%8A%A8%E5%9B%9E%E5%A4%8D%E5%9B%BE%E7%89%87.html"},{"title":"微服务架构常见的分布式事务解决方案","text":"多个服务，位于不同主机，不同的网络当中，没有办法用本地事务保证要么一起成功，要么一起失败。 BASE理论BA: Basic Availability 基本业务可用性（支持分区失败） S: Soft state 柔性状态（状态允许有短时间不同步，异步） E: Eventual consistency 最终一致性（最终数据是一致的，但不是实时一致） 原子性（A）与持久性（D）必须根本保障 为了可用性、性能与降级服务的需要，只有降低一致性( C ) 与 隔离性( I ) 的要求 酸碱平衡(ACID-BASE Balance) CAP定理对于共享数据系统，最多只能同时拥有CAP其中的两个，没法三者兼顾。 任意两者的组合都有其适用场景 真实系统应当是ACID与BASE的混合体 不同类型的业务可以也应当区别对待 解决方案 实现业务处理服务在业务事务提交前，向实时消息服务请求发送消息，实时消息服务只记录消息数据，而不真正发送。业务处理服务在业务事务提交后，向实时消息服务确认发送。只有在得到确认发送指令后，实时消息服务才真正发送 消息业务处理服务在业务事务回滚后，向实时消息服务取消发送。消息状态确认系统定期找到未确认发送或回滚发送的消息，向业务处理服务询问消息状态，业务处理服务根据消息ID或消息内容确定该消息是否有效 约束被动方的处理结果不影响主动方的处理结果,被动方的消息处理操作是幂等操作 成本可靠消息系统建设成本 一次消息发送需要两次请求，业务处理服务需实现消息状态回查接口 优点、适用范围消息数据独立存储、独立伸缩，降低业务系统与消息系统间的耦合 方案特点兼容所有实现AMQP标准的MQ中间件 确保业务数据可靠的前提下，实现业务数据的最终一致（理想状态下基本是准实时一致） 柔性事务解决方案 TCC（两阶段型、补偿型） 实现一个完整的业务活动由一个主业务服务与若干从业务服务组成 主业务服务负责发起并完成整个业务活动 从业务服务提供TCC型业务操作 业务活动管理器控制业务活动的一致性，它登记业务活动中的操作，并在业务活动提交时确认所有的TCC型操作的confirm操作，在业务活动取消时调用所有TCC型操作的cancel操作 成本实现TCC操作的成本 业务活动结束时confirm或cancel操作的执行成本 业务活动日志成本 适用范围强隔离性、严格一致性要求的业务活动 适用于执行时间较短的业务（比如处理账户、收费等业务） 用到的服务模式TCC操作、幂等操作、可补偿操作、可查询操作 方案特点不与具体的服务框架耦合（在RPC架构中通用） 位于业务服务层，而非资源层 可以灵活选择业务资源的锁定粒度 最大努力通知型 实现业务活动的主动方，在完成业务处理之后，向业务活动的被动方发送消息，允许消息丢失。 业务活动的被动方根据定时策略，向业务活动主动方查询，恢复丢失的业务消息。 约束被动方的处理结果不影响主动方的处理结果 成本业务查询与校对系统的建设成本 使用范围对业务最终一致性的时间敏感度低 跨企业的业务活动 方案特点业务活动的主动方在完成业务处理后，向业务活动被动方发送通知消息（允许消息丢失）主动方可以设置时间阶梯型通知规则，在通知失败后按规则重复通知，直到通知N次后不主动方提供校对查询接口给被动方按需校对查询，用于恢复丢失的业务消息 应用案例银行通知、商户通知等（各大交易业务平台间的商户通知：多次通知、查询校对、对账文件）","link":"/2020/09/20/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E5%B8%B8%E8%A7%81%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.html"},{"title":"消息中间件Kafaka - PHP操作使用Kafka","text":"PHP使用Kafka 安装libkafka 安装rdkafka php操作kafka 我们需要安装libkafka和rdkafka 下载 去GitHub上克隆下来 git clone https://github.com/edenhill/librdkafka.git 安装 cd librdkafka/ ./configure &amp;&amp; make &amp;&amp; make install 安装成功界面 没有报错就是安装成功 下载 git clone https://github.com/arnaud-lb/php-rdkafka cd php-rdkafka/ 为php安装扩展 在php-rdkafka这个目录下 phpize 然后会生成源代码安装的脚本 把php-config的位置改成自己php-config的位置 ./configure --with-php-config=/usr/local/php/bin/php-config 编译安装 make &amp;&amp; make install 成功后会出现一个文件夹 这个位置就是保存的我们刚刚安装的扩展 进入该目录 cd /usr/local/php/lib/php/extensions/no-debug-non-zts-20170718/ 会发现出现个rdkafka.so文件 修改php.ini文件加入 这里的路径就是写自己rdkafka.so文件的路径 extension=/usr/local/php/lib/php/extensions/no-debug-non-zts-20170718/rdkafka.so 重启php php-m 出现rdkafka就是安装成功 运行前先开启我们的zookeeper和kafka 上篇文章有如何开启 运行producer kafka默认端口9092 vim producer.php","link":"/2019/10/27/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6kafaka-php%E6%93%8D%E4%BD%9C%E4%BD%BF%E7%94%A8kafka.html"},{"title":"消息中间件Kafka - PHP操作使用Kafka","text":"博主： gaobinzhan 发布时间：2019 年 03 月 21 日 1366次浏览 暂无评论 1527字数 分类： 消息中间件 [TOC] 我们需要安装libkafka和rdkafka 安装libkafka 下载 去GitHub上克隆下来 git clone https://github.com/edenhill/librdkafka.git 安装 cd librdkafka/ ./configure &amp;&amp; make &amp;&amp; make install 安装成功界面 没有报错就是安装成功 安装rdkafka 下载 git clone https://github.com/arnaud-lb/php-rdkafka cd php-rdkafka/ 为php安装扩展 在php-rdkafka这个目录下 phpize 然后会生成源代码安装的脚本 把php-config的位置改成自己php-config的位置 ./configure --with-php-config=/usr/local/php/bin/php-config 编译安装 make &amp;&amp; make install 成功后会出现一个文件夹 这个位置就是保存的我们刚刚安装的扩展 进入该目录 cd /usr/local/php/lib/php/extensions/no-debug-non-zts-20170718/ 会发现出现个rdkafka.so文件 修改php.ini文件加入 这里的路径就是写自己rdkafka.so文件的路径 extension=/usr/local/php/lib/php/extensions/no-debug-non-zts-20170718/rdkafka.so 重启php php-m 出现rdkafka就是安装成功 php操作kafka 运行前先开启我们的zookeeper和kafka 上篇文章有如何开启 运行producer kafka默认端口9092 vim producer.php","link":"/2020/09/23/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6kafka-php%E6%93%8D%E4%BD%9C%E4%BD%BF%E7%94%A8kafka.html"},{"title":"消息中间件Kafka - 介绍及安装","text":"博主： gaobinzhan 发布时间：2019 年 03 月 20 日 916次浏览 暂无评论 1815字数 分类： 消息中间件 [TOC] 优势 高吞吐量：非常普通的硬件Kafka也可以支持每秒数百万的消息 支持通过Kafka服务器和消费机集群来区分消息 支持Hadoop并行数据加载 关键概念 Broker：Kafka集群中的一台或多台服务器统称为broker。 Topic：Kafka处理的消息源（feeds of messages）的不同分类。 Partition：Topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。partition中的每条消息都会被分配一个有序的id（offset）。 Message：消息，是通信的基本单位，每个producer可以向一个topic（主题）发布一些消息。 Producers：消息和数据生产者，向Kafka的一个topic发布消息的过程叫做producers。 Consumers：消息和数据的消费者，订阅topics并处理其发布的消息的过程叫做consumers。 安装 下载 先安装jdk 然后jdk的安装方式在elasticsearch的安装文章中有，这里就不写了 kafka官网 wget https://www-us.apache.org/dist/kafka/2.1.1/kafka_2.11-2.1.1.tgz 解压 tar -xzvf kafka_2.11-2.1.1.tgz 修改配置文件 cd kafka_2.11-2.1.1/config zookeeper.properties 是zookeeper的配置文件，默认端口号2181，可不做修改 server.properties 是kafka配置文件，将 zookeeper.connect 这行 改为自己的zookeeper地址和端口号 修改完成之后 返回kafka主目录 cd .. 运行zookeeper和kafka 运行zookeeper bin/zookeeper-server-start.sh config/zookeeper.properties 不要关闭此窗口 再开一个新窗口 重新进入kafka目录 运行kafka bin/kafka-server-start.sh config/server.properties 运行producer和consumer 跟上步操作一样 不要关闭窗口 重新开 重新进入kafka目录 创建一个topic为test 把ip和port改为自己zookeeper的 bin/kafka-topics.sh --create --zookeeper ip:port --replication-factor 1 --partitions 1 --topic test 运行producer bin/kafka-console-producer.sh --broker-list ip:port --topic test 跟上步操作一样 不要关闭窗口 重新开 重新进入kafka目录 运行consumer bin/kafka-console-consumer.sh --bootstrap-server ip:port --topic test --from-beginning 然后在producer发送信息 会发现 consumer的窗口会出现你发送的消息 [TOC] 优势 高吞吐量：非常普通的硬件Kafka也可以支持每秒数百万的消息 支持通过Kafka服务器和消费机集群来区分消息 支持Hadoop并行数据加载 关键概念 Broker：Kafka集群中的一台或多台服务器统称为broker。 Topic：Kafka处理的消息源（feeds of messages）的不同分类。 Partition：Topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。partition中的每条消息都会被分配一个有序的id（offset）。 Message：消息，是通信的基本单位，每个producer可以向一个topic（主题）发布一些消息。 Producers：消息和数据生产者，向Kafka的一个topic发布消息的过程叫做producers。 Consumers：消息和数据的消费者，订阅topics并处理其发布的消息的过程叫做consumers。 安装 下载 先安装jdk 然后jdk的安装方式在elasticsearch的安装文章中有，这里就不写了 kafka官网 wget https://www-us.apache.org/dist/kafka/2.1.1/kafka_2.11-2.1.1.tgz 解压 tar -xzvf kafka_2.11-2.1.1.tgz 修改配置文件 cd kafka_2.11-2.1.1/config zookeeper.properties 是zookeeper的配置文件，默认端口号2181，可不做修改 server.properties 是kafka配置文件，将 zookeeper.connect 这行 改为自己的zookeeper地址和端口号 修改完成之后 返回kafka主目录 cd .. 运行zookeeper和kafka 运行zookeeper bin/zookeeper-server-start.sh config/zookeeper.properties 不要关闭此窗口 再开一个新窗口 重新进入kafka目录 运行kafka bin/kafka-server-start.sh config/server.properties 运行producer和consumer 跟上步操作一样 不要关闭窗口 重新开 重新进入kafka目录 创建一个topic为test 把ip和port改为自己zookeeper的 bin/kafka-topics.sh --create --zookeeper ip:port --replication-factor 1 --partitions 1 --topic test 运行producer bin/kafka-console-producer.sh --broker-list ip:port --topic test 跟上步操作一样 不要关闭窗口 重新开 重新进入kafka目录 运行consumer bin/kafka-console-consumer.sh --bootstrap-server ip:port --topic test --from-beginning 然后在producer发送信息 会发现 consumer的窗口会出现你发送的消息","link":"/2020/09/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6kafka-%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85.html"},{"title":"消息队列 - 应用场景","text":"博主： gaobinzhan 发布时间：2019 年 03 月 20 日 736次浏览 暂无评论 1069字数 分类： 消息中间件 [TOC] 相关概念 消息队列中间件时分布式系统中重要的组件，主要解决应用耦合，异步消息，流量削锋等问题。实现高性能，高可用，可伸缩和最终一致性架构。是大型分布式系统不可缺少的中间件。 异步处理 场景说明：用户注册成功后，发送注册邮件，再发送注册短信。 串行方式：将注册信息写入数据库成功后，向用户发送邮件，再发送注册短信，将结果返回客户端。 并行方式：将注册信息写入数据库成功后，发送注册邮件的同时，发送注册短信，以上三个任务完成后，返回给客户端。 消息队列：将注册信息写入数据库成功后，注册信息写入消息队列，发送邮件和短信的消费者异步读取消息队列，写入消息队列即将返回给客户端。 应用解耦 场景说明：用户下单后，订单系统需要通知库存系统。 传统方式：订单系统调用库存系统的接口。 消息队列-&gt; _订单系统_：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功。_库存系统_：订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作。 流量削锋 场景说明：秒杀活动，一般会因为流量过大，导致流量暴增。 传统方式：服务端突然接受来自前端的大量订单请求 消息队列：在应用前端加入消息队列-&gt; 用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面 秒杀业务根据消息队列中的请求信息，再做后续处理 日志处理 解决大量日志传输的问题 日志采集客户端，负责日志数据采集，写入消息队列 消息队列，负责日志数据的接收，存储和转发 日志处理应用：订阅并消费消息队列中的日志数据 消息通讯 点对点消息队列，或者聊天室 客户端A和客户端B使用同一队列，进行消息通讯 客户端A，客户端B，客服端N订阅同一主题，进行消息发布和接收 主要产品 目前在生成环境，使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ等 [TOC] 相关概念 消息队列中间件时分布式系统中重要的组件，主要解决应用耦合，异步消息，流量削锋等问题。实现高性能，高可用，可伸缩和最终一致性架构。是大型分布式系统不可缺少的中间件。 异步处理 场景说明：用户注册成功后，发送注册邮件，再发送注册短信。 串行方式：将注册信息写入数据库成功后，向用户发送邮件，再发送注册短信，将结果返回客户端。 并行方式：将注册信息写入数据库成功后，发送注册邮件的同时，发送注册短信，以上三个任务完成后，返回给客户端。 消息队列：将注册信息写入数据库成功后，注册信息写入消息队列，发送邮件和短信的消费者异步读取消息队列，写入消息队列即将返回给客户端。 应用解耦 场景说明：用户下单后，订单系统需要通知库存系统。 传统方式：订单系统调用库存系统的接口。 消息队列-&gt; _订单系统_：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功。_库存系统_：订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作。 流量削锋 场景说明：秒杀活动，一般会因为流量过大，导致流量暴增。 传统方式：服务端突然接受来自前端的大量订单请求 消息队列：在应用前端加入消息队列-&gt; 用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面 秒杀业务根据消息队列中的请求信息，再做后续处理 日志处理 解决大量日志传输的问题 日志采集客户端，负责日志数据采集，写入消息队列 消息队列，负责日志数据的接收，存储和转发 日志处理应用：订阅并消费消息队列中的日志数据 消息通讯 点对点消息队列，或者聊天室 客户端A和客户端B使用同一队列，进行消息通讯 客户端A，客户端B，客服端N订阅同一主题，进行消息发布和接收 主要产品 目前在生成环境，使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ等","link":"/2020/09/20/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html"},{"title":"（转载）二十岁出头，你一无所有，但你却拥有一切","text":"那年我在离家的时候一个劲地往自己的硬盘里塞《灌篮高手》，我妈一副嗤之以鼻的表情看着我，似乎是在说：“这么大的人了居然还这么喜欢看动漫。” 我不知道怎么回应她，只好耸耸肩，因为我实在无法对我亲爱的娘亲说明这部动漫对我的意义。 你知道，有些歌有些东西就是有那种力量。哪怕它在你的手机里藏了好几年，哪怕它早就过了黄金期，哪怕越来越少的人会提起它。你就是知道，当你一听起这首歌的时候，当你一看起那些漫画的时候，你就会想到以前的自己，你就会获得一种莫名的力量。这种力量能够让你感受到自己的节奏，让你以跟世界不同的方式独自运转着，你能听到自己。比如那首永远的butterfly和直到世界的尽头，它们比记忆更可靠。 在记忆里最让你印象深刻的，一定是当年的你自己。因为只有在这个时候才发现，在你嚷嚷着“时间变化太快”的同时，在那些所谓的“物是人非”里，变化最多的人是你自己。我不知道怎么样的人生是最可怕的，但是我知道当你有一天你回头看，当你发现你曾经所说的一切，你曾经信誓旦旦的一切变成说说而已的时候，一定不会好受到哪里去。 好像人一长大，就会把很多东西给弄丢了。比如那些简单却能让自己充实开心一天的东西，比如让自己肆意哭和笑的能力，还有那些曾经一起结伴同行的人。最可怕的不是弄丢了这些东西，而是你变得心安理得。你开始安慰自己，这就是成长，这就是我们最终会变成的样子。你只是找了个借口继续这样的生活，对以前的自己嗤之以鼻。 只是每当你听起以前的歌的时候，或者你看到某个人在他自己的道路坚持下去的时候，你都会像被自己扇了一个大嘴巴。 看着别人的努力羡慕一下然后转身回去过自己的生活的你，又凭什么去过自己想要的人生？ （二）努力，是为了给自己交代 曾经跟好友为了商谈一个项目去北京，对方是一个标准的八零后，北漂。这是他飘着的第三年，伴随着他一直没有改变的直来直往的性格。这是他第三年换的第三份工作，一直没有安稳过。他说：“这些年我看过了很多人，有些人不用做什么就可以有很好的前景，有些人拼死拼活还是没有办法在这个城市里生存。” 在沪江上认识的一个小姑娘，她曾经差点为了她的男朋友去国外陪读一年，可是后来他们偏偏分手了。后来她决定一个人去上海，最苦逼的时候连饭都没得吃，就拿着几个包子躲在地铁站里，不知道去哪里。 曾经我总是无法理解，明明回到爸妈身边工作更好，也可以陪在爸妈身边，何必在大城市里摸爬滚打，还得不到一个很好的结果。就像我曾经写过的那个在动车里哭泣的姑娘，到最后没办法了只能回家。我曾觉得这样太不值得，然而当我有一天面临选择的时候，我终于明白他们做决定的时候是一个什么样的心情。 那个北漂着的哥们说过，哪怕自己奋斗了一辈子也是个屌丝，那么至少这样子自己不会再有借口了，不会在老的时候悔不该当初。你说值得么？我觉得值得。虽然我直来直往的性格给自己带来了很多麻烦，但这就是我，这就是我存在的方式。 其实所有漂泊的人，不过是为了有一天能够不再漂泊，能用自己的力量撑起身后的家人和自己爱的人。你觉得最好的生活状态是什么？我觉得最好的生活状态莫过于，在你的青春年纪傻逼地为了理想坚持过，最后回到平淡用现实的方法让自己生活下去。能实现梦想自然是最好，但没能实现自己的梦想那也没有什么可惜的。成长的第一步就是接受这个世界的多样性，认识到现实的不美好，然后还是决定要坚持最初的坚持。 小时候我总嚷嚷着，努力是了改变世界，然而现在的我会觉得，有些人努力只是为了变成一个普通人，有些人努力只是为了给自己交代，也许我们始终都只是一个小人物，但这并不妨碍我们选择用什么样的方式活下去。窃以为，那些在看透了生活的无奈之后，还是选择不敷衍不抱怨不自卑依旧热爱生活依旧努力做好身边的事的人，努力便是他们对自己的交代。 就像我曾经跟李婧讨论去哪里工作的时候，最后我们得出结论，其实无论在哪个城市存活都不容易，但无论过成什么样子，都要自己承担的起。 我有勇气做选择，自然要有本事承担地起后果。 （三）只有行动，才能解除你所有的不安 你说你想要当自由撰稿人，可从不见你努力写稿；你说你想考研，可从不见你背词做题；你看到学霸出没于是嗤之以鼻说这样活着没意思，你看到有人旅行又不屑一顾说这只是从大流。我开始怀疑你挂在嘴边的是不是逃避现实的借口，我开始怀疑你是不是在一遍遍逃避和自我安慰中变得惴惴不安。 于是你慢慢屈服于自己的欲望。明明在几年以后能有更好的生活，却一定要在现在买上最新的包。每个人都开始想要达到一定的社会地位和物质条件，似乎结果才是最重要的。然而，你有没有想过，你所谓的所有努力，是为了满足你的欲望还是真的追求上进？就像汪峰的歌里面说的：“少人走着却困在原地，多少人活着却如同死去，多少人爱着却好似分离，多少人笑着却满含泪滴。” 终于有一天，你发现你取得了当时所要的结果，可是在那之后，却再也不知道怎么继续了。 二十岁出头的时候，请把自己摆在二十岁出头的位置上。你没有理由也没能力去拥有一个四十岁的人拥有的阅历和财富，你除了手头的青春你一无所有，但就是你手头这为数不多的东西，能决定你是一个怎么样的人。 我不知道这个世界上是不是真的有所谓的安全感，还是因为每个人都说自己没有安全感，所以你也觉得自己没有安全感。我对安全感的定义只有两个：一是别人给你的能量总有一天会消失的，只有自己给自己的安全感最可靠，只有行动才会给你带来安全感；二是永远要记得，不管你是一个什么样的德行，你都是你父母的安全感。 所以当你觉得不安的时候，请想一想身后的父母，想想他们正在为你打拼；请想一想自己的初衷，然后抬起头继续倔强地走下去。 唯有行动，才能解除你所有的不安。 （四）有梦想，不抱怨 时间一天天过去，我们终会因我们的努力或堕落变得丰富或苍白。 有时间我就每天花两小时看书，没时间就睡前看二十分钟，周末的话可以看完整本书。做论题做一遍做不好我就做两遍，文稿要求我写一万字我就写将近两万字然后删。写出一篇好文是运气，如果一个人一直在写的话，那就是靠努力。更多时候，世界对你的态度取决于你对世界的态度，没什么好抱怨的。 为什么我们一再打击还要继续向前走？为什么明明很失望了我们也不愿意放弃一个人和一个理想？ 所有人，所有人还坚持向前走着，只是因为他想要向前走着，只是因为他还不愿意像世界投降。也许没有人跟你完全一样，也没有人可以时时刻刻地陪在你身边，也许我们很久以后回过头来看，会连现在的珍惜的人的样貌都记不清。可是我最大的幸运却是，即便如此，还是有人愿意在有限的时间里用心地陪我走过这一段。愿意跟我一起为了梦想努力，经历那些孤单流离。 这样一想，人生也还真是不错呢。 当你看书看到头痛两眼通红的时候；当你按着遥控器不停转台的时候；当你翻着通讯录不知道打给谁的时候；当你独自穿越人群看着两岸灯火找不到归属感的时候；你就应该听起一首歌，看起一本书，想想自己最初的坚持和你站在这个地方的理由，然后抬起头勇敢地走下去了。 这首歌（汪峰《存在》）有一句话是：“是否找个理由随波逐流，或是勇敢前行挣脱牢笼。”我想，你知道答案。 你现在一无所有，但你却拥有一切，因为你还有牛逼的梦想。只要路是自己选的，就不怕走远，生活总会留点什么给对它抱有信心的人的。 原文链接：http://blog.csdn.net/itmyhome1990/article/details/8769913","link":"/2020/09/20/%EF%BC%88%E8%BD%AC%E8%BD%BD%EF%BC%89%E4%BA%8C%E5%8D%81%E5%B2%81%E5%87%BA%E5%A4%B4%EF%BC%8C%E4%BD%A0%E4%B8%80%E6%97%A0%E6%89%80%E6%9C%89%EF%BC%8C%E4%BD%86%E4%BD%A0%E5%8D%B4%E6%8B%A5%E6%9C%89%E4%B8%80.html"}],"tags":[],"categories":[{"name":"uncategorized","slug":"uncategorized","link":"/categories/uncategorized/"}]}